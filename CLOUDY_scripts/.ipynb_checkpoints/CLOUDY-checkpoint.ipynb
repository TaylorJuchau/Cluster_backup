{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyCloudy as pc\n",
    "import pyneb\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) #TJ change directory to include the entire ASTRO5160 directory\n",
    "from Py_files.Basic_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_emission_lines(model_name, target_string, wl_range):\n",
    "    \"\"\"\n",
    "    Parse a file and extract emission line data matching the pattern:\n",
    "    [Capital letter][optional lowercase letter] space integer (e.g., H  1 or He 2)\n",
    "    followed by wavelength, flux values, etc.\n",
    "    \n",
    "    Args:\n",
    "        model_name: type = str - model_name used to find the output file you want to parse\n",
    "        target_string: type = str - species you want expected fluxes for. \"H  1\" for example, note the two spaces between H and 1.\n",
    "        wl_range: type = list - [shortest wavelength, longest wavelength] representing the range we are interested in (in meters)\n",
    "    Returns:\n",
    "        list: List of lists, each containing [species, wavelength, flux1, flux2, ...]\n",
    "    \"\"\"\n",
    "    filename = f'{model_name}.out'\n",
    "    results = []\n",
    "    iteration_pattern = re.compile(r'Iteration\\s+(\\d+)\\s+of\\s+(\\d+)')\n",
    "    final_iteration = False\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            if not final_iteration:\n",
    "                iteration_match = iteration_pattern.search(line)\n",
    "                if iteration_match:\n",
    "                    n, m = iteration_match.groups()\n",
    "                    if n == m:\n",
    "                        final_iteration = True\n",
    "                continue  # Skip processing until we find the iteration line\n",
    "            # Find all matches of the pattern in the current line\n",
    "            if target_string in line:\n",
    "                start = line.index(target_string)\n",
    "                remaining = line[start + len(target_string):].strip()\n",
    "                parts = remaining.split()\n",
    "    \n",
    "                if len(parts) >= 2:\n",
    "                    species = target_string.replace(\" \", \"\")  # → \"H1\"\n",
    "                    wavelength = parts[0]\n",
    "                    flux = parts[1]\n",
    "                    flux_norm = parts[2]\n",
    "                    if ((type(try_float(flux_norm)) == float) & (type(try_float(flux)) == float) & (type(try_float(wavelength[:-1])) == float)):\n",
    "                        results.append([species, wavelength, flux, flux_norm, i])\n",
    "    wavelengths = []\n",
    "    relative_fluxes = []\n",
    "    for row in results:\n",
    "        wavelength_str = row[1]\n",
    "        if 'm' in wavelength_str:  # Convert meters to Angstroms\n",
    "            wavelength = float(wavelength_str.replace('m', '')) * 1e-6\n",
    "        elif 'A' in wavelength_str:  # Already in Angstroms\n",
    "            wavelength = float(wavelength_str.replace('A', '')) * 1e-10\n",
    "        else:  # Assume Angstroms if no unit\n",
    "            wavelength = float(wavelength_str)\n",
    "        if ((wavelength > wl_range[0]) & (wavelength < wl_range[1])):\n",
    "                \n",
    "            # Extract relative flux (4th column)\n",
    "            relative_flux = float(row[3])\n",
    "            \n",
    "            wavelengths.append(wavelength)\n",
    "            relative_fluxes.append(relative_flux)\n",
    "            \n",
    "    return {\n",
    "        'wavelength': np.array(wavelengths),\n",
    "        'relative_flux': np.array(relative_fluxes)\n",
    "        }    \n",
    "\n",
    "data = parse_emission_lines('052325_trial1', 'H  1', [0.96e-6, 28.095e-6])\n",
    "plt.scatter(data['wavelength'], data['relative_flux'], s = 1)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt 05/23/2025\n",
    "def print_output_file(model_name):\n",
    "    with open(f'{model_name}.out', 'r') as f:\n",
    "        print(f.read())\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_emission_lines(model_name, target_string):\n",
    "    \"\"\"\n",
    "    Parse a file and extract emission line data matching the pattern:\n",
    "    [Capital letter][optional lowercase letter] space integer (e.g., H 1 or N 5)\n",
    "    followed by wavelength, flux values, etc.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the file to parse\n",
    "        \n",
    "    Returns:\n",
    "        list: List of lists, each containing [species, wavelength, flux1, flux2, ...]\n",
    "    \"\"\"\n",
    "    filename = f'{model_name}.out'\n",
    "    results = []\n",
    "    iteration_pattern = re.compile(r'Iteration\\s+(\\d+)\\s+of\\s+(\\d+)')\n",
    "    final_iteration = False\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            if not final_iteration:\n",
    "                iteration_match = iteration_pattern.search(line)\n",
    "                if iteration_match:\n",
    "                    n, m = iteration_match.groups()\n",
    "                    if n == m:\n",
    "                        final_iteration = True\n",
    "                continue  # Skip processing until we find the iteration line\n",
    "            # Find all matches of the pattern in the current line\n",
    "            if target_string in line:\n",
    "                start = line.index(target_string)\n",
    "                remaining = line[start + len(target_string):].strip()\n",
    "                parts = remaining.split()\n",
    "    \n",
    "                if len(parts) >= 2:\n",
    "                    species = target_string.replace(\" \", \"\")  # → \"H1\"\n",
    "                    wavelength = parts[0]\n",
    "                    flux = parts[1]\n",
    "                    results.append([species, wavelength, flux, i])\n",
    "\n",
    "                    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# results = parse_emission_lines('your_file.txt')\n",
    "# for entry in results:\n",
    "#     print(entry)\n",
    "    \n",
    "def write_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter -2\\n')\n",
    "        f.write(f'table SED \"fsps_iso.ascii\"\\n')\n",
    "        f.write(f'hden 3\\n')\n",
    "        f.write(f'cmb\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature 2 K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]\\n')\n",
    "        f.write('set temperature floor 2.73\\n')\n",
    "        f.write('set nchrg 2\\n')\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('save lines, array \"hydrogen_lines.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ISM abundance scaling 1.5\\n')\n",
    "        f.write('save lines, array \"052325_trial1.dat\" \"H  1\" no extinction\\n')\n",
    "    return input_file.split('.i')[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_name = '052325_trial1'\n",
    "    cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "    \n",
    "    cloudy_input_file = write_CLOUDY_input_file()\n",
    "    print(cloudy_input_file)\n",
    "    os.system(f'{cloudy_path} -r {model_name}')\n",
    "    print(model_name)\n",
    "    h1_array = parse_emission_lines(model_name, \"H  1\")\n",
    "    h1_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = 'Data_files/intrat.out_1e3_8e3'\n",
    "    lines_output_file = 'Data_files/observed_lines_wavelengths.txt'\n",
    "    obs_fluxes_file = 'Data_files/observed_fluxes.txt'\n",
    "    obs_WL = []\n",
    "    obs_fluxes = []\n",
    "    with open(input_file, 'r') as f_in, open(lines_output_file, 'w') as f_lines_out, open(obs_fluxes_file, 'w') as f_fluxes_out:\n",
    "        lines = f_in.readlines()[3:]  # Skip the first 3 header lines\n",
    "        for line in lines:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                parts = line.strip().split()  \n",
    "                wl_microns = float(parts[0])\n",
    "                wl_angstroms = wl_microns * 1e4\n",
    "                obs_WL.append(wl_angstroms)\n",
    "                flux = float(parts[1])\n",
    "                obs_fluxes.append(flux)\n",
    "                f_fluxes_out.write(f'{flux}\\n')\n",
    "                f_lines_out.write(f'H  1 {wl_angstroms:.2f}\\n')\n",
    "    plt.scatter(obs_WL, obs_fluxes, s=1)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('flux\\n(ergs/cm3/s)')\n",
    "    plt.xlabel('wavelength\\n(angstroms)')\n",
    "    plt.title('Observed fluxes for all detected hydrogen lines')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_file(model_name):\n",
    "    with open(f'{model_name}.out', 'r') as f:\n",
    "        print(f.read())\n",
    "    return None\n",
    "def write_vary_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter {ionization_param}\\n')\n",
    "        f.write(f'blackbody {temperature} vary\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "        f.write('optimize lines intrinsic\\n')\n",
    "        \n",
    "        f.write(f'H  1 0.954861m intensity = {5.615E-27/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.005215m intensity = {8.533E-27/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.094112m intensity = {1.397E-26/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.282163m intensity = {2.544E-26/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.875621m intensity = {5.368E-26/normalize_to}\\n')\n",
    "        \n",
    "        f.write('end of lines\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        #stop condition ionizstion frac 10^-3\n",
    "        #c_input.set_stop(stop_criter=('efrac -3.0','temperature 1'))\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write('save lines, array \"hydrogen_lines.dat\" \"H 1\"\\n')\n",
    "        f.write('save lines list \"Simulated_lines.lin\" \"Data_files/observed_lines_wavelengths.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "\n",
    "\n",
    "def write_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter {ionization_param}\\n')\n",
    "        f.write(f'blackbody {temperature}\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write('save lines, array \"hydrogen_lines.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        f.write('save lines list \"Simulated_lines.lin\" \"Data_files/observed_lines_wavelengths.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = 'Data_files/intrat.out_1e3_8e3'\n",
    "    lines_output_file = 'Data_files/observed_lines_wavelengths.txt'\n",
    "    obs_fluxes_file = 'Data_files/observed_fluxes.txt'\n",
    "    obs_WL = []\n",
    "    obs_fluxes = []\n",
    "    with open(input_file, 'r') as f_in, open(lines_output_file, 'w') as f_lines_out, open(obs_fluxes_file, 'w') as f_fluxes_out:\n",
    "        lines = f_in.readlines()[3:]  # Skip the first 3 header lines\n",
    "        for line in lines:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                parts = line.strip().split()  \n",
    "                wl_microns = float(parts[0])\n",
    "                wl_angstroms = wl_microns * 1e4\n",
    "                obs_WL.append(wl_angstroms)\n",
    "                flux = float(parts[1])\n",
    "                obs_fluxes.append(flux)\n",
    "                f_fluxes_out.write(f'{flux}\\n')\n",
    "                f_lines_out.write(f'H  1 {wl_angstroms:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get optimal temp to reproduce fluxes\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = 'zCLOUDY_vary_temp'\n",
    "    cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "    \n",
    "    #Define model parameters\n",
    "    temperature = 12000\n",
    "    stop_temp = 10\n",
    "    e_density = np.log10(1000) #in n/cm^3\n",
    "    e_temp = 8000 #in kelvin\n",
    "    ionization_param = -2\n",
    "    stop_thickness = '100 pc'\n",
    "    h_density = 3\n",
    "    normalize_to = 5.368E-26\n",
    "    \n",
    "    \n",
    "    \n",
    "    cloudy_input_file = write_vary_CLOUDY_input_file()\n",
    "    os.system(f'{cloudy_path} -r {model_name}')\n",
    "    \n",
    "    os.system(f'{cloudy_path} -r optimal')\n",
    "    \n",
    "    read_output_file(\"optimal\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run with set parameters\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = 'zCLOUDY_12k_temp'\n",
    "    #Define model parameters\n",
    "    temperature = 12000\n",
    "    stop_temp = 10\n",
    "    e_density = np.log10(1000) #in n/cm^3\n",
    "    e_temp = 8000 #in kelvin\n",
    "    ionization_param = -2\n",
    "    stop_thickness = '100 pc'\n",
    "    h_density = 3\n",
    "    normalize_to = 5.368E-26\n",
    "    \n",
    "    cloudy_input_file = write_CLOUDY_input_file()\n",
    "    os.system(f'{cloudy_path} -r {model_name}')\n",
    "    \n",
    "    read_output_file(model_name)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(1.0000*normalize_to)\n",
    "    print(0.4836*normalize_to)\n",
    "    print(0.2634*normalize_to)\n",
    "    print(0.1601*normalize_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'Simulated_lines.lin'\n",
    "\n",
    "with open(output_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split('\\t')\n",
    "        for part in parts:\n",
    "            print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Data_files/intrat.out_1e3_8e3'\n",
    "lines_output_file = 'Data_files/observed_lines_wavelengths.txt'\n",
    "obs_fluxes_file = 'Data_files/observed_fluxes.txt'\n",
    "obs_WL = []\n",
    "obs_fluxes = []\n",
    "with open(input_file, 'r') as f_in, open(lines_output_file, 'w') as f_lines_out, open(obs_fluxes_file, 'w') as f_fluxes_out:\n",
    "    lines = f_in.readlines()[3:]  # Skip the first 3 header lines\n",
    "    for line in lines:\n",
    "        if line.strip():  # Skip empty lines\n",
    "            parts = line.strip().split()  \n",
    "            wl_microns = float(parts[0])\n",
    "            wl_angstroms = wl_microns * 1e4\n",
    "            obs_WL.append(wl_angstroms)\n",
    "            flux = float(parts[1])\n",
    "            obs_fluxes.append(flux)\n",
    "            f_fluxes_out.write(f'{flux}\\n')\n",
    "            f_lines_out.write(f'H  1 {wl_angstroms:.2f}\\n')\n",
    "\n",
    "z = 0.0017\n",
    "rest_wl = np.array(obs_WL)/(1+z)\n",
    "rest_wl\n",
    "norm_fluxes = np.array(obs_fluxes)/obs_fluxes[4]\n",
    "\n",
    "plt.scatter(rest_wl, norm_fluxes, s=1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('flux\\n(ergs/cm3/s)')\n",
    "plt.xlabel('wavelength\\n(angstroms)')\n",
    "plt.title('Observed fluxes for all detected hydrogen lines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing for Daniella\n",
    "def extract_flux(file_path, target_wl):\n",
    "    fluxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if target_wl in parts:\n",
    "                # Once you find the wavelength, decide which column has the flux\n",
    "                # Assuming flux is the number *immediately following* the target\n",
    "                index = parts.index(target_wl)\n",
    "                try:\n",
    "                    flux = float(parts[index + 2])\n",
    "                    fluxes.append(flux)\n",
    "                except (IndexError, ValueError):\n",
    "                    raise ValueError(f\"Flux value could not be read after {target_wl} in {file_path}\")\n",
    "        return np.mean(fluxes)\n",
    "    raise ValueError(f\"Wavelength {target_wl} not found in {file_path}\")\n",
    "def write_CLOUDY_input_file(temperature, ion):\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter {ion}\\n')\n",
    "        f.write(f'blackbody {temperature}\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write(f'save lines, array \"{model_name}.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        #f.write(f'save lines list \"{model_name}_sim_lines.lin\" \"{model_name}_ratio.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for temperature in np.linspace(8000, 10000, 3):\n",
    "    for ion_par in np.linspace(-3,-2, 3):\n",
    "        \n",
    "            \n",
    "        model_name = f'Daniella_test_t{int(np.round(temperature/1000))}_i{int(np.round(ion_par*10))}'\n",
    "        cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "        \n",
    "        #Define model parameters\n",
    "        stop_temp = 10\n",
    "        e_density = np.log10(10000) #in n/cm^3\n",
    "        e_temp = 10000 #in kelvin\n",
    "        stop_thickness = '100 pc'\n",
    "        h_density = 3\n",
    "        normalize_to = 5.368E-26\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        cloudy_input_file = write_CLOUDY_input_file(temperature,ion_par)\n",
    "        os.system(f'{cloudy_path} -r {model_name}')\n",
    "        \n",
    "        print(f\"{temperature, ion_par}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = '1.87510m'\n",
    "files = glob.glob('Dan*.out')\n",
    "print(files)\n",
    "for fil in files:\n",
    "    print(fil, 1/extract_flux(fil, wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter \\n')\n",
    "        f.write(f'blackbody {temperature}\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write(f'save lines, array \"{model_name}.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        #f.write(f'save lines list \"{model_name}_sim_lines.lin\" \"{model_name}_ratio.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "\n",
    "model_name = f'Daniella_test_t{int(np.round(temperature/1000))}_i{int(np.round(ion_par*10))}'\n",
    "cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "\n",
    "#Define model parameters\n",
    "stop_temp = 10\n",
    "e_density = np.log10(10000) #in n/cm^3\n",
    "e_temp = 10000 #in kelvin\n",
    "stop_thickness = '100 pc'\n",
    "h_density = 3\n",
    "normalize_to = 5.368E-26\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cloudy_input_file = write_CLOUDY_input_file(temperature,ion_par)\n",
    "os.system(f'{cloudy_path} -r {model_name}')\n",
    "\n",
    "print(f\"{temperature, ion_par}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
