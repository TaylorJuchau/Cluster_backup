{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5793dac4-261c-4271-a06c-7d24100156da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyCloudy as pc\n",
    "import pyneb\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) #TJ change directory to include the entire ASTRO5160 directory\n",
    "from Py_files.Basic_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38860ef2-7922-4efe-91f8-1d9906cf735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/d/ret1/Taylor/jupyter_notebooks/Research/CLOUDY_stuff'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad894dc-6b83-4100-8985-bda7bbee410f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '052325_trial1.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 65\u001b[0m\n\u001b[1;32m     58\u001b[0m             relative_fluxes\u001b[38;5;241m.\u001b[39mappend(relative_flux)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavelength\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(wavelengths),\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_flux\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(relative_fluxes)\n\u001b[1;32m     63\u001b[0m         }    \n\u001b[0;32m---> 65\u001b[0m data \u001b[38;5;241m=\u001b[39m parse_emission_lines(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m052325_trial1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH  1\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0.96e-6\u001b[39m, \u001b[38;5;241m28.095e-6\u001b[39m])\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavelength\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_flux\u001b[39m\u001b[38;5;124m'\u001b[39m], s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39myscale(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mparse_emission_lines\u001b[0;34m(model_name, target_string, wl_range)\u001b[0m\n\u001b[1;32m     16\u001b[0m iteration_pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+of\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m final_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(file):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m final_iteration:\n",
      "File \u001b[0;32m/usr/local/Anaconda2024/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '052325_trial1.out'"
     ]
    }
   ],
   "source": [
    "def parse_emission_lines(model_name, target_string, wl_range):\n",
    "    \"\"\"\n",
    "    Parse a file and extract emission line data matching the pattern:\n",
    "    [Capital letter][optional lowercase letter] space integer (e.g., H  1 or He 2)\n",
    "    followed by wavelength, flux values, etc.\n",
    "    \n",
    "    Args:\n",
    "        model_name: type = str - model_name used to find the output file you want to parse\n",
    "        target_string: type = str - species you want expected fluxes for. \"H  1\" for example, note the two spaces between H and 1.\n",
    "        wl_range: type = list - [shortest wavelength, longest wavelength] representing the range we are interested in (in meters)\n",
    "    Returns:\n",
    "        list: List of lists, each containing [species, wavelength, flux1, flux2, ...]\n",
    "    \"\"\"\n",
    "    filename = f'{model_name}.out'\n",
    "    results = []\n",
    "    iteration_pattern = re.compile(r'Iteration\\s+(\\d+)\\s+of\\s+(\\d+)')\n",
    "    final_iteration = False\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            if not final_iteration:\n",
    "                iteration_match = iteration_pattern.search(line)\n",
    "                if iteration_match:\n",
    "                    n, m = iteration_match.groups()\n",
    "                    if n == m:\n",
    "                        final_iteration = True\n",
    "                continue  # Skip processing until we find the iteration line\n",
    "            # Find all matches of the pattern in the current line\n",
    "            if target_string in line:\n",
    "                start = line.index(target_string)\n",
    "                remaining = line[start + len(target_string):].strip()\n",
    "                parts = remaining.split()\n",
    "    \n",
    "                if len(parts) >= 2:\n",
    "                    species = target_string.replace(\" \", \"\")  # → \"H1\"\n",
    "                    wavelength = parts[0]\n",
    "                    flux = parts[1]\n",
    "                    flux_norm = parts[2]\n",
    "                    if ((type(try_float(flux_norm)) == float) & (type(try_float(flux)) == float) & (type(try_float(wavelength[:-1])) == float)):\n",
    "                        results.append([species, wavelength, flux, flux_norm, i])\n",
    "    wavelengths = []\n",
    "    relative_fluxes = []\n",
    "    for row in results:\n",
    "        wavelength_str = row[1]\n",
    "        if 'm' in wavelength_str:  # Convert meters to Angstroms\n",
    "            wavelength = float(wavelength_str.replace('m', '')) * 1e-6\n",
    "        elif 'A' in wavelength_str:  # Already in Angstroms\n",
    "            wavelength = float(wavelength_str.replace('A', '')) * 1e-10\n",
    "        else:  # Assume Angstroms if no unit\n",
    "            wavelength = float(wavelength_str)\n",
    "        if ((wavelength > wl_range[0]) & (wavelength < wl_range[1])):\n",
    "                \n",
    "            # Extract relative flux (4th column)\n",
    "            relative_flux = float(row[3])\n",
    "            \n",
    "            wavelengths.append(wavelength)\n",
    "            relative_fluxes.append(relative_flux)\n",
    "            \n",
    "    return {\n",
    "        'wavelength': np.array(wavelengths),\n",
    "        'relative_flux': np.array(relative_fluxes)\n",
    "        }    \n",
    "\n",
    "data = parse_emission_lines('052325_trial1', 'H  1', [0.96e-6, 28.095e-6])\n",
    "plt.scatter(data['wavelength'], data['relative_flux'], s = 1)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18519dc8-f06d-4c14-b38f-f720b82a1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt 05/23/2025\n",
    "def print_output_file(model_name):\n",
    "    with open(f'{model_name}.out', 'r') as f:\n",
    "        print(f.read())\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_emission_lines(model_name, target_string):\n",
    "    \"\"\"\n",
    "    Parse a file and extract emission line data matching the pattern:\n",
    "    [Capital letter][optional lowercase letter] space integer (e.g., H 1 or N 5)\n",
    "    followed by wavelength, flux values, etc.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the file to parse\n",
    "        \n",
    "    Returns:\n",
    "        list: List of lists, each containing [species, wavelength, flux1, flux2, ...]\n",
    "    \"\"\"\n",
    "    filename = f'{model_name}.out'\n",
    "    results = []\n",
    "    iteration_pattern = re.compile(r'Iteration\\s+(\\d+)\\s+of\\s+(\\d+)')\n",
    "    final_iteration = False\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            if not final_iteration:\n",
    "                iteration_match = iteration_pattern.search(line)\n",
    "                if iteration_match:\n",
    "                    n, m = iteration_match.groups()\n",
    "                    if n == m:\n",
    "                        final_iteration = True\n",
    "                continue  # Skip processing until we find the iteration line\n",
    "            # Find all matches of the pattern in the current line\n",
    "            if target_string in line:\n",
    "                start = line.index(target_string)\n",
    "                remaining = line[start + len(target_string):].strip()\n",
    "                parts = remaining.split()\n",
    "    \n",
    "                if len(parts) >= 2:\n",
    "                    species = target_string.replace(\" \", \"\")  # → \"H1\"\n",
    "                    wavelength = parts[0]\n",
    "                    flux = parts[1]\n",
    "                    results.append([species, wavelength, flux, i])\n",
    "\n",
    "                    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# results = parse_emission_lines('your_file.txt')\n",
    "# for entry in results:\n",
    "#     print(entry)\n",
    "    \n",
    "def write_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter -2\\n')\n",
    "        f.write(f'table SED \"fsps_iso.ascii\"\\n')\n",
    "        f.write(f'hden 3\\n')\n",
    "        f.write(f'cmb\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature 2 K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]\\n')\n",
    "        f.write('set temperature floor 2.73\\n')\n",
    "        f.write('set nchrg 2\\n')\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('save lines, array \"hydrogen_lines.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ISM abundance scaling 1.5\\n')\n",
    "        f.write('save lines, array \"052325_trial1.dat\" \"H  1\" no extinction\\n')\n",
    "    return input_file.split('.i')[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f737c-2d1e-4fee-97e5-840f530eace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_name = '052325_trial1'\n",
    "    cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "    \n",
    "    cloudy_input_file = write_CLOUDY_input_file()\n",
    "    print(cloudy_input_file)\n",
    "    os.system(f'{cloudy_path} -r {model_name}')\n",
    "    print(model_name)\n",
    "    h1_array = parse_emission_lines(model_name, \"H  1\")\n",
    "    h1_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421282eb-9fc3-4a5b-ae9b-1103212b3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a044d-8c7e-4eb2-b6c5-5c0e07629979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = 'Data_files/intrat.out_1e3_8e3'\n",
    "    lines_output_file = 'Data_files/observed_lines_wavelengths.txt'\n",
    "    obs_fluxes_file = 'Data_files/observed_fluxes.txt'\n",
    "    obs_WL = []\n",
    "    obs_fluxes = []\n",
    "    with open(input_file, 'r') as f_in, open(lines_output_file, 'w') as f_lines_out, open(obs_fluxes_file, 'w') as f_fluxes_out:\n",
    "        lines = f_in.readlines()[3:]  # Skip the first 3 header lines\n",
    "        for line in lines:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                parts = line.strip().split()  \n",
    "                wl_microns = float(parts[0])\n",
    "                wl_angstroms = wl_microns * 1e4\n",
    "                obs_WL.append(wl_angstroms)\n",
    "                flux = float(parts[1])\n",
    "                obs_fluxes.append(flux)\n",
    "                f_fluxes_out.write(f'{flux}\\n')\n",
    "                f_lines_out.write(f'H  1 {wl_angstroms:.2f}\\n')\n",
    "    plt.scatter(obs_WL, obs_fluxes, s=1)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('flux\\n(ergs/cm3/s)')\n",
    "    plt.xlabel('wavelength\\n(angstroms)')\n",
    "    plt.title('Observed fluxes for all detected hydrogen lines')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd28cac-883e-436a-997f-bb5046eac601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_file(model_name):\n",
    "    with open(f'{model_name}.out', 'r') as f:\n",
    "        print(f.read())\n",
    "    return None\n",
    "def write_vary_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter {ionization_param}\\n')\n",
    "        f.write(f'blackbody {temperature} vary\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "        f.write('optimize lines intrinsic\\n')\n",
    "        \n",
    "        f.write(f'H  1 0.954861m intensity = {5.615E-27/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.005215m intensity = {8.533E-27/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.094112m intensity = {1.397E-26/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.282163m intensity = {2.544E-26/normalize_to}\\n')\n",
    "        f.write(f'H  1 1.875621m intensity = {5.368E-26/normalize_to}\\n')\n",
    "        \n",
    "        f.write('end of lines\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        #stop condition ionizstion frac 10^-3\n",
    "        #c_input.set_stop(stop_criter=('efrac -3.0','temperature 1'))\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write('save lines, array \"hydrogen_lines.dat\" \"H 1\"\\n')\n",
    "        f.write('save lines list \"Simulated_lines.lin\" \"Data_files/observed_lines_wavelengths.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "\n",
    "\n",
    "def write_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter {ionization_param}\\n')\n",
    "        f.write(f'blackbody {temperature}\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write('save lines, array \"hydrogen_lines.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        f.write('save lines list \"Simulated_lines.lin\" \"Data_files/observed_lines_wavelengths.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd3919-8287-4bcf-b53a-265126e949be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = 'Data_files/intrat.out_1e3_8e3'\n",
    "    lines_output_file = 'Data_files/observed_lines_wavelengths.txt'\n",
    "    obs_fluxes_file = 'Data_files/observed_fluxes.txt'\n",
    "    obs_WL = []\n",
    "    obs_fluxes = []\n",
    "    with open(input_file, 'r') as f_in, open(lines_output_file, 'w') as f_lines_out, open(obs_fluxes_file, 'w') as f_fluxes_out:\n",
    "        lines = f_in.readlines()[3:]  # Skip the first 3 header lines\n",
    "        for line in lines:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                parts = line.strip().split()  \n",
    "                wl_microns = float(parts[0])\n",
    "                wl_angstroms = wl_microns * 1e4\n",
    "                obs_WL.append(wl_angstroms)\n",
    "                flux = float(parts[1])\n",
    "                obs_fluxes.append(flux)\n",
    "                f_fluxes_out.write(f'{flux}\\n')\n",
    "                f_lines_out.write(f'H  1 {wl_angstroms:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca08079-c40b-4928-a96a-10c7ee68b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get optimal temp to reproduce fluxes\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = 'zCLOUDY_vary_temp'\n",
    "    cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "    \n",
    "    #Define model parameters\n",
    "    temperature = 12000\n",
    "    stop_temp = 10\n",
    "    e_density = np.log10(1000) #in n/cm^3\n",
    "    e_temp = 8000 #in kelvin\n",
    "    ionization_param = -2\n",
    "    stop_thickness = '100 pc'\n",
    "    h_density = 3\n",
    "    normalize_to = 5.368E-26\n",
    "    \n",
    "    \n",
    "    \n",
    "    cloudy_input_file = write_vary_CLOUDY_input_file()\n",
    "    os.system(f'{cloudy_path} -r {model_name}')\n",
    "    \n",
    "    os.system(f'{cloudy_path} -r optimal')\n",
    "    \n",
    "    read_output_file(\"optimal\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d90c3-f009-48cd-b0ab-134152d512b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run with set parameters\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = 'zCLOUDY_12k_temp'\n",
    "    #Define model parameters\n",
    "    temperature = 12000\n",
    "    stop_temp = 10\n",
    "    e_density = np.log10(1000) #in n/cm^3\n",
    "    e_temp = 8000 #in kelvin\n",
    "    ionization_param = -2\n",
    "    stop_thickness = '100 pc'\n",
    "    h_density = 3\n",
    "    normalize_to = 5.368E-26\n",
    "    \n",
    "    cloudy_input_file = write_CLOUDY_input_file()\n",
    "    os.system(f'{cloudy_path} -r {model_name}')\n",
    "    \n",
    "    read_output_file(model_name)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532a092-d716-41f9-8b2a-fa0e0cb465a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4bb93-cf83-4775-afb4-b890d8fb07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(1.0000*normalize_to)\n",
    "    print(0.4836*normalize_to)\n",
    "    print(0.2634*normalize_to)\n",
    "    print(0.1601*normalize_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487be629-e631-42d4-bcf2-23b963f5b858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b5426-8e3f-4661-9998-5d438fbb7b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file = 'Simulated_lines.lin'\n",
    "\n",
    "with open(output_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split('\\t')\n",
    "        for part in parts:\n",
    "            print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa44b0-bc71-4a97-a206-24666edd5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Data_files/intrat.out_1e3_8e3'\n",
    "lines_output_file = 'Data_files/observed_lines_wavelengths.txt'\n",
    "obs_fluxes_file = 'Data_files/observed_fluxes.txt'\n",
    "obs_WL = []\n",
    "obs_fluxes = []\n",
    "with open(input_file, 'r') as f_in, open(lines_output_file, 'w') as f_lines_out, open(obs_fluxes_file, 'w') as f_fluxes_out:\n",
    "    lines = f_in.readlines()[3:]  # Skip the first 3 header lines\n",
    "    for line in lines:\n",
    "        if line.strip():  # Skip empty lines\n",
    "            parts = line.strip().split()  \n",
    "            wl_microns = float(parts[0])\n",
    "            wl_angstroms = wl_microns * 1e4\n",
    "            obs_WL.append(wl_angstroms)\n",
    "            flux = float(parts[1])\n",
    "            obs_fluxes.append(flux)\n",
    "            f_fluxes_out.write(f'{flux}\\n')\n",
    "            f_lines_out.write(f'H  1 {wl_angstroms:.2f}\\n')\n",
    "\n",
    "z = 0.0017\n",
    "rest_wl = np.array(obs_WL)/(1+z)\n",
    "rest_wl\n",
    "norm_fluxes = np.array(obs_fluxes)/obs_fluxes[4]\n",
    "\n",
    "plt.scatter(rest_wl, norm_fluxes, s=1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('flux\\n(ergs/cm3/s)')\n",
    "plt.xlabel('wavelength\\n(angstroms)')\n",
    "plt.title('Observed fluxes for all detected hydrogen lines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69069145-3b84-4d16-ace8-a03fc9e16840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aee112-3f58-44ca-995a-ce9107883752",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing for Daniella\n",
    "def extract_flux(file_path, target_wl):\n",
    "    fluxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if target_wl in parts:\n",
    "                # Once you find the wavelength, decide which column has the flux\n",
    "                # Assuming flux is the number *immediately following* the target\n",
    "                index = parts.index(target_wl)\n",
    "                try:\n",
    "                    flux = float(parts[index + 2])\n",
    "                    fluxes.append(flux)\n",
    "                except (IndexError, ValueError):\n",
    "                    raise ValueError(f\"Flux value could not be read after {target_wl} in {file_path}\")\n",
    "        return np.mean(fluxes)\n",
    "    raise ValueError(f\"Wavelength {target_wl} not found in {file_path}\")\n",
    "def write_CLOUDY_input_file(temperature, ion):\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter {ion}\\n')\n",
    "        f.write(f'blackbody {temperature}\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write(f'save lines, array \"{model_name}.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        #f.write(f'save lines list \"{model_name}_sim_lines.lin\" \"{model_name}_ratio.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8fcec-71d5-42dc-adac-90afdc0194e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for temperature in np.linspace(8000, 10000, 3):\n",
    "    for ion_par in np.linspace(-3,-2, 3):\n",
    "        \n",
    "            \n",
    "        model_name = f'Daniella_test_t{int(np.round(temperature/1000))}_i{int(np.round(ion_par*10))}'\n",
    "        cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "        \n",
    "        #Define model parameters\n",
    "        stop_temp = 10\n",
    "        e_density = np.log10(10000) #in n/cm^3\n",
    "        e_temp = 10000 #in kelvin\n",
    "        stop_thickness = '100 pc'\n",
    "        h_density = 3\n",
    "        normalize_to = 5.368E-26\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        cloudy_input_file = write_CLOUDY_input_file(temperature,ion_par)\n",
    "        os.system(f'{cloudy_path} -r {model_name}')\n",
    "        \n",
    "        print(f\"{temperature, ion_par}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07adc4-91ee-4dcf-9d2d-051279fe9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = '1.87510m'\n",
    "files = glob.glob('Dan*.out')\n",
    "print(files)\n",
    "for fil in files:\n",
    "    print(fil, 1/extract_flux(fil, wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3f1dc-de0b-4b6e-bb70-a2e8da70a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_CLOUDY_input_file():\n",
    "    input_file = f\"{model_name}.in\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'title {model_name}\\n')\n",
    "        f.write(f'Ionization parameter \\n')\n",
    "        f.write(f'blackbody {temperature}\\n')\n",
    "        f.write(f'hden {h_density}\\n')\n",
    "        f.write('iterate to convergence\\n') \n",
    "        f.write(f'stop temperature {stop_temp} K\\n')  # Stop condition\n",
    "        f.write(f'stop neutral column density [0.1% of total H column]')\n",
    "\n",
    "        f.write('normalize to \"H  1\" 18756.21 angstroms\\n')  # Normalization to paschen\n",
    "        f.write('no level 2 lines\\n') # Case B only\n",
    "        f.write('abundances ism\\n')\n",
    "        f.write('atom H-like levels resolved 50\\n')\n",
    "        f.write(f'save lines, array \"{model_name}.dat\" \"H 1\"\\n')\n",
    "        f.write('grains ism\\n')\n",
    "        #f.write(f'save lines list \"{model_name}_sim_lines.lin\" \"{model_name}_ratio.txt\" no extinction\\n')\n",
    "        f.write(f'save overview \"{model_name}.ovr\"\\n')\n",
    "    return input_file\n",
    "\n",
    "model_name = f'Daniella_test_t{int(np.round(temperature/1000))}_i{int(np.round(ion_par*10))}'\n",
    "cloudy_path = \"/d/ret1/Taylor/CLOUDY/c23.01/source/cloudy.exe\"\n",
    "\n",
    "#Define model parameters\n",
    "stop_temp = 10\n",
    "e_density = np.log10(10000) #in n/cm^3\n",
    "e_temp = 10000 #in kelvin\n",
    "stop_thickness = '100 pc'\n",
    "h_density = 3\n",
    "normalize_to = 5.368E-26\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cloudy_input_file = write_CLOUDY_input_file(temperature,ion_par)\n",
    "os.system(f'{cloudy_path} -r {model_name}')\n",
    "\n",
    "print(f\"{temperature, ion_par}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb3c76-1b4a-4c4e-8e8f-cc0e4baa9d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
