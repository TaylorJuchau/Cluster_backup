{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #TJ ignore warnings (careful enabling this)\n",
    "\n",
    "home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "parent_dir = Path(home_directory).resolve() #TJ current notebook's parent directory\n",
    "os.chdir(parent_dir) #TJ change working directory to be the parent directory\n",
    "\n",
    "from Py_files.Basic_analysis import * #TJ import basic functions from custom package\n",
    "from Py_files.Convolution_script import * #TJ import convolution functions from custom package\n",
    "\n",
    "def load_and_sort_convolved_Karin_spectrum(file_path):\n",
    "    '''import data and sort by wavelength from very particularly structured file\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file_path : type = str - path to file with data\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    structured array ('wavelength', 'intensity', 'uncertainty') where intensity and uncertainty are in W/m2/Hz\n",
    "    '''    \n",
    "    with open(file_path, 'r') as file:\n",
    "        header = file.readline().strip().split()\n",
    "        #TJ check first line structure for compliance\n",
    "        if ((len(header) == 3) & (type(try_float(header[0])) == type(0.1)) & (type(try_float(header[1])) == type(0.1)) & (type(try_float(header[2])) == type(0.1))):\n",
    "            data_list = []\n",
    "            data_list.append((try_float(header[0])*1e-6, try_float(header[1])*1e-20, try_float(header[2])*1e-20))\n",
    "            aperture_area_sr = (np.pi * (((0.75*u.arcsec).to(u.rad))**2)).value\n",
    "            for line in file:\n",
    "                parts = line.strip().split(maxsplit=3)\n",
    "                \n",
    "                #TJ Convert numeric columns to floats\n",
    "                wavelength = float(parts[0])*1e-6 #TJ float required for sorting\n",
    "                intensity = try_float(parts[1])*1e-20 * aperture_area_sr\n",
    "                uncertainty = try_float(parts[2])*1e-20 * aperture_area_sr\n",
    "                \n",
    "                data_list.append((wavelength, intensity, uncertainty))\n",
    "        \n",
    "            #TJ Define dtype with notes as string\n",
    "            dtype = [\n",
    "                ('wavelength', float),\n",
    "                ('intensity', float),\n",
    "                ('uncertainty', float),\n",
    "            ]\n",
    "            \n",
    "            data = np.array(data_list, dtype=dtype)\n",
    "            sorted_data = np.sort(data, order=['wavelength'])  #TJ Sort by wavelength\n",
    "            \n",
    "            return sorted_data\n",
    "        else:\n",
    "            print('''File format is not as expected. Should be 3 columns no header, if not, see \"import_data_and_sort_by_wavelength\"\n",
    "            function from Flux_calibration notebook''')\n",
    "            return None\n",
    "\n",
    "\n",
    "def extract_filter_name(filename):\n",
    "    '''extract entire filter name, for example: F164N\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file_name : type = str - name of filter's fits file of format similar to ngc5194_nircam_1v3_f164n_i2d.fits\n",
    "        *note*: function keys on the \"_\" and .fits to get filter name, requires lower case filter names, see generalized \"sort_filters\" function\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    filter name as string\n",
    "    '''   \n",
    "    # For .fits files: ngc5194_nircam_1v3_f164n_i2d.fits → \"f164n\"\n",
    "    if filename.endswith('.fits'):\n",
    "        parts = os.path.basename(filename).split('_')\n",
    "        for part in parts:\n",
    "            if part.startswith('f') and part[1:].replace('n', '').replace('w', '').replace('m', '').isdigit():\n",
    "                return part.lower()\n",
    "    # For .dat files: F070M.dat → \"f070m\"\n",
    "    elif filename.endswith('.dat'):\n",
    "        return os.path.splitext(os.path.basename(filename))[0].lower()\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_list_of_files():\n",
    "    '''cross-matches files in filter_directory to filters with images in image_directory, sorts by filter number\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    none \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    list of arrays, first entry is the image file array, second is the filter file array, both sorted by filter numer (in name)\n",
    "    '''   \n",
    "    filter_directory = '/d/crow1/tools/cigale/database_builder/filters/jwst/'\n",
    "    path = ['nircam', 'miri']\n",
    "    filter_files = np.concatenate([glob.glob(os.path.join(filter_directory + file_path, \"*.dat\")) for file_path in path])\n",
    "    image_directory = 'Data_files/Image_files'\n",
    "    image_files = glob.glob(os.path.join(image_directory, \"*.fits\"))\n",
    "    # Initialize aligned lists\n",
    "    image_file_array = []\n",
    "    filter_file_array = []\n",
    "    \n",
    "    # Loop through .fits files and find matching .dat files\n",
    "    for fits_file in image_files:\n",
    "        fits_filter = extract_filter_name(fits_file)\n",
    "        if not fits_filter:\n",
    "            continue  # Skip if no filter name found\n",
    "        \n",
    "        # Search for matching .dat file\n",
    "        for dat_file in filter_files:\n",
    "            dat_filter = extract_filter_name(dat_file)\n",
    "            if dat_filter == fits_filter:\n",
    "                image_file_array.append(fits_file)\n",
    "                filter_file_array.append(dat_file)\n",
    "                break  # Stop searching after first match\n",
    "    filter_name_array = [f.split(\"/\")[-1] for f in filter_file_array] #TJ generate array of just the filter names\n",
    "    filter_numbers = np.array([get_filter_number(file) for file in filter_name_array]) #TJ generate array of just filter numbers\n",
    "    sort_indices = np.argsort(filter_numbers) #TJ sort by these numbers\n",
    "    sorted_filter_names = np.array(filter_file_array)[sort_indices]\n",
    "    sorted_image_files = np.array(image_file_array)[sort_indices]\n",
    "    return sorted_image_files, sorted_filter_names\n",
    "\n",
    "def get_filter_number(filter_name):\n",
    "    '''extracts numbers from filter name (drops F, N, W, etc from the ends)\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter_files : type = list - list of filter names\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    filter name as string\n",
    "    '''   \n",
    "    match = re.search(r'[A-Za-z](\\d+)[A-Za-z]', filter_name)  # Numbers between ANY letters\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_Fnu_transmission(Fnu_array, wl_array, transmission_array, trans_wl_array):\n",
    "    '''get expected flux through filter in units of whatever the flux_array is. Make sure to convert to mks units\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    Fnu_array : type = array - array of flux density values\n",
    "    wl_array : type = array - array of wavelength values for the corresponding Fnu_array values (should be in meters)\n",
    "    transmission_array : type = array - array of unitless transmission coefficient\n",
    "    trans_wl_array : type = array - array of wavelength values for the corresponding transmission values (should be in meters)\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    total_flux : type = float - in units of flux_array\n",
    "    '''   \n",
    "    if ((trans_wl_array[0] < wl_array[0]) or (trans_wl_array[-1] > wl_array[-1])): #TJ Check if wavelengths are compatible with filter\n",
    "        print('wavelengths adjusted to not include full filter')\n",
    "        idx_start = np.searchsorted(trans_wl_array, wl_array[0], side='left')\n",
    "        idx_end = np.searchsorted(trans_wl_array, wl_array[-1], side='right')\n",
    "        \n",
    "        # Expand by one index if possible\n",
    "        idx_start = max(0, idx_start - 1)  # Include one lower index\n",
    "        idx_end = min(len(trans_wl_array), idx_end + 1)  # Include one higher index\n",
    "        \n",
    "        # Slice transmission data\n",
    "        trans_wl_array = trans_wl_array[idx_start:idx_end]\n",
    "        transmission_array = transmission_array[idx_start:idx_end]\n",
    "    if len(trans_wl_array) == 0:\n",
    "        raise ValueError(\"No overlap between flux wavelengths and filter transmission curve\")\n",
    "    #TJ convert all arrays to numpy arrays for better indexing\n",
    "    Fnu_array = np.array(Fnu_array)\n",
    "    wl_array = np.array(wl_array)\n",
    "    transmission_array = np.array(transmission_array)\n",
    "    trans_wl_array = np.array(trans_wl_array)\n",
    "\n",
    "    \n",
    "    #TJ Convert wavelength to frequency, reverse so freq increases left to right\n",
    "    spec_freq_array = c / wl_array[::-1]\n",
    "    Fnu_array = Fnu_array[::-1]\n",
    "    trans_freq_array = c / trans_wl_array[::-1]\n",
    "    transmission_array = transmission_array[::-1]\n",
    "\n",
    "    #TJ Interpolate Fnu onto the transmission frequency grid\n",
    "    #TJ this is because jwst transmission arrays are averages over BW widths which are much coarser than Fnu is.\n",
    "    \n",
    "    interp_Fnu = np.interp(trans_freq_array, spec_freq_array, Fnu_array)\n",
    "    \n",
    "    \n",
    "    weight = transmission_array / trans_freq_array #TJ weight the numerator and denominator by T *d_nu over nu for integration\n",
    "    numerator = np.trapz(interp_Fnu * weight, trans_freq_array)#TJ perform integration\n",
    "    denominator = np.trapz(weight, trans_freq_array)\n",
    "    ab_mean_flux = numerator / denominator\n",
    "    # Numerator: Fν * Transmission / nu integrated over frequency\n",
    "    \n",
    "    return ab_mean_flux.value\n",
    "\n",
    "\n",
    "\n",
    "def fake_missing_header_info(filepath):\n",
    "    '''WARNING!!! This will overwrite blank header fields permanently. If you want to retain those empty fields,\n",
    "        perform this function on a copy of the file\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filepath : type = str - string to location of IFU fits file\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    nothing, updates the fits file to have the fields 'DATE-BEG' 'MJD-BEG' 'DATE-END' 'MJD-END' 'XPOSURE' 'TELAPSE'\n",
    "    '''   \n",
    "    \n",
    "    with fits.open(filepath, mode='update') as hdul:\n",
    "        hdr = hdul['SCI'].header\n",
    "        \n",
    "        # Dictionary of default values (key: (value, comment))\n",
    "        defaults = {\n",
    "            'DATE-BEG': ('2000-01-01T00:00:00', 'Default observation start date'),\n",
    "            'MJD-BEG': (51544.0, 'Default MJD observation start'),\n",
    "            'DATE-END': ('2000-01-01T00:01:00', 'Default observation end date'),\n",
    "            'MJD-END': (51544.000694, 'Default MJD observation end'),\n",
    "            'XPOSURE': (60.0, 'Default exposure time [s]'),\n",
    "            'TELAPSE': (60.0, 'Default elapsed time [s]')\n",
    "        }\n",
    "        \n",
    "        # Only add missing keywords\n",
    "        for key, (value, comment) in defaults.items():\n",
    "            if key not in hdr:\n",
    "                hdr[key] = (value, comment)\n",
    "                print(f\"Added default {key} = {value}\")\n",
    "            else:\n",
    "                print(f\"Preserved existing {key} = {hdr[key]}\")\n",
    "        \n",
    "        # Special case: If DATE-BEG exists but MJD-BEG doesn't, compute it\n",
    "        if 'DATE-BEG' in hdr and 'MJD-BEG' not in hdr:\n",
    "            try:\n",
    "                t = Time(hdr['DATE-BEG'], format='isot')\n",
    "                hdr['MJD-BEG'] = (t.mjd, 'Computed from DATE-BEG')\n",
    "                print(f\"Computed MJD-BEG from DATE-BEG: {t.mjd}\")\n",
    "            except ValueError:\n",
    "                hdr['MJD-BEG'] = (51544.0, 'Fallback MJD value')\n",
    "        \n",
    "        # Similar for DATE-END/MJD-END\n",
    "        if 'DATE-END' in hdr and 'MJD-END' not in hdr:\n",
    "            try:\n",
    "                t = Time(hdr['DATE-END'], format='isot')\n",
    "                hdr['MJD-END'] = (t.mjd, 'Computed from DATE-END')\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "def get_IFU_spectrum(IFU_filepath, loc, radius):\n",
    "    '''extract spectrum from IFU file with aperature of radius, centered at ra,dec = loc\n",
    "    does not replace negative flux values\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    IFU_filepath : type = str - string to location of IFU fits file\n",
    "    loc : type = list - ra, dec in degrees or SkyCoord object\n",
    "    radius : type = float - radius of aperture, must have units attached (like u.deg or u.arcsecond)\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    structured array with entries for \"wavelength\" and \"intensity\"\n",
    "    '''   \n",
    "    #fake_missing_header_info(IFU_filepath) #TJ run this if needed\n",
    "    hdul = fits.open(IFU_filepath)\n",
    "    header = hdul['SCI'].header\n",
    "    wcs = WCS(header)\n",
    "    cube = SpectralCube.read(IFU_filepath, hdu='SCI')\n",
    "\n",
    "    # === CONVERT RA/DEC TO PIXEL COORDINATES ===\n",
    "    # Create SkyCoord object for spatial coordinates\n",
    "    if type(loc) == list:\n",
    "        spatial_coords = SkyCoord(ra=loc[0]*u.deg, dec=loc[1]*u.deg)\n",
    "    elif type(loc) == SkyCoord:\n",
    "        spatial_coords = loc\n",
    "    else:\n",
    "        print('loc is not a list of ra, dec and it is not a SkyCoord object.')\n",
    "        return None\n",
    "    \n",
    "    # Convert spatial coordinates to pixels\n",
    "    x, y = wcs.celestial.all_world2pix(spatial_coords.ra.deg, \n",
    "                                      spatial_coords.dec.deg, 0)\n",
    "    \n",
    "    # === BUILD APERTURE ===\n",
    "    if header['CDELT2'] != header['CDELT1']:\n",
    "        print('pixels are not square!  revisit get_IFU_spectrum() function to fix')\n",
    "        return None\n",
    "    cdelt = np.abs(header['CDELT2']) * u.deg\n",
    "    pixel_scale = cdelt.to(u.arcsec)  # arcsec/pixel\n",
    "    pix_area = header['PIXAR_SR'] #TJ pixel area in steradians\n",
    "    radius = radius.to(u.arcsec)\n",
    "    radius_pix = (radius / pixel_scale).value\n",
    "    aperture = CircularAperture((x, y), r=radius_pix)\n",
    "    aperture_area_sr = np.pi * (radius.to(u.rad))**2\n",
    "\n",
    "    # === CRITICAL UNIT HANDLING ===\n",
    "    cube = cube.with_spectral_unit(u.m)  # Ensure wavelength in meters\n",
    "    \n",
    "    # Convert flux units properly\n",
    "    # Step 1: MJy/sr → W/m²/Hz/sr\n",
    "    cube = cube.to(u.W/(u.m**2 * u.Hz * u.sr))  \n",
    "    \n",
    "    # Step 2: Multiply by pixel area to get W/m²/Hz/pixel\n",
    "    pix_area_sr = header['PIXAR_SR'] * u.sr\n",
    "    cube = cube * pix_area_sr\n",
    "    \n",
    "    # Step 3: Perform aperture sum (now in W/m²/Hz)\n",
    "    flux_density_spectrum = []\n",
    "    for i in range(len(cube.spectral_axis)):\n",
    "        image_slice = cube[i].value  # Now in W/m²/Hz\n",
    "        phot = aperture_photometry(image_slice, aperture)\n",
    "        flux_density_spectrum.append(phot['aperture_sum'][0])  # No extra multiplication!\n",
    "    wavelengths = cube.spectral_axis.to(u.m).value\n",
    "    flux_density_spectrum = np.array(flux_density_spectrum)\n",
    "\n",
    "    dtype = [('wavelength', 'f8'), ('intensity', 'f8')]\n",
    "    spectrum = np.zeros(len(cube.spectral_axis), dtype=dtype)\n",
    "    spectrum['wavelength'] = cube.spectral_axis.to(u.m).value\n",
    "    spectrum['intensity'] = np.array(flux_density_spectrum)\n",
    "\n",
    "    return spectrum\n",
    "\n",
    "\n",
    "def get_image_flux(image_file, loc, radius):\n",
    "    '''extract flux from image file with aperature of radius, centered at ra,dec = loc\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    image_file : type = str - string to location of image fits file\n",
    "    loc : type = list - ra, dec in degrees or SkyCoord object\n",
    "    radius : type = float - radius of aperture, must have units attached (like u.deg or u.arcsecond)\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    flux_density observed through filter\n",
    "    '''\n",
    "    #TJ assign location as SkyCoord object\n",
    "    if type(loc) == list:\n",
    "        spatial_coords = SkyCoord(ra=loc[0]*u.deg, dec=loc[1]*u.deg)\n",
    "    elif type(loc) == SkyCoord:\n",
    "        spatial_coords = loc\n",
    "    else:\n",
    "        print('loc is not a list of ra, dec and it is not a SkyCoord object.')\n",
    "        return None\n",
    "    hdul = fits.open(image_file) #TJ load file\n",
    "    data = hdul['SCI'].data*1e-20  #TJ convert flux density to mks units\n",
    "    header = hdul['SCI'].header #TJ load header\n",
    "    if header['BUNIT'] != 'MJy/sr': #TJ check if units are MJy/sr, output will be nonsensical if not\n",
    "        print('flux is NOT in MJy/sr. review get_image_flux function to fix')\n",
    "        return None\n",
    "    pix_area = header[\"PIXAR_SR\"] #TJ define the angular size of a pixel in staradians\n",
    "    wcs = WCS(header) #TJ read in the world coordinate system\n",
    "    radius_pixels = (radius).to_value(u.deg) / abs(header['CDELT2']) #TJ get the radius of the aperture in number of pixels\n",
    "    \n",
    "    #TJ Convert RA/Dec to pixel coordinates\n",
    "    x, y = wcs.all_world2pix(spatial_coords.ra.deg, spatial_coords.dec.deg, 0)\n",
    "    aperture = CircularAperture((x, y), r = radius_pixels)\n",
    "    \n",
    "    #TJ Perform aperture photometry\n",
    "    phot_result = aperture_photometry(data, aperture)\n",
    "    total_flux = phot_result['aperture_sum'][0]*pix_area  #TJ the result is in pixel units, multiply by steradians per pixel to get units right\n",
    "\n",
    "    return total_flux    \n",
    "\n",
    "def compare_IFU_to_image(IFU_filepath, image_filepath, filter_filepath, loc, radius):\n",
    "    '''extract spectrum from IFU file with aperature of radius, centered at ra,dec = loc using filter data (must be in meters)\n",
    "       extract total flux from image file for circle centered at loc with radius radius\n",
    "       compare the two.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    IFU_filepath : type = str - string to location of IFU fits file\n",
    "    image_filepath : type = str - string to location of image fits file\n",
    "    filter_filepath : type = list - first entry is an array of wavelengths (in m)\n",
    "    loc : type = list - ra, dec in degrees or SkyCoord object\n",
    "    radius : type = float - radius of aperture, must have units attached (like u.deg or u.arcsecond)\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    IFU predicted flux, image_extracted flux, ratio\n",
    "    '''   \n",
    "    IFU_hdul = fits.open(IFU_filepath)\n",
    "    IFU_data = IFU_hdul['SCI'].data  # flux in MJy/sr or μJy/arcsec²\n",
    "    IFU_header = IFU_hdul['SCI'].header\n",
    "    IFU_SED_data = get_IFU_spectrum(IFU_filepath, loc, radius)\n",
    "    aperture_area_sr = np.pi * (radius.to(u.rad))**2\n",
    "    filter_data = []\n",
    "    with open(filter_filepath, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    \n",
    "    print('IFU', IFU_SED_data[\"wavelength\"][0], IFU_SED_data[\"wavelength\"][-1])\n",
    "    print('filter', filter_wl[0], filter_wl[-1])\n",
    "    \n",
    "    IFU_expected_flux = ((get_Fnu_transmission(IFU_SED_data[\"intensity\"], IFU_SED_data[\"wavelength\"], filter_trans, filter_wl)))\n",
    "    photo_flux = (get_image_flux(image_filepath, loc, radius))\n",
    "    if IFU_expected_flux:\n",
    "        return IFU_expected_flux, photo_flux, IFU_expected_flux/photo_flux\n",
    "    else:\n",
    "        return None\n",
    "if __name__ == \"__main__\":\n",
    "    #########################################################################\n",
    "    #TJ update values in this region every time!\n",
    "\n",
    "    include_karin = True\n",
    "    show_raw_fluxes = True\n",
    "    show_normalized_fluxes = True\n",
    "    image_files, filter_files = generate_list_of_files()\n",
    "    #SED_filepath = 'Data_files/ARM2_HII2_stitch.dat' #TJ switch to this one and rerun to use unconvolved array\n",
    "\n",
    "    if include_karin:\n",
    "        SED_filepath = 'Data_files/ARM2_HII2_conv_stitched_test.dat' \n",
    "        karin_SED_data = load_and_sort_convolved_Karin_spectrum(SED_filepath) #TJ this is a precomputed spectra to compare to IFU derived data\n",
    "    #TJ define IFU file path\n",
    "    IFU_filepath = 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'\n",
    "    IFU_hdul = fits.open(IFU_filepath)\n",
    "    IFU_data = IFU_hdul['SCI'].data  # flux in MJy/sr or μJy/arcsec²\n",
    "    IFU_header = IFU_hdul['SCI'].header\n",
    "    \n",
    "    loc = [202.4340450, 47.1732517] #TJ define location, radius, and aperture area\n",
    "    radius = 0.75*u.arcsec\n",
    "##############################################################################\n",
    "    \n",
    "    aperture_area_sr = np.pi * (radius.to(u.rad))**2\n",
    "    \n",
    "    print(\"Compressing IFU data cube into 2d array with flux summed over all pixels in aperture\")\n",
    "    IFU_335 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F335M.fits\", loc, radius)\n",
    "    IFU_360 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F360M.fits\", loc, radius)\n",
    "    IFU_405 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F405N.fits\", loc, radius)\n",
    "    IFU_430 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F430M.fits\", loc, radius)\n",
    "    IFU_444 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F444W.fits\", loc, radius)\n",
    "    IFU_560 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F560W.fits\", loc, radius)\n",
    "    IFU_770 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F770W.fits\", loc, radius)\n",
    "    IFU_1000 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F1000W.fits\", loc, radius)\n",
    "    IFU_1130 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F1130W.fits\", loc, radius)\n",
    "    IFU_1280 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F1280W.fits\", loc, radius)\n",
    "    IFU_1500 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F1500W.fits\", loc, radius)\n",
    "    IFU_1800 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F1800W.fits\", loc, radius)\n",
    "    IFU_2100 = get_IFU_spectrum(\"Data_files/IFU_files/M51_IFU_convolved_to_F2100W.fits\", loc, radius)\n",
    "    IFU_SED_data = get_IFU_spectrum(IFU_filepath, loc, radius)\n",
    "    \n",
    "    print(\"Extracting filter data\")\n",
    "    filter_data_array = [] #TJ initialize filter data array\n",
    "    \n",
    "    for file in filter_files: #TJ loop through filter files and extract wl and transmission data\n",
    "        data = []\n",
    "        with open(file, 'r') as f:\n",
    "                header = f.readline().strip().split()\n",
    "                for line in f:\n",
    "                    data_line = line.strip().split()\n",
    "                    data.append(data_line)\n",
    "                \n",
    "        header, filter_T = data[:2], np.array(data[2:])\n",
    "\n",
    "        wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "        T = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "        filter_data_array.append([wl, T])\n",
    "    #TJ initialize arrays\n",
    "    if include_karin:\n",
    "        Karin_expected_flux = []\n",
    "    IFU_expected_flux = []\n",
    "    photo_flux = []\n",
    "    NIRSpec_indices = []\n",
    "    print('doing the work')\n",
    "    for i, filter_data in enumerate(filter_data_array):\n",
    "        if include_karin:\n",
    "            Karin_expected_flux.append((get_Fnu_transmission(karin_SED_data[\"intensity\"], karin_SED_data[\"wavelength\"], filter_data[1], filter_data[0])))\n",
    "        IFU_expected = (get_Fnu_transmission(IFU_SED_data[\"intensity\"], IFU_SED_data[\"wavelength\"], filter_data[1], filter_data[0]))\n",
    "\n",
    "        if IFU_expected:\n",
    "            IFU_expected_flux.append(IFU_expected)\n",
    "            NIRSpec_indices.append(i)\n",
    "        photo_flux.append(get_image_flux(image_files[i], loc, radius))\n",
    "    IFU_444_expected = (get_Fnu_transmission(IFU_444[\"intensity\"], IFU_444[\"wavelength\"], filter_data_array[15][1], filter_data_array[15][0]))\n",
    "    IFU_430_expected = (get_Fnu_transmission(IFU_430[\"intensity\"], IFU_430[\"wavelength\"], filter_data_array[14][1], filter_data_array[14][0]))\n",
    "    IFU_405_expected = (get_Fnu_transmission(IFU_405[\"intensity\"], IFU_405[\"wavelength\"], filter_data_array[13][1], filter_data_array[13][0]))\n",
    "    IFU_360_expected = (get_Fnu_transmission(IFU_360[\"intensity\"], IFU_360[\"wavelength\"], filter_data_array[12][1], filter_data_array[12][0]))\n",
    "    IFU_335_expected = (get_Fnu_transmission(IFU_335[\"intensity\"], IFU_335[\"wavelength\"], filter_data_array[11][1], filter_data_array[11][0]))\n",
    "    '''IFU_560_expected = (get_Fnu_transmission(IFU_560[\"intensity\"], IFU_560[\"wavelength\"], filter_data_array[16][1], filter_data_array[16][0]))\n",
    "    IFU_770_expected = (get_Fnu_transmission(IFU_770[\"intensity\"], IFU_770[\"wavelength\"], filter_data_array[17][1], filter_data_array[17][0]))\n",
    "    IFU_1000_expected = (get_Fnu_transmission(IFU_1000[\"intensity\"], IFU_1000[\"wavelength\"], filter_data_array[18][1], filter_data_array[18][0]))\n",
    "    IFU_1130_expected = (get_Fnu_transmission(IFU_1130[\"intensity\"], IFU_1130[\"wavelength\"], filter_data_array[19][1], filter_data_array[19][0]))\n",
    "    IFU_1280_expected = (get_Fnu_transmission(IFU_1280[\"intensity\"], IFU_1280[\"wavelength\"], filter_data_array[20][1], filter_data_array[20][0]))\n",
    "    IFU_1500_expected = (get_Fnu_transmission(IFU_1500[\"intensity\"], IFU_1500[\"wavelength\"], filter_data_array[21][1], filter_data_array[21][0]))\n",
    "    IFU_1800_expected = (get_Fnu_transmission(IFU_1800[\"intensity\"], IFU_1800[\"wavelength\"], filter_data_array[22][1], filter_data_array[22][0]))\n",
    "    IFU_2100_expected = (get_Fnu_transmission(IFU_2100[\"intensity\"], IFU_2100[\"wavelength\"], filter_data_array[23][1], filter_data_array[23][0]))'''\n",
    "\n",
    "    print(\"work completed\")\n",
    "\n",
    "    #TJ convert to numpy array for better indexing and mathematics\n",
    "    #Karin_expected_flux = np.array(Karin_expected_flux)\n",
    "    IFU_expected_flux = np.array(IFU_expected_flux)\n",
    "    photo_flux = np.array(photo_flux)\n",
    "    NIRSpec_indices = np.array(NIRSpec_indices)\n",
    "    \n",
    "    if show_normalized_fluxes:\n",
    "        plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "        # Now plot with sorted data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        if include_karin:\n",
    "            plt.scatter([extract_filter_name(x) for x in filter_files], Karin_expected_flux/photo_flux, label='Karin convolution', s=100, marker='o', color='blue')\n",
    "        plt.scatter([extract_filter_name(x) for x in filter_files[NIRSpec_indices]], IFU_expected_flux/photo_flux[NIRSpec_indices], label='raw IFU', s=100, marker='x', color='red')\n",
    "        plt.scatter(extract_filter_name(filter_files[11]), IFU_335_expected/photo_flux[11], label='my convolution', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[12]), IFU_360_expected/photo_flux[12], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[13]), IFU_405_expected/photo_flux[13], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[14]), IFU_430_expected/photo_flux[14], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[15]), IFU_444_expected/photo_flux[15], label='', s=50, marker='x', color='black')\n",
    "        '''plt.scatter(extract_filter_name(filter_files[16]), IFU_560_expected/photo_flux[16], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[17]), IFU_770_expected/photo_flux[17], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[18]), IFU_1000_expected/photo_flux[18], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[19]), IFU_1130_expected/photo_flux[19], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[20]), IFU_1280_expected/photo_flux[20], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[21]), IFU_1500_expected/photo_flux[21], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[22]), IFU_1800_expected/photo_flux[22], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[23]), IFU_2100_expected/photo_flux[23], label='', s=50, marker='x', color='black')'''\n",
    "\n",
    "        plt.axhline(y=1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Filter Names')\n",
    "        plt.ylabel('Filter Pass Through (MJy)')\n",
    "        plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to Spectrum-derived values\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    if show_raw_fluxes:\n",
    "        plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "        # Now plot with sorted data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        if include_karin:\n",
    "            plt.scatter([extract_filter_name(x) for x in filter_files], Karin_expected_flux, label='Karin', s=100, marker='o', color='blue')\n",
    "        plt.scatter([extract_filter_name(x) for x in filter_files], photo_flux, label = 'image_extracted', s=100, marker = 'x', color = 'red')\n",
    "        plt.scatter([extract_filter_name(x) for x in filter_files[NIRSpec_indices]], IFU_expected_flux, label='IFU-determined', s=50, marker='x', color='green')\n",
    "        plt.scatter(extract_filter_name(filter_files[11]), IFU_335_expected, label='', s=50, marker='x', color='black')\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Filter Names')\n",
    "        plt.ylabel('Filter Pass Through (MJy)')\n",
    "        plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to Spectrum-derived values\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "\n",
    "from spectral_cube import SpectralCube\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #TJ ignore warnings (careful enabling this)\n",
    "\n",
    "home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "parent_dir = Path(home_directory).resolve() #TJ current notebook's parent directory\n",
    "os.chdir(parent_dir) #TJ change working directory to be the parent directory\n",
    "\n",
    "from Py_files.Basic_analysis import * #TJ import basic functions from custom package\n",
    "from Py_files.Convolution_script import * #TJ import convolution functions from custom package\n",
    "from Py_files.All_flux_calibration_functions import * #TJ import convolution functions from custom package\n",
    "\n",
    "image_files, filter_files = generate_list_of_files()\n",
    "\n",
    "locations = [[202.5062429, 47.2143358], [202.4335225, 47.1729608], [202.4340450, 47.1732517], [202.4823742, 47.1958589]]\n",
    "radius = 0.75*u.arcsec\n",
    "conv_images = glob.glob('Data_files/Image_files/Convolved_images/location_2/*')\n",
    "Grant_conv_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "#for file in image_files:\n",
    "#    for l, loc in enumerate(locations):\n",
    "#        convolve_image_to_psf(file, 17.1e-6, location=loc, size=7.5*u.arcsec, output_file=f'location_{l}/{file.split(\"lv3_\")[-1].split(\"_i2d\")[0]}_convolved_to_17p1um.fits')\n",
    "im_file = image_files[2]\n",
    "raw_files = glob.glob('Data_files/IFU_files/raw_IFUs/location_0/*s3d.fits')\n",
    "cut_files = glob.glob('Data_files/IFU_files/raw_IFUs/location_0/F*')\n",
    "#ifu_file = 'Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g235m-f170lp_s3d.fits'\n",
    "ifu_file = 'Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g140m-f100lp_s3d.fits'\n",
    "image_files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_cube_to_filter(ifu_filepath, filter_name, output_filename=None):\n",
    "    \"\"\"\n",
    "    Cut an IFU cube to only the wavelengths within a given filter's range.\n",
    "\n",
    "    Parameters:\n",
    "    - ifu_filepath: str, path to the IFU FITS file\n",
    "    - filter_name: str, filter name\n",
    "    - output_filepath: str, optional, path to save the new FITS file\n",
    "\n",
    "    Returns:\n",
    "    - output_filepath: str, path to the saved FITS file\n",
    "    \"\"\"\n",
    "    # Load IFU cube\n",
    "    hdul = fits.open(ifu_filepath)\n",
    "    header = hdul['SCI'].header\n",
    "    data = hdul['SCI'].data\n",
    "\n",
    "    # Build spectral axis\n",
    "    wcs = WCS(header)\n",
    "    naxis3 = header['NAXIS3']\n",
    "    crval3 = header['CRVAL3']  # starting wavelength\n",
    "    cdelt3 = header['CDELT3']  # delta wavelength per pixel\n",
    "    crpix3 = header['CRPIX3']  # reference pixel\n",
    "\n",
    "    # Wavelength array\n",
    "    wl_array = crval3 + (np.arange(naxis3) - (crpix3 - 1)) * cdelt3\n",
    "    # Get filter range\n",
    "    wl_min, wl_max = get_filter_wl_range(filter_name)\n",
    "    wl_min = wl_min.to(u.um).value\n",
    "    wl_max = wl_max.to(u.um).value\n",
    "    # Find indices within range (safe side: keep one extra on either side)\n",
    "    indices_in_range = np.where((wl_array >= wl_min) & (wl_array <= wl_max))[0]\n",
    "\n",
    "    if len(indices_in_range) == 0:\n",
    "        raise ValueError(f\"No wavelengths found within range for filter {filter_name}.\")\n",
    "\n",
    "    # Expand range by 1 on each side, staying within array bounds\n",
    "    start_idx = max(indices_in_range[0] - 1, 0)\n",
    "    end_idx = min(indices_in_range[-1] + 2, naxis3)  # +2 because slice is exclusive on end\n",
    "\n",
    "    # Slice data\n",
    "    cut_data = data[start_idx:end_idx, :, :]\n",
    "\n",
    "    # Update header\n",
    "    new_header = header.copy()\n",
    "    new_naxis3 = cut_data.shape[0]\n",
    "    new_header['NAXIS3'] = new_naxis3\n",
    "    new_header['CRVAL3'] = wl_array[start_idx]\n",
    "    new_header['CRPIX3'] = 1  # first pixel is start_idx now\n",
    "\n",
    "    # Save new FITS\n",
    "    hdu = fits.PrimaryHDU(data=cut_data, header=new_header)\n",
    "    hdul_new = fits.HDUList([hdu])\n",
    "\n",
    "    if output_filename is None:\n",
    "        base, ext = os.path.splitext(ifu_filepath)\n",
    "        output_filepath = f\"{base}_{filter_name}_cut.fits\"\n",
    "    location_idx = ifu_filepath.split('location_')[-1].split('/')[0]\n",
    "    hdul_new.writeto(f'Data_files/IFU_files/raw_IFUs/location_{location_idx}/{output_filename}', overwrite=True)\n",
    "\n",
    "    # Cleanup\n",
    "    hdul.close()\n",
    "\n",
    "    return output_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#homogenize_to_target_psf(image_files[6], 21e-6, output_file='location_0/f200w_image_convolved_to_21um.fits', location = locations[0], size = 5*u.arcsec)\n",
    "#homogenize_to_target_psf(cut_files[6], 21e-6, output_file=f\"Convolved_to_21um/{cut_files[6].split('/')[-1].split('_')[0]}_ifu_convolved.fits\")\n",
    "#test_convolve_image(image_files[6], 21e-6, 'F200W')\n",
    "#test_convolve_image(cut_files[6], 21e-6, 'F200W')\n",
    "#test_convolve_image(file_path, target_wavelength_m, native_filter, output_filepath=None)\n",
    "'''\n",
    "for i, file in enumerate(cut_files[::-1]):\n",
    "    filter = file.split('/')[-1].split('_')[0]\n",
    "    test_convolve_image(file, 21e-6, filter, output_filepath = f'Data_files/IFU_files/Convolved_to_21um/test_{filter}_IFU{i}_convolved_to_21um.fits')\n",
    "\n",
    "for i, file in enumerate(image_files[::-1]):\n",
    "    filter = extract_filter_name(file).upper()\n",
    "    test_convolve_image(file, 21e-6, filter, output_filepath = f'Data_files/Image_files/Convolved_images/test_{filter}_img{i}_convolved_to_21um.fits')\n",
    "'''\n",
    "'''\n",
    "conv_image_files = glob.glob('Data_files/Image_files/Convolved_images/test*.fits')\n",
    "conv_ifu_files = glob.glob('Data_files/IFU_files/Convolved_to_21um/test*.fits')\n",
    "radius = 0.75*u.arcsec\n",
    "loc = locations[0]\n",
    "conv_y_data = []\n",
    "for file in filter_files:\n",
    "    filter_name = extract_filter_name(file).upper()\n",
    "    image_file = [img for img in image_files if extract_filter_name(img).upper() == filter_name][0]\n",
    "    photo_flux = get_image_flux(image_file, loc, radius)\n",
    "    filter_data = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    ifu_files = which_fits(file, raw_files)\n",
    "    ifu_spectrum = stitch_spectra(ifu_files, loc, radius, anchor_idx=0, replace_negatives = 0)\n",
    "    ifu_flux = get_Fnu_transmission(ifu_spectrum[\"intensity\"], ifu_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    conv_y_data.append(ifu_flux/photo_flux)\n",
    "'''\n",
    "x_axis = np.array([extract_filter_name(x) for x in filter_files])\n",
    "conv_data = np.array([x_axis, conv_y_data])\n",
    "#np.save(f'Data_files/misc_data/Updated_flux_calibration/location{l}_both_convolved_to17p1um.npy', conv_data)\n",
    "#np.save(f'Data_files/misc_data/Updated_flux_calibration/location{l}_raw_files.npy', raw_data)\n",
    "#np.save(f'Data_files/misc_data/Updated_flux_calibration/location0_21um_files.npy', conv_data)\n",
    "raw_data = np.load('Data_files/misc_data/Updated_flux_calibration/location0_raw_files.npy')\n",
    "grant_data = np.load('Data_files/misc_data/Updated_flux_calibration/location0_both_convolved_to17p1um.npy')\n",
    "x = raw_data[0]\n",
    "raw_y = [try_float(i) for i in raw_data[1]]\n",
    "grant_y = [try_float(i) for i in grant_data[1]]\n",
    "conv_y = [try_float(i) for i in conv_data[1]]\n",
    "\n",
    "plt.scatter(x, conv_y, label = '21um convolution')\n",
    "plt.scatter(x, raw_y, label = 'both raw')\n",
    "plt.scatter(x, grant_y, label = '17um convolution')\n",
    "#plt.ylim(0.8, 1.6)\n",
    "plt.ylabel('synthetic flux/photo flux')\n",
    "plt.xlabel('filter name')\n",
    "plt.title('Synthetic flux compared to image measured flux')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rads = [0.2, 0.4, 0.6, 0.75, 1]\n",
    "for l, loc in enumerate(locations):\n",
    "    all_conv_image_files = glob.glob(f'Data_files/Image_files/Convolved_images/location_{l}/*')\n",
    "    if l==2:\n",
    "        raw_files = glob.glob(f'Data_files/IFU_files/raw_IFUs/location_1/*')\n",
    "        conv_files = glob.glob(f'Data_files/IFU_files/Grant_files/location_1/*')\n",
    "    else:\n",
    "        raw_files = glob.glob(f'Data_files/IFU_files/raw_IFUs/location_{l}/*')\n",
    "        conv_files = glob.glob(f'Data_files/IFU_files/Grant_files/location_{l}/*')\n",
    "    print('Using files: ', raw_files)\n",
    "    radius = 0.75*u.arcsec\n",
    "    conv_y_data = []\n",
    "    raw_y_data = []\n",
    "    for file in filter_files:\n",
    "        filter_name = extract_filter_name(file).upper()\n",
    "        raw_image_file = [img for img in image_files if extract_filter_name(img).upper() == filter_name][0]\n",
    "        raw_photo_flux = get_image_flux(raw_image_file, loc, radius)\n",
    "        conv_image_file = [img for img in all_conv_image_files if extract_filter_name(img).upper() == filter_name][0]\n",
    "        conv_photo_flux = get_image_flux(conv_image_file, loc, radius)\n",
    "        filter_file = [flt for flt in filter_files if extract_filter_name(flt).upper() == filter_name][0]\n",
    "        filter_data = []\n",
    "        with open(filter_file, 'r') as f:\n",
    "            header = f.readline().strip().split()\n",
    "            for line in f:\n",
    "                data_line = line.strip().split()\n",
    "                filter_data.append(data_line)\n",
    "                \n",
    "        header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "        filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "        filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "        raw_ifu_files = which_fits(filter_file, raw_files)\n",
    "        raw_spectrum = stitch_spectra(raw_ifu_files, loc, radius, anchor_idx=0, replace_negatives = 0)\n",
    "        raw_ifu_flux = get_Fnu_transmission(raw_spectrum[\"intensity\"], raw_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        raw_y_data.append(raw_ifu_flux/raw_photo_flux)\n",
    "        conv_ifu_files = which_fits(filter_file, conv_files)\n",
    "        conv_spectrum = stitch_spectra(conv_ifu_files, loc, radius, anchor_idx=0, replace_negatives = 0)\n",
    "        conv_ifu_flux = get_Fnu_transmission(conv_spectrum[\"intensity\"], conv_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        conv_y_data.append(conv_ifu_flux/conv_photo_flux)\n",
    "\n",
    "    x_axis = np.array([extract_filter_name(x) for x in filter_files])\n",
    "    raw_data = np.array([x_axis, raw_y_data])\n",
    "    conv_data = np.array([x_axis, conv_y_data])\n",
    "    np.save(f'Data_files/misc_data/Updated_flux_calibration/location{l}_both_convolved_to17p1um.npy', conv_data)\n",
    "    np.save(f'Data_files/misc_data/Updated_flux_calibration/location{l}_raw_files.npy', raw_data)\n",
    "    \n",
    "    plt.scatter(x_axis, conv_y_data, label = 'both convolved')\n",
    "    plt.scatter(x_axis, raw_y_data, label = 'both raw')\n",
    "    plt.ylim(0.8, 1.6)\n",
    "    plt.ylabel('synthetic flux/photo flux')\n",
    "    plt.xlabel('filter name')\n",
    "    plt.title('Synthetic flux compared to image measured flux')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    if show_normalized_fluxes:\n",
    "        plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "        # Now plot with sorted data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        if include_karin:\n",
    "            plt.scatter([extract_filter_name(x) for x in filter_files], Karin_expected_flux/photo_flux, label='Karin convolution', s=100, marker='o', color='blue')\n",
    "        plt.scatter([extract_filter_name(x) for x in filter_files[NIRSpec_indices]], IFU_expected_flux/photo_flux[NIRSpec_indices], label='raw IFU', s=100, marker='x', color='red')\n",
    "        plt.scatter(extract_filter_name(filter_files[11]), IFU_335_expected/photo_flux[11], label='my convolution', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[12]), IFU_360_expected/photo_flux[12], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[13]), IFU_405_expected/photo_flux[13], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[14]), IFU_430_expected/photo_flux[14], label='', s=50, marker='x', color='black')\n",
    "        plt.scatter(extract_filter_name(filter_files[15]), IFU_444_expected/photo_flux[15], label='', s=50, marker='x', color='black')\n",
    "\n",
    "        plt.axhline(y=1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Filter Names')\n",
    "        plt.ylabel('Filter Pass Through (MJy)')\n",
    "        plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to Spectrum-derived values\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    if show_raw_fluxes:\n",
    "        plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "        # Now plot with sorted data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        if include_karin:\n",
    "            plt.scatter([extract_filter_name(x) for x in filter_files], Karin_expected_flux, label='Karin', s=100, marker='o', color='blue')\n",
    "        plt.scatter([extract_filter_name(x) for x in filter_files], photo_flux, label = 'image_extracted', s=100, marker = 'x', color = 'red')\n",
    "        plt.scatter([extract_filter_name(x) for x in filter_files[NIRSpec_indices]], IFU_expected_flux, label='IFU-determined', s=50, marker='x', color='green')\n",
    "        plt.scatter(extract_filter_name(filter_files[11]), IFU_335_expected, label='', s=50, marker='x', color='black')\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Filter Names')\n",
    "        plt.ylabel('Filter Pass Through (MJy)')\n",
    "        plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to Spectrum-derived values\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_axis, y_data, label = 'photo convolved to 17.1um')\n",
    "plt.scatter(x_axis, raw_y_data, label = 'raw photo')\n",
    "plt.ylim(0.8, 1.6)\n",
    "plt.ylabel('synthetic flux/photo flux')\n",
    "plt.xlabel('filter name')\n",
    "plt.title('Synthetic flux compared to image measured flux')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_array = np.array(Karin_expected_flux)\n",
    "\n",
    "# Save file\n",
    "np.save('Data_files/misc_data/Karin_expected_flux.npy', saved_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thomas_values = np.array([IFU_335_expected, IFU_360_expected, IFU_405_expected, IFU_430_expected, IFU_444_expected])\n",
    "np.save('Data_files/misc_data/Thomas_reduction_expected_fluxes', Thomas_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul = fits.open(IFU_filepath) #TJ load file\n",
    "data = hdul['SCI'].data*1e-20  #TJ convert flux density to mks units\n",
    "header = hdul['SCI'].header #TJ load header\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [extract_filter_name(x) for x in filter_files]:\n",
    "    print(name.replace(\"f\",\"F\").replace(\"w\",\"W\").replace(\"m\", \"M\").replace(\"n\", \"N\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [IFU_335_expected/photo_flux[11], IFU_360_expected/photo_flux[12], IFU_405_expected/photo_flux[13],IFU_430_expected/photo_flux[14],IFU_444_expected/photo_flux[15]]\n",
    "np.std(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_wl_range(filter):\n",
    "    '''Use the filter files to determine what wavelength range we need for each filter\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter : type = str - string describing the filter name (case sensitive), for example \"F335M\"\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    Path to newly convolved file as a string\n",
    "    '''   \n",
    "    filter_files = ['/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F115W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F140M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F150W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F164N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F182M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F187N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F200W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F210M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F212N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F250M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F300M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F335M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F360M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F405N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F430M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F444W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F560W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F770W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1000W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1130W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1280W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1500W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1800W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F2100W.dat']\n",
    "    filter_file = [filer_filepath for filer_filepath in filter_files if extract_filter_name(filer_filepath).upper() == filter][0]\n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    return filter_wl[0]*u.m, filter_wl[-1]*u.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = SpectralCube.read('Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits', hdu='SCI')\n",
    "cube_wl = cube.spectral_axis.to(u.m)\n",
    "wl1, wl2 = get_filter_wl_range('F115W')\n",
    "idx = np.where((cube_wl >= wl1) & (cube_wl <= wl2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(integer):\n",
    "    if integer > 3:\n",
    "        return 6, None\n",
    "    else:\n",
    "        return 6, 3\n",
    "x,y = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_cubes = glob.glob('Data_files/IFU_files/*convolved*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_names = ['F115W', 'F140M', 'F150W', 'F164N', 'F182M', 'F187N', 'F200W', 'F210M', 'F212N', 'F250M', 'F300M', 'F335M', 'F360M', 'F405N', \n",
    "           'F430M', 'F444W', 'F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W'] \n",
    "for filter in filter_names:\n",
    "    print(\"for filter \", filter)\n",
    "    print(get_filter_wl_range(filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(f'Data_files/misc_data/flux_v_radius/F335M_radius_dependance.npy')\n",
    "y = np.load('Data_files/misc_data/flux_v_radius/F335M_bright_source_radius_dependence.npy')\n",
    "#plt.scatter(y[1], y[0])\n",
    "plt.scatter(x[1], x[0])\n",
    "filter_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_file = '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F335M.dat'\n",
    "\n",
    "filter_name = extract_filter_name(filter_file).upper()\n",
    "original_IFUs = which_fits(filter_file, karin_SDuval_IFU_files)\n",
    "\n",
    "#fluxes, radii = try_radii(original_IFUs, filter_name, test_loc, use_default=True)\n",
    "#array = np.array([fluxes, radii])\n",
    "#np.save(f'Data_files/misc_data/flux_v_radius/{filter_name}_raw_bright_source_radius_dependence.npy', array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "1*(u.deg**2).to(u.sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
