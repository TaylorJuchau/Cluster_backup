{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "from astropy.visualization import AsinhStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import SqrtStretch\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from astropy.nddata import block_reduce\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "\n",
    "\n",
    "home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "os.chdir(home_directory) #TJ change working directory to be the parent directory\n",
    "\n",
    "from Py_files.Functions import * #TJ import functions from custom package\n",
    "\n",
    "with open(\"Data_files/misc_data/jwst_pivots.pkl\", \"rb\") as file:\n",
    "    jwst_pivots = pickle.load(file)\n",
    "with open(\"Data_files/misc_data/jwst_filter_means.pkl\", \"rb\") as file:\n",
    "    jwst_means = pickle.load(file)\n",
    "\n",
    "image_files, filter_files = generate_list_of_files(filter_directory, image_directory)\n",
    "full_raw_ifu_files_loc0 = ['Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g140m-f100lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g235m-f170lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g395m-f290lp_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch4-shortmediumlong_s3d_trimmed.fits']\n",
    "full_raw_ifu_files_loc1 = ['Data_files/IFU_files/raw_IFUs/location_1/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch4-shortmediumlong_s3d_trimmed.fits']\n",
    "#TJ location 2 also within loc1 files\n",
    "full_raw_ifu_files_loc3 = ['Data_files/IFU_files/raw_IFUs/location_3/jw03435-o006_t010_nirspec_g140m-f100lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/jw03435-o006_t010_nirspec_g235m-f170lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/jw03435-o006_t010_nirspec_g395m-f290lp_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch4-shortmediumlong_s3d_trimmed.fits']\n",
    "#TJ this full_spectrum is built by stitching cube0 to cube1 anchored to cube1\n",
    "#TJ then stitching cube2 to cube3 anchored to cube3, then stitching all the others unaltered\n",
    "full_spec = 'Data_files/misc_data/Updated_flux_calibration/full_spectrum_loc0_rad1p25.npy'\n",
    "locations = [[202.5062429, 47.2143358], [202.4335225, 47.1729608], [202.4340450, 47.1732517], [202.4823742, 47.1958589]]\n",
    "radius = 1.25*u.arcsec\n",
    "r0 = 1.25*u.arcsec\n",
    "r1 = 0.9*u.arcsec\n",
    "r2 = 1*u.arcsec\n",
    "r3 = 1.1*u.arcsec\n",
    "filter_names = [extract_filter_name(x) for x in filter_files]\n",
    "anchor_filters=[]\n",
    "for file in full_raw_ifu_files_loc0:\n",
    "    l = get_largest_filter_within(file)\n",
    "    if l is not None:\n",
    "        anchor_filters.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ip25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_files, loc, radius, ncols=3, cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Create a collage of cutout images with an aperture overlay.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_image_fits_files : list of str\n",
    "        List of FITS image file paths (must contain SCI extension).\n",
    "    loc : list, tuple, or SkyCoord\n",
    "        Location of aperture center, either [RA, Dec] in degrees or a SkyCoord object.\n",
    "    radius : Quantity\n",
    "        Aperture radius (must have angular units, e.g. arcsec).\n",
    "    ncols : int, optional\n",
    "        Number of columns in the collage (default = 3).\n",
    "    cmap : str, optional\n",
    "        Colormap for displaying images (default = 'viridis').\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure loc is SkyCoord\n",
    "    if not isinstance(loc, SkyCoord):\n",
    "        loc_sky = SkyCoord(ra=loc[0]*u.deg, dec=loc[1]*u.deg, frame='icrs')\n",
    "    else:\n",
    "        loc_sky = loc\n",
    "\n",
    "    n_images = len(image_files)\n",
    "    nrows = int(np.ceil(n_images / ncols))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(5*ncols, 5*nrows), \n",
    "                             subplot_kw={'projection': None})\n",
    "    axes = np.atleast_1d(axes).ravel()  # Flatten in case of 1 row/col\n",
    "    \n",
    "    for ax, image_file in zip(axes, image_files):\n",
    "        # Load FITS\n",
    "        hdu = fits.open(image_file)['SCI']\n",
    "        image = hdu.data\n",
    "        header = hdu.header\n",
    "        wcs = WCS(header, naxis=2)\n",
    "        pixel_scale = np.abs(wcs.wcs.cdelt[0]) * 3600  # arcsec/pixel\n",
    "\n",
    "        # Make cutout\n",
    "        cutout = Cutout2D(image, position=loc_sky, size=(radius*3, radius*3), wcs=wcs)\n",
    "\n",
    "        # Convert SkyCoord -> pixel coords\n",
    "        x_img, y_img = cutout.wcs.world_to_pixel(loc_sky)\n",
    "\n",
    "        # Plot\n",
    "        im = ax.imshow(cutout.data, origin='lower', cmap=cmap,\n",
    "                  norm=ImageNormalize(cutout.data, stretch=AsinhStretch(), \n",
    "                                      vmin=0, vmax=np.percentile(cutout.data, 99)))\n",
    "        ax.add_patch(Circle((x_img, y_img), \n",
    "                            (radius.to(u.arcsec).value)/pixel_scale, \n",
    "                            ec='red', fc='none', lw=2, alpha=0.7))\n",
    "        cbar = plt.colorbar(\n",
    "            im,\n",
    "            ax=ax,\n",
    "            fraction=0.046,\n",
    "            pad=0.04\n",
    "        )\n",
    "        cbar.set_label(\"Flux (native units)\", fontsize=10)\n",
    "        ax.set_title(image_file.split(\"/\")[-1], fontsize=12)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Hide empty panels if n_images doesn’t fill full grid\n",
    "    for ax in axes[n_images:]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_image_and_synth(filter, ifu_fileset, loc, radius, image_files=v0p3_images, color_min_max = [1, 99.5]):\n",
    "    \"\"\"\n",
    "    Show real image and synthetic IFU-derived image side by side.\n",
    "    Works with either one or two IFU cubes needed for the filter.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Location handling\n",
    "    # ------------------------------------------------------------\n",
    "    if not isinstance(loc, SkyCoord):\n",
    "        loc_sky = SkyCoord(ra=loc[0] * u.deg, dec=loc[1] * u.deg, frame=\"icrs\")\n",
    "    else:\n",
    "        loc_sky = loc\n",
    "\n",
    "    def nearest_spaxel_map(cube_src, cube_target):\n",
    "        ny, nx = cube_target.shape[1:]\n",
    "        y_t, x_t = np.mgrid[:ny, :nx]\n",
    "\n",
    "        world = cube_target.wcs.celestial.pixel_to_world(x_t, y_t)\n",
    "        x_s, y_s = cube_src.wcs.celestial.world_to_pixel(world)\n",
    "\n",
    "        x_s = np.clip(np.round(x_s).astype(int), 0, cube_src.shape[2] - 1)\n",
    "        y_s = np.clip(np.round(y_s).astype(int), 0, cube_src.shape[1] - 1)\n",
    "\n",
    "        return y_s, x_s\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Locate real image\n",
    "    # ------------------------------------------------------------\n",
    "    real_image_file = [x for x in image_files if extract_filter_name(x) == filter][0]\n",
    "    \n",
    "    short_wl, long_wl = [x.value for x in get_filter_wl_range(filter)]\n",
    "\n",
    "    needed_ifus = []\n",
    "    for file in ifu_fileset:\n",
    "        wl = SpectralCube.read(file, hdu=\"SCI\").spectral_axis.to(u.m).value\n",
    "        if (wl[0] < short_wl) and (wl[-1] > long_wl):\n",
    "            needed_ifus = [file]\n",
    "            break\n",
    "        if (long_wl > wl[0]) and (short_wl < wl[-1]):\n",
    "            needed_ifus.append(file)\n",
    "        if len(needed_ifus) > 1:\n",
    "            break\n",
    "\n",
    "    cube1 = SpectralCube.read(needed_ifus[0], hdu=\"SCI\")\n",
    "    cube2 = SpectralCube.read(needed_ifus[1], hdu=\"SCI\") if len(needed_ifus) > 1 else None\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Base cube quantities\n",
    "    # ------------------------------------------------------------\n",
    "    wl1 = cube1.spectral_axis.to(u.m).value\n",
    "    d1 = cube1.unmasked_data[:].value\n",
    "\n",
    "    ny, nx = cube1.shape[1:]\n",
    "    n_pix = ny * nx\n",
    "    d1 = d1.reshape(len(wl1), n_pix).T\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Stitch spectra if needed\n",
    "    # ------------------------------------------------------------\n",
    "    if cube2 is not None:\n",
    "        wl2 = cube2.spectral_axis.to(u.m).value\n",
    "        d2 = cube2.unmasked_data[:].value\n",
    "\n",
    "        y2, x2 = nearest_spaxel_map(cube2, cube1)\n",
    "        d2 = d2[:, y2, x2].reshape(len(wl2), n_pix).T\n",
    "\n",
    "        wl_all = np.concatenate([wl1, wl2])\n",
    "        sort_idx = np.argsort(wl_all)\n",
    "        wl_all = wl_all[sort_idx]\n",
    "\n",
    "        spec_all = np.concatenate([d1, d2], axis=1)[:, sort_idx]\n",
    "\n",
    "        wl_min = max(wl1.min(), wl2.min())\n",
    "        wl_max = min(wl1.max(), wl2.max())\n",
    "        overlap = (wl_all >= wl_min) & (wl_all <= wl_max)\n",
    "        both = np.isin(wl_all, wl1) & np.isin(wl_all, wl2) & overlap\n",
    "        spec_all[:, both] *= 0.5\n",
    "    else:\n",
    "        wl_all = wl1\n",
    "        spec_all = d1\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Synthetic photometry\n",
    "    # ------------------------------------------------------------\n",
    "    filter_wl, filter_trans = get_filter_data(filter)\n",
    "\n",
    "    image = np.empty(n_pix)\n",
    "    for i in range(n_pix):\n",
    "        image[i] = get_Fnu_transmission(\n",
    "            spec_all[i], wl_all, filter_trans, filter_wl, warnings=True\n",
    "        )\n",
    "\n",
    "    synth_image = image.reshape(ny, nx)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Attach WCS to synthetic image\n",
    "    # ------------------------------------------------------------\n",
    "    synth_hdu = fits.PrimaryHDU(\n",
    "        synth_image,\n",
    "        header=cube1.wcs.celestial.to_header()\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot real vs synthetic\n",
    "    # ------------------------------------------------------------\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # -------------------------\n",
    "    # REAL IMAGE\n",
    "    # -------------------------\n",
    "    hdu = fits.open(real_image_file)[\"SCI\"]\n",
    "    real_pix_size = hdu.header['PIXAR_A2']**0.5\n",
    "    aperture_radius = radius.to(u.arcsec).value / real_pix_size\n",
    "    cutout_real = Cutout2D(\n",
    "        hdu.data,\n",
    "        position=loc_sky,\n",
    "        size=(radius * 3, radius * 3),\n",
    "        wcs=WCS(hdu.header)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # SYNTHETIC IMAGE (WCS CUTOUT)\n",
    "    # -------------------------\n",
    "    cutout_synth = Cutout2D(\n",
    "        synth_hdu.data,\n",
    "        position=loc_sky,\n",
    "        size=(radius * 3, radius * 3),\n",
    "        wcs=WCS(synth_hdu.header)\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Shared normalization (1–99%)\n",
    "    # ------------------------------------------------------------\n",
    "    combined = np.concatenate([\n",
    "        cutout_real.data[np.isfinite(cutout_real.data)],\n",
    "        cutout_synth.data[np.isfinite(cutout_synth.data)]\n",
    "    ])\n",
    "\n",
    "    vmin = np.percentile(combined, color_min_max[0])\n",
    "    vmax = np.percentile(combined, color_min_max[1])\n",
    "\n",
    "    cmap = plt.get_cmap(\"viridis\").copy()\n",
    "    cmap.set_under(\"black\")\n",
    "    cmap.set_over(\"white\")\n",
    "    norm = colors.Normalize(vmin=vmin, vmax=vmax, clip=False)\n",
    "\n",
    "    pix_scale = np.abs(cutout_synth.wcs.wcs.cdelt[0]) * 3600\n",
    "    r_ap_pix = radius.to(u.arcsec).value / pix_scale\n",
    "\n",
    "    # -------------------------\n",
    "    # PLOT REAL\n",
    "    # -------------------------\n",
    "    im0 = axes[0].imshow(\n",
    "        cutout_real.data,\n",
    "        origin=\"lower\",\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "    axes[0].set_title(f\"{filter} – Real\")\n",
    "\n",
    "    cbar0 = plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    cbar0.set_label(\"Flux\", fontsize=14)\n",
    "    cbar0.ax.tick_params(labelsize=12)\n",
    "\n",
    "    x_r, y_r = cutout_real.wcs.world_to_pixel(loc_sky)\n",
    "    axes[0].add_patch(\n",
    "        Circle((x_r, y_r), aperture_radius, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # PLOT SYNTHETIC\n",
    "    # -------------------------\n",
    "    im1 = axes[1].imshow(\n",
    "        cutout_synth.data,\n",
    "        origin=\"lower\",\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "    axes[1].set_title(f\"{filter} – Synthetic (IFU)\")\n",
    "\n",
    "    cbar1 = plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    cbar1.set_label(\"Flux\", fontsize=14)\n",
    "    cbar1.ax.tick_params(labelsize=12)\n",
    "\n",
    "    x_s, y_s = cutout_synth.wcs.world_to_pixel(loc_sky)\n",
    "    axes[1].add_patch(\n",
    "        Circle((x_s, y_s), r_ap_pix, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Cleanup\n",
    "    # -------------------------\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def is_filter_relevent(filter, ifu_file):\n",
    "    '''If a filter's mean wavelength is inside the ifu, returns True\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter : type = string - name of filter (\"F115W\")\n",
    "    ifu_file : type = string - string to location of ifu file\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    True if filter's mean wavelength is inside the ifu_file, False if it is not.\n",
    "    '''\n",
    "    wls = SpectralCube.read(ifu_file, hdu = 'SCI').spectral_axis.to(u.m)\n",
    "    short, long = wls[0], wls[-1]\n",
    "    return (jwst_means[filter] > short) & (jwst_means[filter] < long)\n",
    "    \n",
    "def adjust_spectrum(original_ifu, filter_name, image_files, location, radius, adjustment_operation = 'add'):\n",
    "    '''Takes an ifu file and adjusts the flux through an aperture centered at a location with specified radius.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    original_ifu : type = string (or, see retry=True)- string to location of ifu file\n",
    "    filter_name : type = string - filter name like \"F115W\"\n",
    "    location : type = either SkyCoord or list of [ra, dec] values in degrees - location of center of aperture\n",
    "    radius : type = angular size - radius of aperture, must have units attached.\n",
    "    adjustment_operation (optional, defaults to 'add'): type = string - either 'add' or 'multiply' to specify what kind of correction to use\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    Structured Numpy array with 'intensity' and 'wavelength' keys\n",
    "    '''\n",
    "    if filter_name is None:\n",
    "        return get_IFU_spectrum(original_ifu, location, radius, replace_negatives = False), 0\n",
    "    else:\n",
    "        image_file = [x for x in image_files if extract_filter_name(x)==filter_name][0]\n",
    "        raw_data = get_IFU_spectrum(original_ifu, location, radius, replace_negatives = False)\n",
    "        filter_wl, filter_trans = get_filter_data(filter_name) #TJ this is the transmission vs wavelength function for this filter\n",
    "        image_flux = get_image_flux(image_file, location, radius, replace_negatives = False) #TJ this is the flux we SHOULD get\n",
    "        initial_synth_flux = get_Fnu_transmission(raw_data['intensity'], raw_data['wavelength'], filter_trans, filter_wl, warnings = True) #TJ this is the current synthetic flux we get\n",
    "        if adjustment_operation == 'add':\n",
    "            correction = image_flux - initial_synth_flux\n",
    "            raw_data['intensity'] = raw_data['intensity'] + correction\n",
    "            return raw_data, correction #TJ now corrected to match photometry\n",
    "        elif adjustment_operation == 'multiply':\n",
    "            correction = image_flux/initial_synth_flux\n",
    "            raw_data['intensity'] = raw_data['intensity']*correction\n",
    "            return raw_data, correction #TJ now corrected\n",
    "        else:\n",
    "            print('adjustment operation not recognized, only \"add\" or \"multiply\" are currently implemented')\n",
    "            return None\n",
    "        print('Something went wrong.')\n",
    "        return raw_data, correction #TJ Now corrected data\n",
    "\n",
    "\n",
    "def get_largest_filter_within(ifu_file):\n",
    "    '''Takes an ifu file and selects the filter with the largest bandpass that is entirely within it.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    ifu_file : type = string - string to location of ifu file\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    Filter name (ex. \"F115W\") corresponding to the largest filter entirely contained within the IFU file \n",
    "    '''\n",
    "    filters = [extract_filter_name(x) for x in filter_files if full_coverage(extract_filter_name(x),ifu_file)==\"good\"]\n",
    "    if len(filters)<1:\n",
    "        print(f'No filters entirely within {ifu_file}')\n",
    "        return None\n",
    "    else:\n",
    "        best_filter = filters[np.argmax([(get_filter_wl_range(fil)[1].value - get_filter_wl_range(fil)[0].value) for fil in filters])]\n",
    "        return best_filter\n",
    "\n",
    "def needed_datasets(filter_name, datasets):\n",
    "    '''returns which ifu_files should be considered when calculating the synthetic flux. If an ifu even slightly overlaps into\n",
    "    the filter's range it is included.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter : type = string - name of filter (\"F115W\")\n",
    "    datasets : type = structured array - array with keys for 'wavelength' and 'intensity'\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    Filter name (ex. \"F115W\") corresponding to the largest filter entirely contained within the IFU file \n",
    "    '''\n",
    "    needed = []\n",
    "    filter_wl, _ = get_filter_data(filter_name)\n",
    "    for data in datasets:\n",
    "        if (filter_wl[0] < data['wavelength'][-1]) & (filter_wl[-1] > data['wavelength'][0]):\n",
    "            needed.append(data)\n",
    "    return needed\n",
    "\n",
    "def merge_datasets(ds1, ds2):\n",
    "    \"\"\"\n",
    "    Merge two structured arrays with 'wavelength' and 'intensity' keys.\n",
    "    Handles overlapping regions by averaging intensities, and automatically\n",
    "    determines which dataset has higher wavelength resolution.\n",
    "    \"\"\"\n",
    "    # Sort by wavelength, just to be safe\n",
    "    ds1 = np.sort(ds1, order='wavelength')\n",
    "    ds2 = np.sort(ds2, order='wavelength')\n",
    "\n",
    "    # Determine wavelength resolutions\n",
    "    d1_res = np.mean(np.diff(ds1['wavelength']))\n",
    "    d2_res = np.mean(np.diff(ds2['wavelength']))\n",
    "\n",
    "    # Assign high- and low-resolution datasets\n",
    "    if d1_res < d2_res:\n",
    "        highres, lowres = ds1, ds2\n",
    "    else:\n",
    "        highres, lowres = ds2, ds1\n",
    "\n",
    "    # Determine overlap region\n",
    "    overlap_start = max(highres['wavelength'][0], lowres['wavelength'][0])\n",
    "    overlap_end   = min(highres['wavelength'][-1], lowres['wavelength'][-1])\n",
    "\n",
    "    # Interpolate the lowres data onto highres wavelengths (only inside overlap)\n",
    "    overlap_mask = (highres['wavelength'] >= overlap_start) & (highres['wavelength'] <= overlap_end)\n",
    "    interp_flux = np.interp(highres['wavelength'][overlap_mask],\n",
    "                            lowres['wavelength'], lowres['intensity'])\n",
    "\n",
    "    # Combine in overlap by averaging\n",
    "    merged_overlap_wl = highres['wavelength'][overlap_mask]\n",
    "    merged_overlap_intensity = 0.5 * (highres['intensity'][overlap_mask] + interp_flux)\n",
    "\n",
    "    # Keep the unique non-overlapping parts from both sides\n",
    "    full_low_side  = ds1[ds1['wavelength'] < overlap_start]\n",
    "    full_high_side = ds2[ds2['wavelength'] > overlap_end]\n",
    "\n",
    "    # Concatenate all pieces and sort\n",
    "    merged = np.concatenate([\n",
    "        full_low_side,\n",
    "        np.rec.fromarrays([merged_overlap_wl, merged_overlap_intensity],\n",
    "                          names=('wavelength', 'intensity')),\n",
    "        full_high_side\n",
    "    ])\n",
    "    merged = np.sort(merged, order='wavelength')\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def get_all_fluxes(filter_files, spec_datasets, image_files, location, radius):\n",
    "    '''Creates synthetic fluxes for all filters in the files that have wavelengths that span the entire filter.\n",
    "    For filters that straddle multiple wavelengths, any wavelength inside a filter that has intensity values\n",
    "    from multiple datasets uses the average intensity from each dataset.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter_files : type = list of strings - name of filter [\"F115W\", \"F2100W\"]\n",
    "    datasets : type = list of structured arrays - arrays with keys for 'wavelength' and 'intensity'\n",
    "    image_files : type = list of strings - strings to image files\n",
    "    location : type = either SkyCoord or list of [ra, dec] values in degrees - location of center of aperture\n",
    "    radius : type = angular size - radius of aperture, must have units attached.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    A dictionary with keys for 'filter_name', 'mean_wl', 'synth_flux', and 'photo_flux'\n",
    "    '''\n",
    "    results = {}\n",
    "\n",
    "    results['filter_name'] = []\n",
    "    results['mean_wl'] = []\n",
    "    results['synth_flux'] = []\n",
    "    results['photo_flux'] = []\n",
    "    results['wavelength'] = []\n",
    "    results['intensity'] = []\n",
    "    \n",
    "    for i, data in enumerate(spec_datasets[1:]):\n",
    "        if i == 0:\n",
    "            prior_data = spec_datasets[0]\n",
    "        prior_data = merge_datasets(prior_data, data)\n",
    "        \n",
    "    results['wavelength'].append(prior_data['wavelength'])\n",
    "    results['intensity'].append(prior_data['intensity'])\n",
    "    \n",
    "    \n",
    "    for filter_file in filter_files:\n",
    "        filter_name = extract_filter_name(filter_file)\n",
    "        image_file = [x for x in image_files if extract_filter_name(x)==filter_name][0]\n",
    "        photo_flux = get_image_flux(image_file, location, radius, replace_negatives = False)\n",
    "        results['photo_flux'].append(photo_flux)\n",
    "        filter_wl, filter_trans = get_filter_data(filter_name)\n",
    "        results['filter_name'].append(filter_name)\n",
    "        results['mean_wl'].append(jwst_means[filter_name].value)\n",
    "        needed_data = needed_datasets(filter_name, spec_datasets)\n",
    "        if len(needed_data) == 0:\n",
    "            print('no spectral data was found for ', filter_name)\n",
    "        if len(needed_data)<2:\n",
    "            synth_flux = get_Fnu_transmission(needed_data[0]['intensity'], needed_data[0]['wavelength'], filter_trans, filter_wl, warnings = True)\n",
    "            results['synth_flux'].append(synth_flux)\n",
    "            \n",
    "        else:\n",
    "            full_data = merge_datasets(needed_data[0], needed_data[1])\n",
    "            synth_flux = get_Fnu_transmission(full_data['intensity'], full_data['wavelength'], filter_trans, filter_wl, warnings = True)\n",
    "            results['synth_flux'].append(synth_flux)\n",
    "    results['wavelength'] = np.array(results['wavelength'][0])\n",
    "    results['intensity'] = np.array(results['intensity'][0])\n",
    "    results['filter_name'] = np.array(results['filter_name'])\n",
    "    results['mean_wl'] = np.array(results['mean_wl'])\n",
    "    results['synth_flux'] = np.array(results['synth_flux'])\n",
    "    results['photo_flux'] = np.array(results['photo_flux'])\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_overlap_region(ds1, ds2):\n",
    "    \"\"\"\n",
    "    Return only the overlapping wavelength region between two structured arrays\n",
    "    with 'wavelength' and 'intensity'. The returned region contains:\n",
    "        - wavelength grid from the higher-resolution dataset (within overlap)\n",
    "        - intensity = average(intensity_highres, interpolated_intensity_lowres)\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort to ensure order\n",
    "    ds1 = np.sort(ds1, order='wavelength')\n",
    "    ds2 = np.sort(ds2, order='wavelength')\n",
    "\n",
    "    # Compute wavelength resolutions\n",
    "    d1_res = np.mean(np.diff(ds1['wavelength']))\n",
    "    d2_res = np.mean(np.diff(ds2['wavelength']))\n",
    "\n",
    "    # Identify high- and low-resolution datasets\n",
    "    if d1_res < d2_res:\n",
    "        highres, lowres = ds1, ds2\n",
    "    else:\n",
    "        highres, lowres = ds2, ds1\n",
    "\n",
    "    # Determine numerical overlap bounds\n",
    "    overlap_start = max(highres['wavelength'][0], lowres['wavelength'][0])\n",
    "    overlap_end   = min(highres['wavelength'][-1], lowres['wavelength'][-1])\n",
    "\n",
    "    # If no overlap, return empty structured array\n",
    "    if overlap_start >= overlap_end:\n",
    "        return np.recarray(0, dtype=[('wavelength', float), ('intensity', float)])\n",
    "\n",
    "    # Mask for high-res wavelengths inside the overlap\n",
    "    mask = (highres['wavelength'] >= overlap_start) & (highres['wavelength'] <= overlap_end)\n",
    "\n",
    "    high_wl = highres['wavelength'][mask]\n",
    "    high_flux = highres['intensity'][mask]\n",
    "\n",
    "    # Interpolate lowres intensities onto the highres wavelength grid\n",
    "    interp_flux = np.interp(high_wl,\n",
    "                            lowres['wavelength'],\n",
    "                            lowres['intensity'])\n",
    "\n",
    "    # Average intensities\n",
    "    avg_flux = 0.5 * (high_flux + interp_flux)\n",
    "\n",
    "    # Return structured array\n",
    "    overlap = np.rec.fromarrays(\n",
    "        [high_wl, avg_flux],\n",
    "        names=('wavelength', 'intensity')\n",
    "    )\n",
    "\n",
    "    return overlap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_data(ifu_files, image_files, filter_files, loc, radius, anchor_filters = anchor_filters):\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    temp_filepath = 'Data_files/misc_data/temp_data'\n",
    "    if os.path.exists(temp_filepath):\n",
    "        shutil.rmtree(temp_filepath)\n",
    "    os.makedirs(temp_filepath)\n",
    "    results = {}\n",
    "    if loc == [202.5062429, 47.2143358]:\n",
    "        loc_index = 0\n",
    "    elif loc == [202.4335225, 47.1729608]:\n",
    "        loc_index = 1\n",
    "    elif loc == [202.4340450, 47.1732517]:\n",
    "        loc_index = 2\n",
    "    elif loc == [202.4823742, 47.1958589]:\n",
    "        loc_index = 3\n",
    "    else:\n",
    "        loc_index = \"?\"\n",
    "    \n",
    "    results['add_datasets'] = []\n",
    "    results['mult_datasets'] = []\n",
    "\n",
    "    results['ifu_files'] = ifu_files\n",
    "    results['image_files']\n",
    "    \n",
    "    results['location'] = loc\n",
    "    results['loc_idx'] = loc_index\n",
    "    results['radius'] = radius\n",
    "    \n",
    "    print('adjusting spectra using additive and multiplicative corrections')\n",
    "    results['add_correction_values'] = []\n",
    "    results['mult_correction_values'] = []\n",
    "    \n",
    "    for i, ifu_file in enumerate(ifu_files):\n",
    "        mult_data, mult_correction = adjust_spectrum(ifu_file, get_largest_filter_within(ifu_file), image_files, loc, radius, adjustment_operation = 'multiply')\n",
    "        results['mult_correction_values'].append(mult_correction)\n",
    "        add_data, add_correction = adjust_spectrum(ifu_file, get_largest_filter_within(ifu_file), image_files, loc, radius, adjustment_operation = 'add')\n",
    "        results['add_correction_values'].append(add_correction)\n",
    "        fname = os.path.join(temp_filepath, f\"add_grism_{i+1}_of_{len(ifu_files)}.npy\")\n",
    "        np.save(fname, add_data)\n",
    "        fname = os.path.join(temp_filepath, f\"mult_grism_{i+1}_of_{len(ifu_files)}.npy\")\n",
    "        np.save(fname, mult_data)\n",
    "\n",
    "        print(f'adjusted {i+1} of {len(ifu_files)}')\n",
    "\n",
    "    add_datasets = []\n",
    "    mult_datasets = []\n",
    "    add_files = glob.glob(f'Data_files/misc_data/temp_data/add_grism*')\n",
    "    mult_files = glob.glob(f'Data_files/misc_data/temp_data/mult_grism*')\n",
    "    for file in add_files:\n",
    "        data = np.load(file)\n",
    "        results['add_datasets'].append(data)\n",
    "        add_datasets.append(data)\n",
    "    for file in mult_files:\n",
    "        data = np.load(file)\n",
    "        results['mult_datasets'].append(data)\n",
    "        mult_datasets.append(data)\n",
    "\n",
    "    \n",
    "    print('calculating additive corrected synthetic photometry...')\n",
    "    add_results = get_all_fluxes(filter_files, add_datasets, image_files, loc, radius)\n",
    "    print('calculating multiplicative corrected synthetic photometry...')\n",
    "    mult_results = get_all_fluxes(filter_files, mult_datasets, image_files, loc, radius)\n",
    "    \n",
    "    \n",
    "    print('Compiling results and cleaning up...')\n",
    "    \n",
    "    results['filter_names'] = add_results['filter_name']\n",
    "    results['filter_wavelengths'] = add_results['mean_wl']\n",
    "    results['add_synthetic_fluxes'] = add_results['synth_flux']\n",
    "    results['mult_synthetic_fluxes'] = mult_results['synth_flux']\n",
    "    if np.mean(add_results['photo_flux']) != np.mean(mult_results['photo_flux']):\n",
    "        print('!!!!!!!!Photo fluxes were not the same in the two datasets! Something has gone wrong')\n",
    "    results['photo_fluxes'] = add_results['photo_flux']\n",
    "    if np.mean(add_results['wavelength']) != np.mean(mult_results['wavelength']):\n",
    "        print('!!!!!!!!!Wavelength arrays were not the same in the two datasets! Something has gone wrong')\n",
    "    results['wavelength'] = add_results['wavelength']\n",
    "    results['add_intensity'] = add_results['intensity']\n",
    "    results['mult_intensity'] = mult_results['intensity']\n",
    "    \n",
    "    shutil.rmtree(temp_filepath)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_results(results, correction = 'mult', show_images = []):\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    if correction == 'mult':\n",
    "        method = 'multiplicative correction'\n",
    "    elif correction == 'add':\n",
    "        method = 'additive correction'\n",
    "    else:\n",
    "        method = 'unrecognized method'\n",
    "    fig = plt.figure(figsize = (45,30))\n",
    "    ax_spec = fig.add_axes((0.05, 0.4, 1, 0.6))\n",
    "    ax_scat = fig.add_axes((0.05, 0.05, 1, 0.35))\n",
    "    fontsize_sm = 35\n",
    "    fontsize_lg = 45\n",
    "    marker_size = 250\n",
    "    cube_colors = ['purple', 'blue', 'cyan', 'green', 'orange', 'red', 'pink']\n",
    "    spec_y_min = 1 #TJ Flux should always be around 10^-20 so setting limits of 0-1 should never be too strict\n",
    "    spec_y_max = 0\n",
    "    short_bounds = []\n",
    "    long_bounds = []\n",
    "    for i, dataset in  enumerate(results[correction+'_datasets']):\n",
    "            \n",
    "            short_bounds.append(dataset['wavelength'][0])\n",
    "            long_bounds.append(dataset['wavelength'][-1])\n",
    "            ax_spec.plot(dataset['wavelength'], dataset['intensity'], alpha = 0.5, color = cube_colors[i], linewidth = 5)\n",
    "            spec_y_min = min(spec_y_min, np.percentile(dataset['intensity'], 1)*0.5)\n",
    "            spec_y_max = max(spec_y_max, np.percentile(dataset['intensity'], 98)*1.5)\n",
    "            if i > 0:\n",
    "                overlap_data = get_overlap_region(results[correction+'_datasets'][i-1], dataset)\n",
    "                ax_spec.plot(overlap_data['wavelength'], overlap_data['intensity'], alpha = 0.5, color = 'black')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ax_spec.plot(addresults0['wavelength'], addresults0['intensity'], linewidth = 5)\n",
    "    ax_scat.plot(results['wavelength'], [1]*len(results[correction+'_intensity']), color = 'white', alpha = 0)\n",
    "    ax_spec.scatter(results['filter_wavelengths'], results[correction+'_synthetic_fluxes'], marker = '*', s=marker_size, color = 'black')\n",
    "    ax_spec.scatter([], [], marker = '*', s=marker_size, color = 'black', label = 'Synth')\n",
    "    ax_spec.scatter(results['filter_wavelengths'], results['photo_fluxes'], marker = \"o\", s=marker_size, color = 'black')\n",
    "    ax_spec.scatter([], [], marker = \"o\", s=marker_size, color = 'black', label = 'Photo')\n",
    "    for i, filter in enumerate(results['filter_names']):\n",
    "        filter_short_wl, filter_long_wl = [x.value for x in get_filter_wl_range(filter)]\n",
    "        ax_spec.hlines(y=results['photo_fluxes'][i], xmin=filter_short_wl, xmax=filter_long_wl, color='black', alpha=0.7, linewidth=3)\n",
    "    \n",
    "    ax_scat.scatter(results['filter_wavelengths'], results[correction+'_synthetic_fluxes']/results['photo_fluxes'], s=marker_size, color = 'black')\n",
    "    \n",
    "    \n",
    "    ax_scat.tick_params(axis='x', which='minor', width=2, length=10, right=True, top=True, direction='in',\n",
    "                       labelsize=fontsize_sm)\n",
    "    ax_scat.tick_params(axis='x', which='major', width=3, length=15, right=True, top=True, direction='in',\n",
    "                       labelsize=fontsize_sm)\n",
    "    ax_scat.tick_params(axis='y', which='both', width=3, length=15, right=True, top=True, direction='in',\n",
    "                       labelsize=fontsize_sm)\n",
    "    ax_scat.set_xlabel('wavelength (m)', fontsize = 40)\n",
    "    ax_scat.set_ylabel('synthetic/photometric flux', fontsize = 40)\n",
    "    ax_spec.tick_params(axis='x', which='minor', width=2, length=10, right=True, top=True, direction='in',\n",
    "                       labelsize=fontsize_sm)\n",
    "    ax_spec.tick_params(axis='x', which='major', width=3, length=15, right=True, top=True, direction='in',\n",
    "                       labelsize=fontsize_sm)\n",
    "    ax_spec.tick_params(axis='y', which='both', width=3, length=15, right=True, top=True, direction='in',\n",
    "                       labelsize=fontsize_sm)\n",
    "    ax_spec.set_ylabel('Intensity (MJy/sr)', fontsize = 40)\n",
    "    \n",
    "    ax_spec.set_title(f\"{results['radius']}-radius aperture at location {results['loc_idx']}\\nUsing {method}\", fontsize = 50)\n",
    "    \n",
    "    ax_scat.set_xscale('log')\n",
    "    ax_spec.set_xscale('log')\n",
    "    ax_spec.set_yscale('log')\n",
    "    label_positions = []  # to store display-space positions\n",
    "\n",
    "    for x, y, name in zip(results['filter_wavelengths'], results[correction+'_synthetic_fluxes']/results['photo_fluxes'], results['filter_names']):\n",
    "        # initial offset (just below the point)\n",
    "        filter_short_wl, filter_long_wl = [x.value for x in get_filter_wl_range(name)]\n",
    "        ax_scat.hlines(y=y, xmin=filter_short_wl, xmax=filter_long_wl, color='black', alpha=0.7, linewidth=3)\n",
    "        y_offset = -0.05 \n",
    "\n",
    "        if name in anchor_filters:\n",
    "            color = 'red'\n",
    "        else:\n",
    "            color = 'black'\n",
    "        # convert data point to display coords\n",
    "        x_disp, y_disp = ax_spec.transData.transform((x, y))\n",
    "        \n",
    "        # check overlap in display coordinates\n",
    "        too_close = False\n",
    "        for (xx, yy) in label_positions:\n",
    "            if abs(x_disp - xx) < 20 and abs(y_disp + y_offset - yy) < 5:  \n",
    "                # 20px horizontal & 12px vertical proximity → overlap\n",
    "                too_close = True\n",
    "                break\n",
    "        \n",
    "        # if overlapping, nudge upward instead of downward\n",
    "        if too_close:\n",
    "            y_offset = +0.2  \n",
    "        if y < 0.8:\n",
    "            y_offset = +0.4\n",
    "        # save adjusted label display position\n",
    "        label_positions.append((x_disp, y_disp + y_offset))\n",
    "        if name == \"F182M\":\n",
    "            y_offset = +0.25\n",
    "        if name == 'F212N':\n",
    "            y_offset = +0.25\n",
    "        # actually plot text in data coordinates\n",
    "        \n",
    "        ax_scat.text(\n",
    "            x, y + y_offset,\n",
    "            name,\n",
    "            ha=\"center\", va=\"top\",\n",
    "            fontsize=fontsize_sm, rotation = 90, color = color,\n",
    "            bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.7, pad=0.5)\n",
    "        )\n",
    "\n",
    "    show_image_files = [x for x in image_files if extract_filter_name(x) in show_images]\n",
    "    image_locations = [(0.05, 0.75, 0.2, 0.2), (0.3, 0.75, 0.2, 0.2), (0.6, 0.41, 0.2, 0.2), (0.8, 0.41, 0.2, 0.2), (0.85, 0.65, 0.18, 0.18)]\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(show_image_files, show_images)):\n",
    "        ax = fig.add_axes(image_locations[i])\n",
    "        image_file = img\n",
    "        hdu = fits.open(image_file)['SCI']\n",
    "        image = hdu.data\n",
    "        image_header = hdu.header\n",
    "        image_wcs = WCS(image_header, naxis=2)\n",
    "        pixel_scale = np.abs(image_wcs.wcs.cdelt[0]) * 3600  # arcsec/pixel\n",
    "    \n",
    "        loc_sky = SkyCoord(ra=results['location'][0]*u.deg, dec=results['location'][1]*u.deg, frame='icrs')\n",
    "        cutout = Cutout2D(data = image, position = loc_sky, size = (results['radius']*3, results['radius']*3), wcs = image_wcs)\n",
    "        ax.set_title('F115W image with bump apertures', fontsize = 30)\n",
    "        x_img, y_img = cutout.wcs.all_world2pix(loc_sky.ra, loc_sky.dec, 0)\n",
    "        im = ax.imshow(cutout.data, origin='lower', cmap='viridis',\n",
    "                              norm=ImageNormalize(cutout.data, stretch=AsinhStretch(), vmin=0, vmax=np.percentile(cutout.data, 99)))\n",
    "        ax.add_patch(Circle((x_img, y_img), (results['radius'].to(u.arcsec).value)/pixel_scale, ec='red', fc='none', lw=3, ls='-', alpha = 0.7))\n",
    "        cbar = plt.colorbar(\n",
    "            im,\n",
    "            ax=ax,\n",
    "            fraction=0.046,\n",
    "            pad=0.04\n",
    "        )\n",
    "        cbar.ax.tick_params(labelsize = fontsize_lg)\n",
    "        ax.set_title(title, fontsize = fontsize_lg)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    \n",
    "    ymin, ymax = ax_scat.get_ylim()\n",
    "    text_y_pos = ymin * 1.1\n",
    "    ax_scat.axhline(y = 1, color = 'gray', linestyle = '--', linewidth = 4, alpha = 0.5)\n",
    "    ax_scat.axvline(x=7.650000025896587e-06, color='gray', linestyle='--', linewidth=4, alpha=0.7)\n",
    "    ax_scat.text(7.25e-6, text_y_pos, \"← NIRCam\", \n",
    "                 ha='right', va='center', \n",
    "                 bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "                 fontsize=fontsize_lg)\n",
    "    \n",
    "    # Add MIRI label to the right\n",
    "    ax_scat.text(8e-6, text_y_pos, \"MIRI →\", \n",
    "             ha='left', va='center', \n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "             fontsize=fontsize_lg)\n",
    "    ax_spec.legend(loc = 'upper left', bbox_to_anchor=(1, 1), fontsize = fontsize_lg)\n",
    "    print('mean ratio : ', np.mean(results[correction+'_synthetic_fluxes']/results['photo_fluxes']))\n",
    "    print('ratio std : ', np.std(results[correction+'_synthetic_fluxes']/results['photo_fluxes']))\n",
    "    correction_factors = np.array(results[correction+'_correction_values'])\n",
    "    print('corrections per solid angle : ', correction_factors/(np.pi*(results['radius'].value)**2))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_and_synth('F1500W', full_raw_ifu_files_loc0, locations[0], radius, image_files=v0p3_images, color_min_max = [1, 99.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Ip25 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 1.25*u.arcsec)\n",
    "plot_results(Ip25, correction = 'mult')\n",
    "plot_results(Ip25, correction = 'add')\n",
    "\n",
    "Ip0 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 1*u.arcsec)\n",
    "plot_results(Ip0, correction = 'mult')\n",
    "plot_results(Ip0, correction = 'add')\n",
    "\n",
    "Op75 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 0.75*u.arcsec)\n",
    "plot_results(Op75, correction = 'mult')\n",
    "plot_results(Op75, correction = 'add')\n",
    "\n",
    "Op5 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 0.5*u.arcsec)\n",
    "plot_results(Op5, correction = 'mult')\n",
    "plot_results(Op5, correction = 'add')\n",
    "\n",
    "Op25 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 0.25*u.arcsec)\n",
    "plot_results(Op25, correction = 'mult')\n",
    "plot_results(Op25, correction = 'add')\n",
    "\n",
    "Op1 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 0.1*u.arcsec)\n",
    "plot_results(Op1, correction = 'mult')\n",
    "plot_results(Op1, correction = 'add')\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "loc1_Ip25 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[1], 1.25*u.arcsec)\n",
    "plot_results(loc1_Ip25, correction = 'mult')\n",
    "plot_results(loc1_Ip25, correction = 'add')\n",
    "\n",
    "loc1_Ip0 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[1], 1*u.arcsec)\n",
    "plot_results(loc1_Ip0, correction = 'mult')\n",
    "plot_results(loc1_Ip0, correction = 'add')\n",
    "\n",
    "loc1_Op75 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[1], 0.75*u.arcsec)\n",
    "plot_results(loc1_Op75, correction = 'mult')\n",
    "plot_results(loc1_Op75, correction = 'add')\n",
    "\n",
    "loc1_Op5 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[1], 0.5*u.arcsec)\n",
    "plot_results(loc1_Op5, correction = 'mult')\n",
    "plot_results(loc1_Op5, correction = 'add')\n",
    "\n",
    "loc1_Op25 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[1], 0.25*u.arcsec)\n",
    "plot_results(loc1_Op25, correction = 'mult')\n",
    "plot_results(loc1_Op25, correction = 'add')\n",
    "\n",
    "loc1_Op1 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[1], 0.1*u.arcsec)\n",
    "plot_results(loc1_Op1, correction = 'mult')\n",
    "plot_results(loc1_Op1, correction = 'add')\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "loc2_Ip25 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[2], 1.25*u.arcsec)\n",
    "plot_results(loc2_Ip25, correction = 'mult')\n",
    "plot_results(loc2_Ip25, correction = 'add')\n",
    "\n",
    "loc2_Ip0 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[2], 1*u.arcsec)\n",
    "plot_results(loc2_Ip0, correction = 'mult')\n",
    "plot_results(loc2_Ip0, correction = 'add')\n",
    "\n",
    "loc2_Op75 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[2], 0.75*u.arcsec)\n",
    "plot_results(loc2_Op75, correction = 'mult')\n",
    "plot_results(loc2_Op75, correction = 'add')\n",
    "\n",
    "loc2_Op5 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[2], 0.5*u.arcsec)\n",
    "plot_results(loc2_Op5, correction = 'mult')\n",
    "plot_results(loc2_Op5, correction = 'add')\n",
    "\n",
    "loc2_Op25 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[2], 0.25*u.arcsec)\n",
    "plot_results(loc2_Op25, correction = 'mult')\n",
    "plot_results(loc2_Op25, correction = 'add')\n",
    "\n",
    "loc2_Op1 = create_data(full_raw_ifu_files_loc1, v0p3_images, filter_files, locations[2], 0.1*u.arcsec)\n",
    "plot_results(loc2_Op1, correction = 'mult')\n",
    "plot_results(loc2_Op1, correction = 'add')\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "loc3_Ip25 = create_data(full_raw_ifu_files_loc3, v0p3_images, filter_files, locations[3], 1.25*u.arcsec)\n",
    "plot_results(loc3_Ip25, correction = 'mult')\n",
    "plot_results(loc3_Ip25, correction = 'add')\n",
    "\n",
    "loc3_Ip0 = create_data(full_raw_ifu_files_loc3, v0p3_images, filter_files, locations[3], 1*u.arcsec)\n",
    "plot_results(loc3_Ip0, correction = 'mult')\n",
    "plot_results(loc3_Ip0, correction = 'add')\n",
    "\n",
    "loc3_Op75 = create_data(full_raw_ifu_files_loc3, v0p3_images, filter_files, locations[3], 0.75*u.arcsec)\n",
    "plot_results(loc3_Op75, correction = 'mult')\n",
    "plot_results(loc3_Op75, correction = 'add')\n",
    "\n",
    "loc3_Op5 = create_data(full_raw_ifu_files_loc3, v0p3_images, filter_files, locations[3], 0.5*u.arcsec)\n",
    "plot_results(loc3_Op5, correction = 'mult')\n",
    "plot_results(loc3_Op5, correction = 'add')\n",
    "\n",
    "loc3_Op25 = create_data(full_raw_ifu_files_loc3, v0p3_images, filter_files, locations[3], 0.25*u.arcsec)\n",
    "plot_results(loc3_Op25, correction = 'mult')\n",
    "plot_results(loc3_Op25, correction = 'add')\n",
    "\n",
    "loc3_Op1 = create_data(full_raw_ifu_files_loc3, v0p3_images, filter_files, locations[3], 0.1*u.arcsec)\n",
    "plot_results(loc3_Op1, correction = 'mult')\n",
    "plot_results(loc3_Op1, correction = 'add')\n",
    "\n",
    "loc0_sets = [Ip25, Ip0, Op75, Op5, Op25, Op1]\n",
    "loc1_sets = [loc1_Ip25, loc1_Ip0, loc1_Op75, loc1_Op5, loc1_Op25, loc1_Op1]\n",
    "loc2_sets = [loc2_Ip25, loc2_Ip0, loc2_Op75, loc2_Op5, loc2_Op25, loc2_Op1]\n",
    "loc3_sets = [loc3_Ip25, loc3_Ip0, loc3_Op75, loc3_Op5, loc3_Op25, loc3_Op1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in loc0_sets:\n",
    "    plot_results(set, correction = 'mult', show_images = ['F560W', 'F2100W'], color_min_max = [1, 99.5])\n",
    "for set in loc1_sets:\n",
    "    plot_results(set, correction = 'mult', show_images = ['F560W', 'F2100W'], color_min_max = [1, 99.5])\n",
    "for set in loc2_sets:\n",
    "    plot_results(set, correction = 'mult', show_images = ['F560W', 'F2100W'], color_min_max = [1, 99.5])\n",
    "for set in loc3_sets:\n",
    "    plot_results(set, correction = 'mult', show_images = ['F560W', 'F2100W'], color_min_max = [1, 99.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_synth(filter, ifu_fileset, loc, radius, image_files=v0p3_images):\n",
    "    \"\"\"\n",
    "    Show real image and synthetic IFU-derived image side by side.\n",
    "    Works with either one or two IFU cubes.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Location handling\n",
    "    # ------------------------------------------------------------\n",
    "    if not isinstance(loc, SkyCoord):\n",
    "        loc_sky = SkyCoord(ra=loc[0] * u.deg, dec=loc[1] * u.deg, frame=\"icrs\")\n",
    "    else:\n",
    "        loc_sky = loc\n",
    "\n",
    "    def nearest_spaxel_map(cube_src, cube_target):\n",
    "        ny, nx = cube_target.shape[1:]\n",
    "        y_t, x_t = np.mgrid[:ny, :nx]\n",
    "\n",
    "        world = cube_target.wcs.celestial.pixel_to_world(x_t, y_t)\n",
    "        x_s, y_s = cube_src.wcs.celestial.world_to_pixel(world)\n",
    "\n",
    "        x_s = np.clip(np.round(x_s).astype(int), 0, cube_src.shape[2] - 1)\n",
    "        y_s = np.clip(np.round(y_s).astype(int), 0, cube_src.shape[1] - 1)\n",
    "\n",
    "        return y_s, x_s\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # Locate real image\n",
    "    # ------------------------------------------------------------\n",
    "    real_image_file = [x for x in image_files if extract_filter_name(x) == filter][0]\n",
    "    \n",
    "    short_wl, long_wl = [x.value for x in get_filter_wl_range(filter)]\n",
    "\n",
    "    needed_ifus = []\n",
    "    for file in ifu_fileset:\n",
    "        wl = SpectralCube.read(file, hdu=\"SCI\").spectral_axis.to(u.m).value\n",
    "        if (wl[0] < short_wl) and (wl[-1] > long_wl):\n",
    "            needed_ifus = [file]\n",
    "            break\n",
    "        if (long_wl > wl[0]) and (short_wl < wl[-1]):\n",
    "            needed_ifus.append(file)\n",
    "        if len(needed_ifus) > 1:\n",
    "            break\n",
    "    #\n",
    "    cube1 = SpectralCube.read(needed_ifus[0], hdu=\"SCI\")\n",
    "    cube2 = SpectralCube.read(needed_ifus[1], hdu=\"SCI\") if len(needed_ifus) > 1 else None\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Base cube quantities\n",
    "    # ------------------------------------------------------------\n",
    "    wl1 = cube1.spectral_axis.to(u.m).value\n",
    "    d1 = cube1.unmasked_data[:].value\n",
    "\n",
    "    ny, nx = cube1.shape[1:]\n",
    "    n_pix = ny * nx\n",
    "    d1 = d1.reshape(len(wl1), n_pix).T\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Stitch spectra if needed\n",
    "    # ------------------------------------------------------------\n",
    "    if cube2 is not None:\n",
    "        wl2 = cube2.spectral_axis.to(u.m).value\n",
    "        d2 = cube2.unmasked_data[:].value\n",
    "\n",
    "        y2, x2 = nearest_spaxel_map(cube2, cube1)\n",
    "        d2 = d2[:, y2, x2].reshape(len(wl2), n_pix).T\n",
    "\n",
    "        wl_all = np.concatenate([wl1, wl2])\n",
    "        sort_idx = np.argsort(wl_all)\n",
    "        wl_all = wl_all[sort_idx]\n",
    "\n",
    "        spec_all = np.concatenate([d1, d2], axis=1)[:, sort_idx]\n",
    "\n",
    "        wl_min = max(wl1.min(), wl2.min())\n",
    "        wl_max = min(wl1.max(), wl2.max())\n",
    "        overlap = (wl_all >= wl_min) & (wl_all <= wl_max)\n",
    "        both = np.isin(wl_all, wl1) & np.isin(wl_all, wl2) & overlap\n",
    "        spec_all[:, both] *= 0.5\n",
    "    else:\n",
    "        wl_all = wl1\n",
    "        spec_all = d1\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Synthetic photometry\n",
    "    # ------------------------------------------------------------\n",
    "    filter_wl, filter_trans = get_filter_data(filter)\n",
    "\n",
    "    image = np.empty(n_pix)\n",
    "    for i in range(n_pix):\n",
    "        image[i] = get_Fnu_transmission(\n",
    "            spec_all[i], wl_all, filter_trans, filter_wl, warnings=True\n",
    "        )\n",
    "\n",
    "    synth_image = image.reshape(ny, nx)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Attach WCS to synthetic image\n",
    "    # ------------------------------------------------------------\n",
    "    synth_hdu = fits.PrimaryHDU(\n",
    "        synth_image,\n",
    "        header=cube1.wcs.celestial.to_header()\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot real vs synthetic\n",
    "    # ------------------------------------------------------------\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # -------------------------\n",
    "    # REAL IMAGE\n",
    "    # -------------------------\n",
    "    hdu = fits.open(real_image_file)[\"SCI\"]\n",
    "    real_pix_size = hdu.header['PIXAR_A2']**0.5\n",
    "    aperture_radius = radius.to(u.arcsec).value / real_pix_size\n",
    "    cutout_real = Cutout2D(\n",
    "        hdu.data,\n",
    "        position=loc_sky,\n",
    "        size=(radius * 3, radius * 3),\n",
    "        wcs=WCS(hdu.header)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # SYNTHETIC IMAGE (WCS CUTOUT)\n",
    "    # -------------------------\n",
    "    cutout_synth = Cutout2D(\n",
    "        synth_hdu.data,\n",
    "        position=loc_sky,\n",
    "        size=(radius * 3, radius * 3),\n",
    "        wcs=WCS(synth_hdu.header)\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Shared normalization (1–99%)\n",
    "    # ------------------------------------------------------------\n",
    "    combined = np.concatenate([\n",
    "        cutout_real.data[np.isfinite(cutout_real.data)],\n",
    "        cutout_synth.data[np.isfinite(cutout_synth.data)]\n",
    "    ])\n",
    "\n",
    "    vmin = np.percentile(combined, 1)\n",
    "    vmax = np.percentile(combined, 99.5)\n",
    "\n",
    "    cmap = plt.get_cmap(\"viridis\").copy()\n",
    "    cmap.set_under(\"black\")\n",
    "    cmap.set_over(\"white\")\n",
    "    norm = colors.Normalize(vmin=vmin, vmax=vmax, clip=False)\n",
    "\n",
    "    pix_scale = np.abs(cutout_synth.wcs.wcs.cdelt[0]) * 3600\n",
    "    r_ap_pix = radius.to(u.arcsec).value / pix_scale\n",
    "\n",
    "    # -------------------------\n",
    "    # PLOT REAL\n",
    "    # -------------------------\n",
    "    im0 = axes[0].imshow(\n",
    "        cutout_real.data,\n",
    "        origin=\"lower\",\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "    axes[0].set_title(f\"{filter} – Real\")\n",
    "\n",
    "    cbar0 = plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    cbar0.set_label(\"Flux\", fontsize=14)\n",
    "    cbar0.ax.tick_params(labelsize=12)\n",
    "\n",
    "    x_r, y_r = cutout_real.wcs.world_to_pixel(loc_sky)\n",
    "    axes[0].add_patch(\n",
    "        Circle((x_r, y_r), aperture_radius, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # PLOT SYNTHETIC\n",
    "    # -------------------------\n",
    "    im1 = axes[1].imshow(\n",
    "        cutout_synth.data,\n",
    "        origin=\"lower\",\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "    axes[1].set_title(f\"{filter} – Synthetic (IFU)\")\n",
    "\n",
    "    cbar1 = plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    cbar1.set_label(\"Flux\", fontsize=14)\n",
    "    cbar1.ax.tick_params(labelsize=12)\n",
    "\n",
    "    x_s, y_s = cutout_synth.wcs.world_to_pixel(loc_sky)\n",
    "    axes[1].add_patch(\n",
    "        Circle((x_s, y_s), r_ap_pix, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Cleanup\n",
    "    # -------------------------\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Ip25 = create_data(full_raw_ifu_files_loc0, v0p3_images, filter_files, locations[0], 1.25*u.arcsec)\n",
    "\n",
    "plot_results(Ip25, correction = 'mult', show_images = ['F560W', 'F2100W'], color_min_max = [1, 99.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in loc1_sets:\n",
    "    plot_results(set, correction = 'mult', show_images = ['F115W', 'F2100W'], color_min_max = [1, 99.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v0p3_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
