{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "from astropy.visualization import AsinhStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import SqrtStretch \n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "from astropy.visualization import AsinhStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import SqrtStretch \n",
    "#TJ define functions needed to generate files\n",
    "os.chdir('/d/ret1/Taylor/jupyter_notebooks/Research') #TJ change working directory to be the parent directory\n",
    "from Py_files.Basic_analysis import *\n",
    "\n",
    "\n",
    "def extract_filter_name(filename):\n",
    "    '''extract entire filter name, for example: F164N\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file_name : type = str - name of filter's fits file of format similar to ngc5194_nircam_1v3_f164n_i2d.fits\n",
    "        *note*: function keys on the \"_\" and .fits to get filter name, requires lower case filter names, see generalized \"sort_filters\" function\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    filter name as string\n",
    "    '''   \n",
    "    # For .fits files: ngc5194_nircam_1v3_f164n_i2d.fits → \"f164n\"\n",
    "    if filename.endswith('.fits'):\n",
    "        parts = os.path.basename(filename).split('_')\n",
    "        for part in parts:\n",
    "            if part.startswith('f') and part[1:].replace('n', '').replace('w', '').replace('m', '').isdigit():\n",
    "                return part.lower()\n",
    "    # For .dat files: F070M.dat → \"f070m\"\n",
    "    elif filename.endswith('.dat'):\n",
    "        return os.path.splitext(os.path.basename(filename))[0].lower()\n",
    "    return None\n",
    "\n",
    "def get_filter_number(filter_name):\n",
    "    '''extracts numbers from filter name (drops F, N, W, etc from the ends)\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter_files : type = list - list of filter names\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    filter name as string\n",
    "    '''   \n",
    "    match = re.search(r'[A-Za-z](\\d+)[A-Za-z]', filter_name)  # Numbers between ANY letters\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def generate_list_of_files():\n",
    "    '''cross-matches files in filter_directory to filters with images in image_directory, sorts by filter number\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    none \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    list of arrays, first entry is the image file array, second is the filter file array, both sorted by filter numer (in name)\n",
    "    '''   \n",
    "    filter_directory = '/d/crow1/tools/cigale/database_builder/filters/jwst/'\n",
    "    path = ['nircam', 'miri']\n",
    "    filter_files = np.concatenate([glob.glob(os.path.join(filter_directory + file_path, \"*.dat\")) for file_path in path])\n",
    "    image_directory = 'Data_files/Image_files'\n",
    "    image_files = glob.glob(os.path.join(image_directory, \"*.fits\"))\n",
    "    # Initialize aligned lists\n",
    "    image_file_array = []\n",
    "    filter_file_array = []\n",
    "    \n",
    "    # Loop through .fits files and find matching .dat files\n",
    "    for fits_file in image_files:\n",
    "        fits_filter = extract_filter_name(fits_file)\n",
    "        if not fits_filter:\n",
    "            continue  # Skip if no filter name found\n",
    "        \n",
    "        # Search for matching .dat file\n",
    "        for dat_file in filter_files:\n",
    "            dat_filter = extract_filter_name(dat_file)\n",
    "            if dat_filter == fits_filter:\n",
    "                image_file_array.append(fits_file)\n",
    "                filter_file_array.append(dat_file)\n",
    "                break  # Stop searching after first match\n",
    "    filter_name_array = [f.split(\"/\")[-1] for f in filter_file_array] #TJ generate array of just the filter names\n",
    "    filter_numbers = np.array([get_filter_number(file) for file in filter_name_array]) #TJ generate array of just filter numbers\n",
    "    sort_indices = np.argsort(filter_numbers) #TJ sort by these numbers\n",
    "    sorted_filter_names = np.array(filter_file_array)[sort_indices]\n",
    "    sorted_image_files = np.array(image_file_array)[sort_indices]\n",
    "    return sorted_image_files, sorted_filter_names\n",
    "#TJ define data paths and location info\n",
    "\n",
    "karin_SDuval_IFU_files = ['Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch4-shortmediumlong_s3d.fits'\n",
    "            ]\n",
    "\n",
    "karin_IFU_files = [ 'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch4-shortmediumlong_s3d.fits',\n",
    "            ]\n",
    "Thomas_IFU_file = 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'\n",
    "\n",
    "SDuval_IFU_files = ['Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch4-shortmediumlong_s3d.fits']\n",
    "\n",
    "Grant_conv_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "pivot_files = []\n",
    "for i in range(1,8):\n",
    "    pivot_files.append(f'Data_files/IFU_files/convolved_to_2100_part{i}.fits')\n",
    "jw_files = glob.glob('Data_files/IFU_files/my_convolutions/*/jw*')\n",
    "sw_files = glob.glob('Data_files/IFU_files/my_convolutions/*/SW*')\n",
    "my_convolutions = np.concatenate([jw_files, sw_files])\n",
    "image_files, filter_files = generate_list_of_files()\n",
    "filter_names = ['F115W', 'F140M', 'F150W', 'F164N', 'F182M', 'F187N', 'F200W', 'F210M', 'F212N', 'F250M', 'F300M', 'F335M', 'F360M', 'F405N', \n",
    "           'F430M', 'F444W', 'F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W'] \n",
    "loc = [202.4340450, 47.1732517]\n",
    "test_loc = [202.43357, 47.17296]\n",
    "\n",
    "radius = 0.75*u.arcsec\n",
    "with open('Data_files/misc_data/flux_v_radius/maximum_radii.dic', 'rb') as f:\n",
    "    radius_dict = pickle.load(f)\n",
    "\n",
    "def get_filter_wl_range(filter):\n",
    "    '''Use the filter files to determine what wavelength range we need for each filter\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter : type = str - string describing the filter name (case sensitive), for example \"F335M\"\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    Path to newly convolved file as a string\n",
    "    '''   \n",
    "    _, filter_files = generate_list_of_files()\n",
    "    filter_file = [filer_filepath for filer_filepath in filter_files if extract_filter_name(filer_filepath).upper() == filter][0]\n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    return filter_wl[0]*u.m, filter_wl[-1]*u.m\n",
    "\n",
    "def plot_integrated_aperture_overlay(IFU_file, image_file, loc, radius, zoom_scale=5):\n",
    "    \"\"\"Display wavelength-integrated IFU data alongside 2D image.\"\"\"\n",
    "    from astropy.nddata import block_reduce\n",
    "    \n",
    "    def load_data(file):\n",
    "        with fits.open(file) as hdul:\n",
    "            for ext in [1, 'SCI', 0]:\n",
    "                try:\n",
    "                    data = hdul[ext].data\n",
    "                    header = hdul[ext].header\n",
    "                    if data is not None:\n",
    "                        # Get 2D celestial WCS\n",
    "                        wcs = WCS(header, naxis=2)\n",
    "                        if data.ndim == 3:\n",
    "                            # Sum over wavelength axis (axis=0)\n",
    "                            integrated_data = np.nansum(data, axis=0)\n",
    "                            return integrated_data, header, wcs\n",
    "                        return data, header, wcs\n",
    "                except (KeyError, IndexError):\n",
    "                    continue\n",
    "        raise ValueError(f\"No valid data found in {file}\")\n",
    "\n",
    "    # Load and integrate IFU data\n",
    "    ifu_integrated, ifu_header, ifu_wcs = load_data(IFU_file)\n",
    "    image_data, image_header, image_wcs = load_data(image_file)\n",
    "    # Convert location to pixels\n",
    "    loc_sky = SkyCoord(ra=loc[0]*u.deg, dec=loc[1]*u.deg, frame='icrs')\n",
    "    x_ifu, y_ifu = ifu_wcs.all_world2pix(loc_sky.ra, loc_sky.dec, 0)\n",
    "    x_img, y_img = image_wcs.all_world2pix(loc_sky.ra, loc_sky.dec, 0)\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    # Plot integrated IFU data\n",
    "    ax1 = fig.add_subplot(121, projection=ifu_wcs)\n",
    "    im1 = ax1.imshow(ifu_integrated, origin='lower', cmap='viridis',\n",
    "                    norm=ImageNormalize(ifu_integrated, stretch=AsinhStretch(0.1)))\n",
    "    fig.colorbar(im1, ax=ax1, label='Integrated Flux')\n",
    "    ax1.set_title('IFU Data (λ-integrated)')\n",
    "\n",
    "    # Plot Image\n",
    "    ax2 = fig.add_subplot(122, projection=image_wcs)\n",
    "    im2 = ax2.imshow(image_data, origin='lower', cmap='viridis',\n",
    "                    norm=ImageNormalize(image_data/8, stretch=SqrtStretch()))\n",
    "    fig.colorbar(im2, ax=ax2, label='Flux')\n",
    "    ax2.set_title('Image Data')\n",
    "\n",
    "    # Add apertures and set zoom\n",
    "    for ax, (x, y), wcs in zip([ax1, ax2], [(x_ifu, y_ifu), (x_img, y_img)], [ifu_wcs, image_wcs]):\n",
    "        pixel_scale = np.abs(wcs.wcs.cdelt[0]) * 3600  # arcsec/pixel\n",
    "        radius_pix = radius.to(u.arcsec).value / pixel_scale\n",
    "        ax.add_patch(Circle((x, y), radius_pix, ec='red', fc='none', lw=2, ls='--'))\n",
    "        \n",
    "        # Set zoom (5x aperture radius by default)\n",
    "        zoom_width = zoom_scale * radius_pix\n",
    "        ax.set_xlim(x - zoom_width, x + zoom_width)\n",
    "        ax.set_ylim(y - zoom_width, y + zoom_width)\n",
    "    \n",
    "    plt.suptitle(f\"Aperture Radius: {radius}\", y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_convolved_filter_name(file):\n",
    "    '''Extracts \"F115W\" from 'Data_files/IFU_files/f100lp_s3dIFU_convolved_tof115w.fits'\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file : type = str - string of a convolved IFU\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    filter_name : type = str - string with capital letters representing the filter name\n",
    "    '''   \n",
    "    return file.split(\"convolved_to\")[1].split(\".f\")[0].upper()\n",
    "\n",
    "def full_coverage(filter_name, IFU_file):\n",
    "    '''Checks if the IFU has full filter converage or not'''\n",
    "    filter_coverage = get_filter_wl_range(filter_name)\n",
    "    cube = SpectralCube.read(IFU_file, hdu = 'SCI')\n",
    "    cube_range = [cube.spectral_axis[0], cube.spectral_axis[-1]]\n",
    "    if filter_coverage[0] < cube_range[0]:\n",
    "        return 'missing shorter'\n",
    "    if filter_coverage[1] > cube_range[1]:\n",
    "        return'missing longer'\n",
    "    else:\n",
    "        return 'good'\n",
    "\n",
    "def get_aperture_flux(file, loc, radius, show_plot= False, zoom = None):\n",
    "    '''display image of fits file, with aperture with radius at location, can also specify zoom\n",
    "    -------------\n",
    "    Parameters\n",
    "    -------------\n",
    "    file : type = str - string to fits file you want to display, can be a list of locations (len(loc) must equal len(radius))\n",
    "    loc : type = either [ra, dec] in degrees, or a SkyCoord object - location of center of the aperture\n",
    "    radius : type = angular unit - radius of aperture with units attached\n",
    "    show_plot (optional, defaults to false) : type = Boolean - show png of image?\n",
    "    zoom : type = angular unit, or list of units - width and height of the fov in the image if single value, if list [width, height]\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    flux : type = float - in units of the image file, total flux through aperture.\n",
    "    '''   \n",
    "\n",
    "    hdul = fits.open(file)\n",
    "    data = hdul[0].data\n",
    "    header = hdul[0].header\n",
    "    pix_area = header[\"PIXAR_SR\"]\n",
    "    # Create WCS object\n",
    "    wcs = WCS(header)\n",
    "\n",
    "    # Plot with imshow_norm\n",
    "    if show_plot:\n",
    "        try:\n",
    "            plt.figure(figsize = (8,8*zoom[1]/zoom[0]))\n",
    "        except:\n",
    "            plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(projection=wcs)\n",
    "        norm = simple_norm(data, stretch='asinh', percent=96.9)\n",
    "        im = ax.imshow(data, norm=norm, cmap='gray', origin='lower')\n",
    "        \n",
    "        # Add RA/Dec gridlines and labels\n",
    "        ax.coords.grid(True, color='white', ls='dotted')\n",
    "        ax.coords[0].set_axislabel('RA')\n",
    "        ax.coords[1].set_axislabel('Dec')\n",
    "    if (type(loc[0]) == float) or (type(loc[0])==np.float64):\n",
    "        x,y = wcs.all_world2pix(loc[0], loc[1], 0)\n",
    "        aperture = CircularAperture((x, y), r=radius.to_value(u.deg) / header['CDELT2'])\n",
    "        phot_result = aperture_photometry(data, aperture)\n",
    "        flux = phot_result['aperture_sum'][0]\n",
    "        if show_plot:\n",
    "            aperture.plot(color='red', lw=2, alpha=0.7, label=f'{flux} MJy')\n",
    "    else:\n",
    "        flux = []\n",
    "        for location in loc:\n",
    "            x,y = wcs.all_world2pix(location[0], location[1], 0)\n",
    "            aperture = CircularAperture((x, y), r=radius.to_value(u.deg) / header['CDELT2'])\n",
    "            phot_result = aperture_photometry(data, aperture)\n",
    "            this_flux = phot_result['aperture_sum'][0]*pix_area\n",
    "            flux.append(this_flux)\n",
    "            if show_plot:\n",
    "                aperture.plot(color='red', lw=2, alpha=0.7, label=f'{radius}\" Aperture')\n",
    "    if show_plot and (zoom is not None):\n",
    "        # Calculate half-width in pixels\n",
    "        pix_scale = abs(header['CDELT2']) * u.deg  # pixel scale in deg/pix\n",
    "        try:\n",
    "            npix_half_x = (zoom[0].to(u.deg) / pix_scale).value / 2\n",
    "            npix_half_y = (zoom[1].to(u.deg) / pix_scale).value / 2\n",
    "            ax.set_xlim(x - npix_half_x, x + npix_half_x)\n",
    "            ax.set_ylim(y - npix_half_y, y + npix_half_y)\n",
    "        except:\n",
    "            npix_half = (zoom.to(u.deg) / pix_scale).value / 2\n",
    "            ax.set_xlim(x - npix_half, x + npix_half)\n",
    "            ax.set_ylim(y - npix_half, y + npix_half)\n",
    "    if show_plot:\n",
    "        ax.legend()\n",
    "\n",
    "        # Colorbar\n",
    "        plt.colorbar(im, ax=ax, orientation='vertical', label='Flux')\n",
    "        \n",
    "        plt.title(f\"{file.split('.fi')[0].split('/')[-1].split('/')[-1]}\")\n",
    "        plt.show()\n",
    "    return flux\n",
    "\n",
    "def get_Fnu_transmission(Fnu_array, wl_array, transmission_array, trans_wl_array):\n",
    "    '''get expected flux through filter in units of whatever the flux_array is. Make sure to convert to mks units\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    Fnu_array : type = array - array of flux density values\n",
    "    wl_array : type = array - array of wavelength values for the corresponding Fnu_array values (should be in meters)\n",
    "    transmission_array : type = array - array of unitless transmission coefficient\n",
    "    trans_wl_array : type = array - array of wavelength values for the corresponding transmission values (should be in meters)\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    total_flux : type = float - in units of flux_array\n",
    "    '''   \n",
    "    if ((trans_wl_array[0] < wl_array[0]) or (trans_wl_array[-1] > wl_array[-1])): #TJ Check if wavelengths are compatible with filter\n",
    "        print(f'filter goes from {trans_wl_array[0]} to {trans_wl_array[-1]}, but provided Fnu array goes from {wl_array[0]} to {wl_array[-1]}')\n",
    "        idx_start = np.searchsorted(trans_wl_array, wl_array[0], side='left')\n",
    "        idx_end = np.searchsorted(trans_wl_array, wl_array[-1], side='right')\n",
    "        \n",
    "        # Expand by one index if possible\n",
    "        idx_start = max(0, idx_start - 1)  # Include one lower index\n",
    "        idx_end = min(len(trans_wl_array), idx_end + 1)  # Include one higher index\n",
    "        \n",
    "        # Slice transmission data\n",
    "        trans_wl_array = trans_wl_array[idx_start:idx_end]\n",
    "        transmission_array = transmission_array[idx_start:idx_end]\n",
    "    if len(trans_wl_array) == 0:\n",
    "        raise ValueError(\"No overlap between flux wavelengths and filter transmission curve\")\n",
    "    #TJ convert all arrays to numpy arrays for better indexing\n",
    "    Fnu_array = np.array(Fnu_array)\n",
    "    wl_array = np.array(wl_array)\n",
    "    transmission_array = np.array(transmission_array)\n",
    "    trans_wl_array = np.array(trans_wl_array)\n",
    "\n",
    "    \n",
    "    #TJ Convert wavelength to frequency, reverse so freq increases left to right\n",
    "    spec_freq_array = c / wl_array[::-1]\n",
    "    Fnu_array = Fnu_array[::-1]\n",
    "    trans_freq_array = c / trans_wl_array[::-1]\n",
    "    transmission_array = transmission_array[::-1]\n",
    "\n",
    "    #TJ Interpolate Fnu onto the transmission frequency grid\n",
    "    #TJ this is because jwst transmission arrays are averages over BW widths which are much coarser than Fnu is.\n",
    "    \n",
    "    interp_Fnu = np.interp(trans_freq_array, spec_freq_array, Fnu_array)\n",
    "    \n",
    "    \n",
    "    weight = transmission_array / trans_freq_array #TJ weight the numerator and denominator by T *d_nu over nu for integration\n",
    "    numerator = np.trapz(interp_Fnu * weight, trans_freq_array)#TJ perform integration\n",
    "    denominator = np.trapz(weight, trans_freq_array)\n",
    "    ab_mean_flux = numerator / denominator\n",
    "    # Numerator: Fν * Transmission / nu integrated over frequency\n",
    "    \n",
    "    return ab_mean_flux.value\n",
    "\n",
    "def which_fits(filter_file, list_of_fits):\n",
    "    '''open the filter file, determine the range of wavelengths needed to compute synthetic flux through it, return which fits files\n",
    "    are needed for this particular filter. This is to save time not convolving cubes we dont need.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter_file : type = str - string to location of filter file that we are interested in.\n",
    "    list_of_fits : type = list - list of strings to the IFU fits files that you want to check\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    needed_fits : type = list - list of strings to the fits files that are actually needed\n",
    "    '''   \n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "            header = f.readline().strip().split()\n",
    "            for line in f:\n",
    "                data_line = line.strip().split()\n",
    "                filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "\n",
    "    wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    T = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    \n",
    "    min_wl, max_wl = min(wl), max(wl)\n",
    "    needed_fits = []\n",
    "    entirely_in = []\n",
    "    for file in list_of_fits:\n",
    "        cube = SpectralCube.read(file, hdu='SCI')\n",
    "        wavelength = cube.spectral_axis\n",
    "        if (wavelength[0].value*1e-6 < max_wl) and (wavelength[-1].value*1e-6 > min_wl):\n",
    "            needed_fits.append(file)\n",
    "            if ((wavelength[0].value*1e-6 < min_wl) and (wavelength[-1].value*1e-6 > max_wl)):\n",
    "                entirely_in.append(True)\n",
    "            else:\n",
    "                entirely_in.append(False)\n",
    "    needed_fits = np.array(needed_fits)\n",
    "\n",
    "    if (sum(entirely_in) == 1):\n",
    "        return needed_fits[entirely_in]\n",
    "    elif ((len(needed_fits) > 1) & (sum(entirely_in) == 0)):\n",
    "        print(f'More than one IFU file is needed for filter {extract_filter_name(filter_file)}')\n",
    "        return needed_fits\n",
    "    elif ((len(needed_fits) > 1) & (sum(entirely_in) > 1)):\n",
    "        print(f'More than one IFU file could be used for filter {extract_filter_name(filter_file)}')\n",
    "        return needed_fits[0]\n",
    "\n",
    "def try_radii(IFU_file, filter_name, loc, show_plot = False, labeler = None, use_default = False):\n",
    "    image_candidates = [img for img in image_files if extract_filter_name(img).upper() == filter_name]\n",
    "    if not image_candidates:\n",
    "        print(f\"No matching image for filter {filter_name}\")\n",
    "    image_file = image_candidates[0]\n",
    "\n",
    "    def radius_to_size(r, radii):\n",
    "        min_radius = np.min(radii)\n",
    "        max_radius = np.max(radii)\n",
    "        # Linearly map radius to marker size between 30 and 110\n",
    "        return 30 + (r - min_radius) / (max_radius - min_radius) * (110 - 30)\n",
    "\n",
    "    filter_files_maybe = [filt for filt in filter_files if extract_filter_name(filt).upper() == filter_name]\n",
    "    if not image_candidates:\n",
    "        print(f\"No matching image for filter {filter_name}\")\n",
    "    filter_file = filter_files_maybe[0]\n",
    "\n",
    "\n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "    if len(filter_data) < 2:\n",
    "        print(f\"Filter file {filter_file} seems empty or malformed.\")\n",
    "\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = np.array([try_float(row[0]) * 1e-10 for row in filter_T])\n",
    "    filter_trans = np.array([try_float(row[1]) for row in filter_T])\n",
    "    relative_fluxes = []\n",
    "    if use_default:\n",
    "        max_radius = radius_dict[extract_filter_name(filter_file).upper()]\n",
    "    else:\n",
    "        max_radii = []\n",
    "        for IFU_file_temp in IFU_file:\n",
    "            max_radii.append(find_max_radius(IFU_file_temp, image_file, loc, min_radius=0.1*u.arcsec, max_radius=10.0*u.arcsec, tolerance=0.01*u.arcsec)[0])\n",
    "        max_radius = min(max_radii)\n",
    "    radii = np.linspace(0.1, max_radius.value, 10)\n",
    "    print(f'Using 10 radii between 0.1 and {max_radius}')\n",
    "    for radius in radii:\n",
    "        radius = radius*u.arcsec\n",
    "        photo_flux = get_image_flux(image_file, loc, radius, replace_negatives=0)\n",
    "\n",
    "        marker_size = radius_to_size(radius.value, radii)\n",
    "        spectrum = stitch_spectra(IFU_file, loc, radius, replace_negatives = 0)\n",
    "        flux = get_Fnu_transmission(spectrum['intensity'], spectrum['wavelength'], filter_trans, filter_wl)/photo_flux\n",
    "        relative_fluxes.append(flux)\n",
    "        if show_plot:\n",
    "            if not labeler:\n",
    "                scatter_point = 'o'\n",
    "            else:\n",
    "                scatter_point = labeler\n",
    "            plt.scatter(radius.value, flux, s = marker_size, marker = scatter_point)\n",
    "    return relative_fluxes, radii\n",
    "\n",
    "def is_aperture_fully_covered(IFU_file, image_file, loc, radius):\n",
    "    '''\n",
    "    Check if a circular aperture is fully within imaged regions for both IFU and image files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    IFU_file : str\n",
    "        Path to the IFU FITS file (must have WCS and SCI extension).\n",
    "    image_file : str\n",
    "        Path to the image FITS file (must have WCS and valid data).\n",
    "    loc : tuple (ra, dec)\n",
    "        Sky coordinates of the aperture center in degrees.\n",
    "    radius : float\n",
    "        Aperture radius in arcseconds.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (bool, bool)\n",
    "        (IFU_fully_covered, image_fully_covered)\n",
    "        True if aperture is fully within imaged regions for each file.\n",
    "    '''\n",
    "    def _check_coverage(file, ext):\n",
    "        # Open file and get data + WCS\n",
    "        with fits.open(file) as hdul:\n",
    "            data = hdul[ext].data\n",
    "            header = hdul[ext].header\n",
    "            wcs = WCS(header)\n",
    "            \n",
    "            # Handle 3D IFU cubes (use first wavelength slice)\n",
    "            if data.ndim == 3:\n",
    "                data = data[0]\n",
    "            \n",
    "            # Create coverage mask (1=imaged, 0=NaN/unimaged)\n",
    "            coverage_mask = np.where(np.isnan(data) | (data == 0), 0, 1)\n",
    "            \n",
    "            # Convert sky coordinates to pixel coordinates\n",
    "            loc_sky = SkyCoord(ra=loc[0] * u.deg, dec=loc[1] * u.deg, frame='icrs')\n",
    "            x_center, y_center = wcs.celestial.all_world2pix(loc_sky.ra.deg, loc_sky.dec.deg, 0)\n",
    "            \n",
    "            # Calculate pixel scale (arcsec/pixel)\n",
    "            try:\n",
    "                pixel_scale = np.abs(header['CDELT1']) * 3600  # deg -> arcsec\n",
    "            except KeyError:\n",
    "                pixel_scale = np.sqrt(header['PIXAR_A2'])  # Fallback for JWST files\n",
    "            \n",
    "            radius_pix = radius.value / pixel_scale\n",
    "            # Measure coverage\n",
    "            aperture = CircularAperture((x_center, y_center), r=radius_pix)\n",
    "            phot_table = aperture_photometry(coverage_mask, aperture)\n",
    "            measured_area = phot_table['aperture_sum'][0]\n",
    "            expected_area = np.pi * (radius_pix ** 2)\n",
    "            \n",
    "            # Allow 1-pixel tolerance for edge effects\n",
    "            return np.isclose(measured_area, expected_area, atol=1.0)\n",
    "\n",
    "    # Check IFU file (SCI extension)\n",
    "    ifu_covered = _check_coverage(IFU_file, ext='SCI')\n",
    "    \n",
    "    # Check image file (primary HDU or SCI)\n",
    "    try:\n",
    "        image_covered = _check_coverage(image_file, ext=0)  # Try primary HDU\n",
    "    except (KeyError, AttributeError):\n",
    "        image_covered = _check_coverage(image_file, ext='SCI')  # Fallback to SCI\n",
    "    \n",
    "    return (ifu_covered, image_covered)\n",
    "\n",
    "\n",
    "def find_max_radius(IFU_file, image_file, loc, min_radius=0.1*u.arcsec, max_radius=10.0*u.arcsec, tolerance=0.01*u.arcsec):\n",
    "    \"\"\"\n",
    "    Find the maximum aperture radius (arcsec) fully covered in both IFU and image files.\n",
    "    Uses binary search between min_radius and max_radius.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    IFU_file : str\n",
    "        Path to IFU FITS file.\n",
    "    image_file : str\n",
    "        Path to image FITS file.\n",
    "    loc : tuple (ra, dec)\n",
    "        Sky coordinates in degrees.\n",
    "    min_radius : float\n",
    "        Minimum aperture radius to test (arcsec).\n",
    "    max_radius : float\n",
    "        Maximum aperture radius to test (arcsec).\n",
    "    tolerance : float\n",
    "        Precision threshold for convergence (arcsec).\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Maximum fully covered radius (arcsec), or 0 if no valid radius found.\n",
    "    \"\"\"\n",
    "    def _is_covered(radius):\n",
    "        ifu_ok, image_ok = is_aperture_fully_covered(IFU_file, image_file, loc, radius)\n",
    "        return ifu_ok and image_ok\n",
    "    \n",
    "    # Binary search\n",
    "    best_radius = 0.0\n",
    "    while max_radius - min_radius > tolerance:\n",
    "        mid_radius = (min_radius + max_radius) / 2\n",
    "        if _is_covered(mid_radius):\n",
    "            best_radius = mid_radius\n",
    "            min_radius = mid_radius  # Try larger radii\n",
    "        else:\n",
    "            max_radius = mid_radius  # Try smaller radii\n",
    "    IFU_pix_scale = (fits.open(IFU_file)['SCI'].header['CDELT2']*u.deg).to(u.arcsec)\n",
    "    image_pix_scale = (fits.open(image_files[0])['SCI'].header['CDELT2']*u.deg).to(u.arcsec)\n",
    "    return (best_radius if best_radius > 0 else 0.0), best_radius/IFU_pix_scale,  best_radius/image_pix_scale\n",
    "\n",
    "def load_and_sort_convolved_Karin_spectrum(file_path):\n",
    "    '''import data and sort by wavelength from very particularly structured file\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file_path : type = str - path to file with data\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    structured array ('wavelength', 'intensity', 'uncertainty') where intensity and uncertainty are in W/m2/Hz\n",
    "    '''    \n",
    "    with open(file_path, 'r') as file:\n",
    "        header = file.readline().strip().split()\n",
    "        #TJ check first line structure for compliance\n",
    "        if ((len(header) == 3) & (type(try_float(header[0])) == type(0.1)) & (type(try_float(header[1])) == type(0.1)) & (type(try_float(header[2])) == type(0.1))):\n",
    "            data_list = []\n",
    "            data_list.append((try_float(header[0])*1e-6, try_float(header[1])*1e-20, try_float(header[2])*1e-20))\n",
    "            aperture_area_sr = (np.pi * (((0.75*u.arcsec).to(u.rad))**2)).value\n",
    "            for line in file:\n",
    "                parts = line.strip().split(maxsplit=3)\n",
    "                \n",
    "                #TJ Convert numeric columns to floats\n",
    "                wavelength = float(parts[0])*1e-6 #TJ float required for sorting\n",
    "                intensity = try_float(parts[1])*1e-20 * aperture_area_sr\n",
    "                uncertainty = try_float(parts[2])*1e-20 * aperture_area_sr\n",
    "                \n",
    "                data_list.append((wavelength, intensity, uncertainty))\n",
    "        \n",
    "            #TJ Define dtype with notes as string\n",
    "            dtype = [\n",
    "                ('wavelength', float),\n",
    "                ('intensity', float),\n",
    "                ('uncertainty', float),\n",
    "            ]\n",
    "            \n",
    "            data = np.array(data_list, dtype=dtype)\n",
    "            sorted_data = np.sort(data, order=['wavelength'])  #TJ Sort by wavelength\n",
    "            \n",
    "            return sorted_data\n",
    "        else:\n",
    "            print('''File format is not as expected. Should be 3 columns no header, if not, see \"import_data_and_sort_by_wavelength\"\n",
    "            function from Flux_calibration notebook''')\n",
    "            return None\n",
    "\n",
    "def get_image_flux(image_file, loc, radius, replace_negatives = False):\n",
    "    '''extract flux from image file with aperature of radius, centered at ra,dec = loc\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    image_file : type = str - string to location of image fits file\n",
    "    loc : type = list - ra, dec in degrees or SkyCoord object\n",
    "    radius : type = float - radius of aperture, must have units attached (like u.deg or u.arcsecond)\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    flux_density observed through filter\n",
    "    '''\n",
    "    #TJ assign location as SkyCoord object\n",
    "    if type(loc) == list:\n",
    "        spatial_coords = SkyCoord(ra=loc[0]*u.deg, dec=loc[1]*u.deg)\n",
    "    elif type(loc) == SkyCoord:\n",
    "        spatial_coords = loc\n",
    "    else:\n",
    "        print('loc is not a list of ra, dec and it is not a SkyCoord object.')\n",
    "        return None\n",
    "    hdul = fits.open(image_file) #TJ load file\n",
    "    \n",
    "    data = hdul['SCI'].data*1e-20  #TJ convert flux density to mks units\n",
    "    if replace_negatives is not False:\n",
    "        min_positive = min(data[data>0])\n",
    "        data[data<0] = replace_negatives*min_positive\n",
    "    header = hdul['SCI'].header #TJ load header\n",
    "    if header['BUNIT'] != 'MJy/sr': #TJ check if units are MJy/sr, output will be nonsensical if not\n",
    "        print('flux is NOT in MJy/sr. review get_image_flux function to fix')\n",
    "        return None\n",
    "    pix_area = header[\"PIXAR_SR\"] #TJ define the angular size of a pixel in staradians\n",
    "    wcs = WCS(header) #TJ read in the world coordinate system\n",
    "    radius_pixels = (radius).to_value(u.deg) / abs(header['CDELT2']) #TJ get the radius of the aperture in number of pixels\n",
    "    \n",
    "    #TJ Convert RA/Dec to pixel coordinates\n",
    "    x, y = wcs.all_world2pix(spatial_coords.ra.deg, spatial_coords.dec.deg, 0)\n",
    "    aperture = CircularAperture((x, y), r = radius_pixels)\n",
    "    \n",
    "    #TJ Perform aperture photometry\n",
    "    phot_result = aperture_photometry(data, aperture)\n",
    "    total_flux = phot_result['aperture_sum'][0]*pix_area  #TJ the result is in pixel units, multiply by steradians per pixel to get units right\n",
    "\n",
    "    return total_flux    \n",
    "\n",
    "\n",
    "def stitch_spectra(fits_files, loc, radius, anchor_idx=0, replace_negatives = False):\n",
    "    \"\"\"\n",
    "    Corrected stitching function that properly handles non-zero anchors\n",
    "    \"\"\"\n",
    "    # 1. Load anchor spectrum\n",
    "    anchor = get_IFU_spectrum(fits_files[anchor_idx], loc, radius, replace_negatives=replace_negatives)\n",
    "    \n",
    "    # 2. Initialize combined spectrum with anchor\n",
    "    combined = {\n",
    "        'wavelength': anchor['wavelength'].copy(),\n",
    "        'intensity': anchor['intensity'].copy()\n",
    "    }\n",
    "    \n",
    "    # 3. Stitch left side (lower wavelengths)\n",
    "    for i in reversed(range(anchor_idx)):  # Files before anchor\n",
    "        print(f'\\nStitching LEFT: file {i} to anchor')\n",
    "        current = get_IFU_spectrum(fits_files[i], loc, radius, replace_negatives = replace_negatives)\n",
    "        \n",
    "        # Left stitching should prepend the new segment\n",
    "        combined = stitch_two_spectra(current, combined, direction='left')\n",
    "    \n",
    "    # 4. Stitch right side (higher wavelengths)\n",
    "    for i in range(anchor_idx+1, len(fits_files)):\n",
    "        print(f'\\nStitching RIGHT: file {i} to combined')\n",
    "        current = get_IFU_spectrum(fits_files[i], loc, radius)\n",
    "        \n",
    "        combined = stitch_two_spectra(combined, current, direction='right')\n",
    "    print(f'Newly combined spectrum goes from {combined[\"wavelength\"][0]} to {combined[\"wavelength\"][-1]}')\n",
    "    return combined\n",
    "\n",
    "def stitch_two_spectra(spec1, spec2, direction):\n",
    "    \"\"\"Properly concatenates spectra in both directions\"\"\"\n",
    "    # Find overlap\n",
    "    if direction == 'right':\n",
    "        overlap_min = max(spec1['wavelength'][0], spec2['wavelength'][0])\n",
    "        overlap_max = min(spec1['wavelength'][-1], spec2['wavelength'][-1])\n",
    "        # Right stitching: spec1 = combined, spec2 = new right segment\n",
    "        keep_from_spec2 = spec2['wavelength'] > spec1['wavelength'][-1]\n",
    "    else:  # left\n",
    "        overlap_min = max(spec1['wavelength'][0], spec2['wavelength'][0])\n",
    "        overlap_max = min(spec1['wavelength'][-1], spec2['wavelength'][-1])\n",
    "        # Left stitching: spec1 = new left segment, spec2 = combined\n",
    "        keep_from_spec2 = spec2['wavelength'] > spec1['wavelength'][-1]  # Keep anchor's right side\n",
    "    \n",
    "    # Calculate offset\n",
    "    mask1 = (spec1['wavelength'] >= overlap_min) & (spec1['wavelength'] <= overlap_max)\n",
    "    mask2 = (spec2['wavelength'] >= overlap_min) & (spec2['wavelength'] <= overlap_max)\n",
    "    \n",
    "    interp_flux = np.interp(\n",
    "        spec1['wavelength'][mask1],\n",
    "        spec2['wavelength'][mask2],\n",
    "        spec2['intensity'][mask2]\n",
    "    )\n",
    "    offset = np.nanmedian(spec1['intensity'][mask1] - interp_flux)\n",
    "    print(f'Stitching these sections required the longer wavelength spectrum to be corrected by {offset}')\n",
    "    print(f'This corresponds to a correction of {offset/np.nanmedian(interp_flux)}')\n",
    "    # Apply correction and concatenate\n",
    "    corrected = spec2['intensity'] + offset\n",
    "    \n",
    "    if direction == 'right':\n",
    "        new_wl = np.concatenate([spec1['wavelength'], spec2['wavelength'][keep_from_spec2]])\n",
    "        new_flux = np.concatenate([spec1['intensity'], corrected[keep_from_spec2]])\n",
    "    else:  # left\n",
    "        new_wl = np.concatenate([spec1['wavelength'], spec2['wavelength'][keep_from_spec2]])\n",
    "        new_flux = np.concatenate([spec1['intensity'], corrected[keep_from_spec2]])\n",
    "    \n",
    "    return {'wavelength': new_wl, 'intensity': new_flux}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
