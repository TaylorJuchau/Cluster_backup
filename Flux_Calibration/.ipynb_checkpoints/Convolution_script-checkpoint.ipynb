{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7888211d-28f0-4d29-9124-8eaefdf64f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/d/ret1/Taylor/stpsf-data/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"STPSF_PATH\"] = \"/d/ret1/Taylor/stpsf-data/\" \n",
    "import webbpsf\n",
    "os.environ[\"STPSF_PATH\"] = \"/d/ret1/Taylor/stpsf-data/\" #TJ for some reason this only works if you do this line twice... no idea why\n",
    "\n",
    "print(os.path.exists(os.environ[\"STPSF_PATH\"]))\n",
    "print(os.environ[\"STPSF_PATH\"]) #TJ check that this kernel has access to the filter files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "from ipywidgets import interact, Dropdown\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from astropy.convolution import convolve_fft, Gaussian2DKernel\n",
    "\n",
    "\n",
    "#parent_dir = Path().resolve().parent #TJ current notebook's parent directory\n",
    "\n",
    "os.chdir('/d/ret1/Taylor/jupyter_notebooks/Research') #TJ change working directory to be the parent directory\n",
    "from Py_files.Basic_analysis import * #import basic functions from custom package\n",
    "from Py_files.Image_vs_spectra import * \n",
    "#TJ import flux calibration functions (mainly compare_IFU_to_image(IFU_filepath, image_filepath, filter_filepath, loc, radius))\n",
    "\n",
    "def get_filter_wl_range(filter):\n",
    "    '''Use the filter files to determine what wavelength range we need for each filter\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter : type = str - string describing the filter name (case sensitive), for example \"F335M\"\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    Path to newly convolved file as a string\n",
    "    '''   \n",
    "    filter_files = ['/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F115W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F140M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F150W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F164N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F182M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F187N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F200W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F210M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F212N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F250M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F300M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F335M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F360M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F405N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F430M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F444W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F560W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F770W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1000W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1130W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1280W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1500W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1800W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F2100W.dat']\n",
    "    filter_file = [filer_filepath for filer_filepath in filter_files if extract_filter_name(filer_filepath).upper() == filter][0]\n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    return filter_wl[0]*u.m, filter_wl[-1]*u.m\n",
    "\n",
    "def convolve(IFU_fits_file, instrument, filter, output_file = None):\n",
    "    '''Convolve an IFU cube to the PSF of the provided filter.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    IFU_fits_file : type = str - string to location of IFU fits that you want to convolve.\n",
    "    instrument : type = str - Either \"MIRI\" or \"NIRCam\" depending on wavelength\n",
    "    filter : type = str - string describing the filter name (case sensitive), for example \"F335M\"\n",
    "    output_file (optional, defaults to use the IFU_file with _convolved_to_{filter}) : type = str - name of the convolved file\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    Path to newly convolved file as a string\n",
    "    '''   \n",
    "\n",
    "    IFU_hdul = fits.open(IFU_fits_file)\n",
    "    header = IFU_hdul[\"SCI\"].header\n",
    "    cube = SpectralCube.read(IFU_fits_file, hdu='SCI')\n",
    "    spectral_axis = cube.spectral_axis  #TJ in meters\n",
    "    # === Load webbpsf instrument ===\n",
    "    if instrument == 'NIRCam':\n",
    "        inst = webbpsf.NIRCam()\n",
    "    elif instrument == \"MIRI\":\n",
    "        inst = webbpsf.MIRI()\n",
    "    inst.filter = filter\n",
    "\n",
    "    # === Prepare output cube ===\n",
    "    convolved_data = np.zeros_like(cube.unmasked_data[:].value)\n",
    "    tqdm_kwargs = {\n",
    "        'dynamic_ncols': True,  # Auto-adjusts width\n",
    "        'mininterval': 0.5,     # Update every 0.5 seconds (optional)\n",
    "        'position': 0,          # Fix position (set to 0 for notebooks)\n",
    "        'leave': True           # Leaves progress bar after completion\n",
    "    }\n",
    "    # === Loop through wavelengths and convolve ===\n",
    "    for i, wavelength in enumerate(tqdm(spectral_axis, desc=f\"Convolving to {filter}\")):\n",
    "        psf = inst.calc_psf(monochromatic=wavelength.to(u.m).value)    \n",
    "        psf_data = psf[0].data\n",
    "        psf_data /= psf_data.sum()  # Normalize PSF to conserve flux\n",
    "    \n",
    "        image_slice = cube.filled_data[...].value[i]  # 2D image at this wavelength\n",
    "        convolved_slice = convolve_fft(image_slice, psf_data, normalize_kernel=True, boundary='fill', fill_value=0)\n",
    "        convolved_data[i] = convolved_slice\n",
    "    \n",
    "    # === Save the convolved cube ===\n",
    "    out_hdu = fits.PrimaryHDU(convolved_data, header=header)\n",
    "    if output_file:\n",
    "        out_hdu.writeto(f\"Data_files/IFU_files/{output_file}\", overwrite=True)\n",
    "        print(f\"✅ PSF convolution complete and saved as {output_file}\")\n",
    "        return f\"Data_files/IFU_files/{output_file}\"\n",
    "    else:\n",
    "        out_hdu.writeto(f\"Data_files/IFU_files/{IFU_fits_file}_convolved_to_{filter}.fits\", overwrite=True)\n",
    "        print(f\"✅ PSF convolution complete and saved as {IFU_fits_file}_convolved_to_{filter}\")\n",
    "        return f\"Data_files/IFU_files/{IFU_fits_file}_convolved_to_{filter}.fits\"\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8decd32b-f07f-47dc-8020-9be0b3883fef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     IFU_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m     instrument \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMIRI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m IFU_hdul \u001b[38;5;241m=\u001b[39m fits\u001b[38;5;241m.\u001b[39mopen(IFU_filepath)\n\u001b[1;32m     27\u001b[0m header \u001b[38;5;241m=\u001b[39m IFU_hdul[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mheader\n\u001b[1;32m     28\u001b[0m cube \u001b[38;5;241m=\u001b[39m SpectralCube\u001b[38;5;241m.\u001b[39mread(IFU_filepath, hdu\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/astropy/io/fits/hdu/hdulist.py:220\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HDUList\u001b[38;5;241m.\u001b[39mfromfile(\n\u001b[1;32m    221\u001b[0m     name,\n\u001b[1;32m    222\u001b[0m     mode,\n\u001b[1;32m    223\u001b[0m     memmap,\n\u001b[1;32m    224\u001b[0m     save_backup,\n\u001b[1;32m    225\u001b[0m     cache,\n\u001b[1;32m    226\u001b[0m     lazy_load_hdus,\n\u001b[1;32m    227\u001b[0m     ignore_missing_simple,\n\u001b[1;32m    228\u001b[0m     use_fsspec\u001b[38;5;241m=\u001b[39muse_fsspec,\n\u001b[1;32m    229\u001b[0m     fsspec_kwargs\u001b[38;5;241m=\u001b[39mfsspec_kwargs,\n\u001b[1;32m    230\u001b[0m     decompress_in_memory\u001b[38;5;241m=\u001b[39mdecompress_in_memory,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    232\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/astropy/io/fits/hdu/hdulist.py:484\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    476\u001b[0m ):\n\u001b[1;32m    477\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_readfrom(\n\u001b[1;32m    485\u001b[0m         fileobj\u001b[38;5;241m=\u001b[39mfileobj,\n\u001b[1;32m    486\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    487\u001b[0m         memmap\u001b[38;5;241m=\u001b[39mmemmap,\n\u001b[1;32m    488\u001b[0m         save_backup\u001b[38;5;241m=\u001b[39msave_backup,\n\u001b[1;32m    489\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    490\u001b[0m         ignore_missing_simple\u001b[38;5;241m=\u001b[39mignore_missing_simple,\n\u001b[1;32m    491\u001b[0m         lazy_load_hdus\u001b[38;5;241m=\u001b[39mlazy_load_hdus,\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    493\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/astropy/io/fits/hdu/hdulist.py:1186\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m _File(\n\u001b[1;32m   1187\u001b[0m             fileobj,\n\u001b[1;32m   1188\u001b[0m             mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   1189\u001b[0m             memmap\u001b[38;5;241m=\u001b[39mmemmap,\n\u001b[1;32m   1190\u001b[0m             cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1191\u001b[0m             use_fsspec\u001b[38;5;241m=\u001b[39muse_fsspec,\n\u001b[1;32m   1192\u001b[0m             fsspec_kwargs\u001b[38;5;241m=\u001b[39mfsspec_kwargs,\n\u001b[1;32m   1193\u001b[0m             decompress_in_memory\u001b[38;5;241m=\u001b[39mdecompress_in_memory,\n\u001b[1;32m   1194\u001b[0m         )\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/astropy/io/fits/file.py:240\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache, use_fsspec, fsspec_kwargs, decompress_in_memory)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filename(fileobj, mode, overwrite)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/astropy/io/fits/file.py:701\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    698\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, IO_FITS_MODES[mode])\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'"
     ]
    }
   ],
   "source": [
    "# === User Inputs ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #TJ add the path to psf data files if needed (may need to go back through adding the path in terminal)\n",
    "    #filters = ['F335M', 'F360M', 'F405N', 'F430M', 'F444W']\n",
    "    filters = ['F335M', 'F360M', 'F405N', 'F430M', 'F444W', 'F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W'] \n",
    "    # === Set up ===\n",
    "    \n",
    "    for filter in filters:\n",
    "        if filter in ['F335M', 'F360M', 'F405N', 'F430M', 'F444W']:\n",
    "            IFU_filepath = \"Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits\"\n",
    "            instrument = 'NIRCam'  # or 'MIRI' if using MIRI cube\n",
    "        if filter in ['F560W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "        if filter in ['F770W', 'F1000W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "        if filter in ['F1130W', 'F1280W', 'F1500W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "        if filter in ['F1800W', 'F2100W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "            \n",
    "        IFU_hdul = fits.open(IFU_filepath)\n",
    "        header = IFU_hdul[\"SCI\"].header\n",
    "        cube = SpectralCube.read(IFU_filepath, hdu='SCI')\n",
    "        wcs = WCS(header)\n",
    "        spectral_axis = cube.spectral_axis  #TJ in meters\n",
    "        # === Load webbpsf instrument ===\n",
    "        if instrument == 'NIRCam':\n",
    "            inst = webbpsf.NIRCam()\n",
    "        elif instrument == \"MIRI\":\n",
    "            inst = webbpsf.MIRI()\n",
    "        inst.filter = filter\n",
    "    \n",
    "        # === Prepare output cube ===\n",
    "        convolved_data = np.zeros_like(cube.unmasked_data[:].value)\n",
    "        tqdm_kwargs = {\n",
    "            'dynamic_ncols': True,  # Auto-adjusts width\n",
    "            'mininterval': 0.5,     # Update every 0.5 seconds (optional)\n",
    "            'position': 0,          # Fix position (set to 0 for notebooks)\n",
    "            'leave': True           # Leaves progress bar after completion\n",
    "        }\n",
    "        # === Loop through wavelengths and convolve ===\n",
    "        for i, wavelength in enumerate(tqdm(spectral_axis, desc=f\"Convolving to {filter}\")):\n",
    "            psf = inst.calc_psf(monochromatic=wavelength.to(u.m).value)    \n",
    "            psf_data = psf[0].data\n",
    "            psf_data /= psf_data.sum()  # Normalize PSF to conserve flux\n",
    "        \n",
    "            image_slice = cube.filled_data[...].value[i]  # 2D image at this wavelength\n",
    "            convolved_slice = convolve_fft(image_slice, psf_data, normalize_kernel=True, boundary='fill', fill_value=0)\n",
    "            convolved_data[i] = convolved_slice\n",
    "        \n",
    "        # === Save the convolved cube ===\n",
    "        out_hdu = fits.PrimaryHDU(convolved_data, header=header)\n",
    "        out_hdu.writeto(f\"Data_files/IFU_files/M51_IFU_convolved_to_{inst.filter}.fits\", overwrite=True)\n",
    "        \n",
    "        print(\"✅ PSF convolution complete and saved as 'M51_IFU_convolved.fits'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5ae93-6b1e-4746-a62e-ff73dbf32997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036871f0-a15c-47e4-bab1-3af7af19013a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca8ecf6-d460-472c-a287-1e5af5d2240f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$[2.8708949,~2.8726849,~2.8744749,~\\dots,~5.2659149,~5.2677049,~5.2694949] \\; \\mathrm{\\mu m}$"
      ],
      "text/plain": [
       "<Quantity [2.87089489, 2.87268489, 2.87447489, ..., 5.2659149 , 5.2677049 ,\n",
       "           5.2694949 ] um>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729060ab-0174-4752-9be8-4371b1509d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F2100W'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8b2777-744d-4ad0-b5fc-8e579f16aeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a77871d-2231-4bb4-b863-79a30e536649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3cad162-a160-4800-86a5-bfaa467c5357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Quantity 9.892e-07 m>, <Quantity 1.3282e-06 m>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filter_wl_range('F115W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e843d5f5-9363-426a-86f9-574b09b2918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stpsf.stpsf_core.MIRI at 0x7fbc3544d050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683383d-543e-4625-a942-a87a3d611df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
