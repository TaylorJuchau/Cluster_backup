{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"STPSF_PATH\"] = \"/d/ret1/Taylor/stpsf-data/\" \n",
    "import webbpsf\n",
    "os.environ[\"STPSF_PATH\"] = \"/d/ret1/Taylor/stpsf-data/\" #TJ for some reason this only works if you do this line twice... no idea why\n",
    "\n",
    "print(os.path.exists(os.environ[\"STPSF_PATH\"]))\n",
    "print(os.environ[\"STPSF_PATH\"]) #TJ check that this kernel has access to the filter files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "from ipywidgets import interact, Dropdown\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from astropy.convolution import convolve_fft, Gaussian2DKernel\n",
    "\n",
    "\n",
    "#parent_dir = Path().resolve().parent #TJ current notebook's parent directory\n",
    "\n",
    "os.chdir('/d/ret1/Taylor/jupyter_notebooks/Research') #TJ change working directory to be the parent directory\n",
    "from Py_files.Basic_analysis import * #import basic functions from custom package\n",
    "from Py_files.Image_vs_spectra import * \n",
    "#TJ import flux calibration functions (mainly compare_IFU_to_image(IFU_filepath, image_filepath, filter_filepath, loc, radius))\n",
    "\n",
    "def get_filter_wl_range(filter):\n",
    "    '''Use the filter files to determine what wavelength range we need for each filter\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter : type = str - string describing the filter name (case sensitive), for example \"F335M\"\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    Path to newly convolved file as a string\n",
    "    '''   \n",
    "    filter_files = ['/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F115W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F140M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F150W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F164N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F182M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F187N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F200W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F210M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F212N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F250M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F300M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F335M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F360M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F405N.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F430M.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/nircam/F444W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F560W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F770W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1000W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1130W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1280W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1500W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F1800W.dat',\n",
    "       '/d/crow1/tools/cigale/database_builder/filters/jwst/miri/F2100W.dat']\n",
    "    filter_file = [filer_filepath for filer_filepath in filter_files if extract_filter_name(filer_filepath).upper() == filter][0]\n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    return filter_wl[0]*u.m, filter_wl[-1]*u.m\n",
    "\n",
    "def convolve(IFU_fits_file, instrument, filter, output_file = None):\n",
    "    '''Convolve an IFU cube to the PSF of the provided filter.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    IFU_fits_file : type = str - string to location of IFU fits that you want to convolve.\n",
    "    instrument : type = str - Either \"MIRI\" or \"NIRCam\" depending on wavelength\n",
    "    filter : type = str - string describing the filter name (case sensitive), for example \"F335M\"\n",
    "    output_file (optional, defaults to use the IFU_file with _convolved_to_{filter}) : type = str - name of the convolved file\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    Path to newly convolved file as a string\n",
    "    '''   \n",
    "\n",
    "    IFU_hdul = fits.open(IFU_fits_file)\n",
    "    header = IFU_hdul[\"SCI\"].header\n",
    "    cube = SpectralCube.read(IFU_fits_file, hdu='SCI')\n",
    "    spectral_axis = cube.spectral_axis  #TJ in meters\n",
    "    # === Load webbpsf instrument ===\n",
    "    if instrument == 'NIRCam':\n",
    "        inst = webbpsf.NIRCam()\n",
    "    elif instrument == \"MIRI\":\n",
    "        inst = webbpsf.MIRI()\n",
    "    inst.filter = filter\n",
    "\n",
    "    # === Prepare output cube ===\n",
    "    convolved_data = np.zeros_like(cube.unmasked_data[:].value)\n",
    "    tqdm_kwargs = {\n",
    "        'dynamic_ncols': True,  # Auto-adjusts width\n",
    "        'mininterval': 0.5,     # Update every 0.5 seconds (optional)\n",
    "        'position': 0,          # Fix position (set to 0 for notebooks)\n",
    "        'leave': True           # Leaves progress bar after completion\n",
    "    }\n",
    "    # === Loop through wavelengths and convolve ===\n",
    "    for i, wavelength in enumerate(tqdm(spectral_axis, desc=f\"Convolving to {filter}\")):\n",
    "        psf = inst.calc_psf(monochromatic=wavelength.to(u.m).value)    \n",
    "        psf_data = psf[0].data\n",
    "        psf_data /= psf_data.sum()  # Normalize PSF to conserve flux\n",
    "    \n",
    "        image_slice = cube.filled_data[...].value[i]  # 2D image at this wavelength\n",
    "        convolved_slice = convolve_fft(image_slice, psf_data, normalize_kernel=True, boundary='fill', fill_value=0)\n",
    "        convolved_data[i] = convolved_slice\n",
    "    \n",
    "    # === Save the convolved cube ===\n",
    "    out_hdu = fits.PrimaryHDU(convolved_data, header=header)\n",
    "    if output_file:\n",
    "        out_hdu.writeto(f\"Data_files/IFU_files/{output_file}\", overwrite=True)\n",
    "        print(f\"✅ PSF convolution complete and saved as {output_file}\")\n",
    "        return f\"Data_files/IFU_files/{output_file}\"\n",
    "    else:\n",
    "        out_hdu.writeto(f\"Data_files/IFU_files/{IFU_fits_file}_convolved_to_{filter}.fits\", overwrite=True)\n",
    "        print(f\"✅ PSF convolution complete and saved as {IFU_fits_file}_convolved_to_{filter}\")\n",
    "        return f\"Data_files/IFU_files/{IFU_fits_file}_convolved_to_{filter}.fits\"\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === User Inputs ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #TJ add the path to psf data files if needed (may need to go back through adding the path in terminal)\n",
    "    #filters = ['F335M', 'F360M', 'F405N', 'F430M', 'F444W']\n",
    "    filters = ['F335M', 'F360M', 'F405N', 'F430M', 'F444W', 'F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W'] \n",
    "    # === Set up ===\n",
    "    \n",
    "    for filter in filters:\n",
    "        if filter in ['F335M', 'F360M', 'F405N', 'F430M', 'F444W']:\n",
    "            IFU_filepath = \"Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits\"\n",
    "            instrument = 'NIRCam'  # or 'MIRI' if using MIRI cube\n",
    "        if filter in ['F560W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "        if filter in ['F770W', 'F1000W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "        if filter in ['F1130W', 'F1280W', 'F1500W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "        if filter in ['F1800W', 'F2100W']:\n",
    "            IFU_filepath = 'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits'\n",
    "            instrument = \"MIRI\"\n",
    "            \n",
    "        IFU_hdul = fits.open(IFU_filepath)\n",
    "        header = IFU_hdul[\"SCI\"].header\n",
    "        cube = SpectralCube.read(IFU_filepath, hdu='SCI')\n",
    "        wcs = WCS(header)\n",
    "        spectral_axis = cube.spectral_axis  #TJ in meters\n",
    "        # === Load webbpsf instrument ===\n",
    "        if instrument == 'NIRCam':\n",
    "            inst = webbpsf.NIRCam()\n",
    "        elif instrument == \"MIRI\":\n",
    "            inst = webbpsf.MIRI()\n",
    "        inst.filter = filter\n",
    "    \n",
    "        # === Prepare output cube ===\n",
    "        convolved_data = np.zeros_like(cube.unmasked_data[:].value)\n",
    "        tqdm_kwargs = {\n",
    "            'dynamic_ncols': True,  # Auto-adjusts width\n",
    "            'mininterval': 0.5,     # Update every 0.5 seconds (optional)\n",
    "            'position': 0,          # Fix position (set to 0 for notebooks)\n",
    "            'leave': True           # Leaves progress bar after completion\n",
    "        }\n",
    "        # === Loop through wavelengths and convolve ===\n",
    "        for i, wavelength in enumerate(tqdm(spectral_axis, desc=f\"Convolving to {filter}\")):\n",
    "            psf = inst.calc_psf(monochromatic=wavelength.to(u.m).value)    \n",
    "            psf_data = psf[0].data\n",
    "            psf_data /= psf_data.sum()  # Normalize PSF to conserve flux\n",
    "        \n",
    "            image_slice = cube.filled_data[...].value[i]  # 2D image at this wavelength\n",
    "            convolved_slice = convolve_fft(image_slice, psf_data, normalize_kernel=True, boundary='fill', fill_value=0)\n",
    "            convolved_data[i] = convolved_slice\n",
    "        \n",
    "        # === Save the convolved cube ===\n",
    "        out_hdu = fits.PrimaryHDU(convolved_data, header=header)\n",
    "        out_hdu.writeto(f\"Data_files/IFU_files/M51_IFU_convolved_to_{inst.filter}.fits\", overwrite=True)\n",
    "        \n",
    "        print(\"✅ PSF convolution complete and saved as 'M51_IFU_convolved.fits'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filter_wl_range('F115W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
