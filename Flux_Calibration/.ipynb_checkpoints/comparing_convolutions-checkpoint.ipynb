{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "\n",
    "home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "parent_dir = Path(home_directory).resolve() #TJ current notebook's parent directory\n",
    "os.chdir(parent_dir) #TJ change working directory to be the parent directory\n",
    "\n",
    "from Py_files.Basic_analysis import * #TJ import basic functions from custom package\n",
    "from Py_files.Image_vs_spectra import *\n",
    "from Py_files.Convolution_script import *\n",
    "\n",
    "#IFU_files = glob.glob('Data_files/IFU_files/*s3d.fits') #TJ this is not correctly sorted, run this and copy into line below\n",
    "karin_SDuval_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits'\n",
    "            ]\n",
    "\n",
    "karin_IFU_files = [ 'Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch4-shortmediumlong_s3d.fits',\n",
    "            ]\n",
    "Thomas_IFU_file = 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'\n",
    "\n",
    "SDuval_IFU_files = ['Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits']\n",
    "\n",
    "Grant_conv_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "\n",
    "image_files, filter_files = generate_list_of_files()\n",
    "filter_names = ['F115W', 'F140M', 'F150W', 'F164N', 'F182M', 'F187N', 'F200W', 'F210M', 'F212N', 'F250M', 'F300M', 'F335M', 'F360M', 'F405N', \n",
    "           'F430M', 'F444W', 'F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W'] \n",
    "loc = [202.4340450, 47.1732517]\n",
    "radius = 0.75*u.arcsec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convolved_filter_name(file):\n",
    "    '''Extracts \"F115W\" from 'Data_files/IFU_files/f100lp_s3dIFU_convolved_tof115w.fits'\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file : type = str - string of a convolved IFU\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    filter_name : type = str - string with capital letters representing the filter name\n",
    "    '''   \n",
    "    return file.split(\"convolved_to\")[1].split(\".f\")[0].upper()\n",
    "\n",
    "\n",
    "def which_fits(filter_file, list_of_fits):\n",
    "    '''open the filter file, determine the range of wavelengths needed to compute synthetic flux through it, return which fits files\n",
    "    are needed for this particular filter. This is to save time not convolving cubes we dont need.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    filter_file : type = str - string to location of filter file that we are interested in.\n",
    "    list_of_fits : type = list - list of strings to the IFU fits files that you want to check\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    needed_fits : type = list - list of strings to the fits files that are actually needed\n",
    "    '''   \n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "            header = f.readline().strip().split()\n",
    "            for line in f:\n",
    "                data_line = line.strip().split()\n",
    "                filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "\n",
    "    wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    T = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    \n",
    "    min_wl, max_wl = min(wl), max(wl)\n",
    "    needed_fits = []\n",
    "    entirely_in = []\n",
    "    for file in list_of_fits:\n",
    "        cube = SpectralCube.read(file, hdu='SCI')\n",
    "        wavelength = cube.spectral_axis\n",
    "        if (wavelength[0].value*1e-6 < max_wl) and (wavelength[-1].value*1e-6 > min_wl):\n",
    "            needed_fits.append(file)\n",
    "            if ((wavelength[0].value*1e-6 < min_wl) and (wavelength[-1].value*1e-6 > max_wl)):\n",
    "                entirely_in.append(True)\n",
    "            else:\n",
    "                entirely_in.append(False)\n",
    "    needed_fits = np.array(needed_fits)\n",
    "\n",
    "    if (sum(entirely_in) == 1):\n",
    "        return needed_fits[entirely_in]\n",
    "    elif ((len(needed_fits) > 1) & (sum(entirely_in) == 0)):\n",
    "        print(f'More than one IFU file is needed for filter {extract_filter_name(filter_file)}')\n",
    "        return needed_fits\n",
    "    elif ((len(needed_fits) > 1) & (sum(entirely_in) > 1)):\n",
    "        print(f'More than one IFU file could be used for filter {extract_filter_name(filter_file)}')\n",
    "        return needed_fits[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combine_spectra(first, next, loc, radius, show_plot = False):\n",
    "    '''extract the spectrum from a region specified by loc and radius from each IFU file, then stitch them together\n",
    "    This function subtracts the next spectrum from the first spectrum in the overlapping region, takes the median of the\n",
    "    difference, then adds that difference to the next spectrum to get the new values. overlapping region is overwritten\n",
    "    by the corrected next spectrum.\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    first : type = str - string to location of IFU fits with shorter wavelength of the two\n",
    "                ****This can also be an already combined spectrum for iterative stitching\n",
    "    next : type = str - string to the location of the IFU fits file with the longer wavelengths (should have an overlap)\n",
    "    loc : type = list - ra, dec in degrees or SkyCoord object\n",
    "    radius : type = float - radius of aperture with units\n",
    "    show_plot (optional, defaults to False) : type = boolean - show plot of the stitched spectrum?\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    combined spectrum : dictionary has entries for ['wavelength'] and ['intensity'] which span the full range of the two files\n",
    "    '''   \n",
    "\n",
    "    if type(first) == str:\n",
    "        \n",
    "        first_IFU_hdul = fits.open(first)\n",
    "        first_header = first_IFU_hdul[\"SCI\"].header\n",
    "        first_cube = SpectralCube.read(first, hdu='SCI')\n",
    "        first_wcs = WCS(first_header)\n",
    "        first_spectral_axis = first_cube.spectral_axis\n",
    "        first_spectrum = get_IFU_spectrum(first, loc, radius, replace_negatives = 1e-1)\n",
    "    elif type(first) == dict:\n",
    "        first_spectrum = first\n",
    "    else:\n",
    "        print('first argument was not a dictionary or a string to a file')\n",
    "    next_IFU_hdul = fits.open(next)\n",
    "    next_header = next_IFU_hdul[\"SCI\"].header\n",
    "    next_cube = SpectralCube.read(next, hdu='SCI')\n",
    "    next_wcs = WCS(next_header)\n",
    "    next_spectral_axis = next_cube.spectral_axis\n",
    "    next_spectrum = get_IFU_spectrum(next, loc, radius, replace_negatives = 1e-1)\n",
    "    mask_first = (first_spectrum['wavelength'] >= next_spectrum['wavelength'][0])\n",
    "    mask_next = (next_spectrum['wavelength'] <= first_spectrum['wavelength'][-1])\n",
    "    next_interp = np.interp(first_spectrum['wavelength'][mask_first], next_spectrum['wavelength'][mask_next], next_spectrum['intensity'][mask_next])\n",
    "    diff_spectrum = first_spectrum['intensity'][mask_first] - next_interp\n",
    "    median_diff = np.nanmedian(diff_spectrum)\n",
    "    corrected_next = next_spectrum['intensity'] + median_diff\n",
    "    combined_spectrum = {\n",
    "    'wavelength': np.concatenate([first_spectrum['wavelength'][~mask_first], next_spectrum['wavelength']]),\n",
    "    'intensity': np.concatenate([first_spectrum['intensity'][~mask_first], corrected_next])\n",
    "    }\n",
    "    if show_plot:\n",
    "        \n",
    "        plt.plot(combined_spectrum['wavelength'], combined_spectrum['intensity'], color = 'red', label = 'combined')\n",
    "        plt.plot(next_spectrum['wavelength'], next_spectrum['intensity'], color = 'orange', label = 'raw')\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return combined_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell compares Karin_reduction cubes to thomas reduction\n",
    "image_flux = get_image_flux(image_files[15], loc, radius)\n",
    "filter_name = extract_filter_name(filter_files[15]).upper()\n",
    "filter_data = []\n",
    "with open(filter_files[15], 'r') as f:\n",
    "    header = f.readline().strip().split()\n",
    "    for line in f:\n",
    "        data_line = line.strip().split()\n",
    "        filter_data.append(data_line)\n",
    "        \n",
    "header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "instrument = 'NIRCam'\n",
    "#TJ commented out so the entire script can be re-run\n",
    "#new_fits = convolve_filter(IFU_files[2], filter_name, output_file = f'Karin_reduction_convolved_to_F444W.fits')\n",
    "new_fits = 'Data_files/IFU_files/Karin_reduction_convolved_to_F444W.fits'\n",
    "spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "print('Using karin_reduction: ', IFU_expected_flux/image_flux)\n",
    "\n",
    "############################################\n",
    "\n",
    "image_flux = get_image_flux(image_files[15], loc, radius)\n",
    "filter_name = extract_filter_name(filter_files[15]).upper()\n",
    "filter_data = []\n",
    "with open(filter_files[15], 'r') as f:\n",
    "    header = f.readline().strip().split()\n",
    "    for line in f:\n",
    "        data_line = line.strip().split()\n",
    "        filter_data.append(data_line)\n",
    "        \n",
    "header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "instrument = 'NIRCam'\n",
    "#TJ commented out so the entire script can be re-run\n",
    "#new_fits = convolve_filter('Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits', filter_name, output_file = f'Thomas_reduction_convolved_to_F444W.fits')\n",
    "new_fits = 'Data_files/IFU_files/Thomas_reduction_convolved_to_F444W.fits'\n",
    "spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "print('Using Thomas_reduction IFU for convolution: ', IFU_expected_flux/image_flux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell doesnt need to be re-ran unless you want to recreate the convolved files, it should save the arrays at the end as well\n",
    "#TJ THIS TAKES SEVERAL HOURS\n",
    "'''image_flux = []\n",
    "karin_SDuval_IFU_flux = []\n",
    "karin_IFU_flux = []\n",
    "aperture_area_sr = np.pi * (radius.to(u.rad))**2\n",
    "for file in filter_files:\n",
    "    \n",
    "    needed_fits = which_fits(file, karin_IFU_files) #TJ extract needed IFU files\n",
    "    needed_karins = which_fits(file, karin_SDuval_IFU_files)\n",
    "    print(f'for filter {extract_filter_name(file).upper()} we need: {needed_fits}')\n",
    "    current_filter_name = extract_filter_name(file).upper()\n",
    "    image_file = [img for img in image_files if extract_filter_name(img).upper() == current_filter_name][0]\n",
    "    print(f'image file selected as {image_file}')\n",
    "    photo_flux = (get_image_flux(image_file, loc, radius))\n",
    "    image_flux.append(photo_flux)\n",
    "\n",
    "    \n",
    "    filter_data = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    \n",
    "    if len(needed_fits)==1:\n",
    "        IFU_file = needed_fits[0]\n",
    "        instrument = 'NIRCam' if get_filter_number(current_filter_name) < 450 else \"MIRI\"\n",
    "        new_fits = convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits')\n",
    "        spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_SDuval_IFU_flux.append(IFU_expected_flux)\n",
    "    else:\n",
    "        new_fits = []\n",
    "        for IFU_file in needed_fits:\n",
    "            \n",
    "            new_fits.append(convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits'))\n",
    "        \n",
    "        spectrum = stitch_spectra(new_fits, loc, radius)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_SDuval_IFU_flux.append(IFU_expected_flux)\n",
    "\n",
    "    if len(needed_karins)==1:\n",
    "        IFU_file = needed_karins[0]\n",
    "        instrument = 'NIRCam' if get_filter_number(current_filter_name) < 450 else \"MIRI\"\n",
    "        new_fits = convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits')\n",
    "        spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_IFU_flux.append(IFU_expected_flux)\n",
    "    else:\n",
    "        new_fits = []\n",
    "        for IFU_file in needed_karins:\n",
    "            \n",
    "            new_fits.append(convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits'))\n",
    "        \n",
    "        spectrum = stitch_spectra(new_fits, loc, radius)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_IFU_flux.append(IFU_expected_flux)\n",
    "\n",
    "karin_SDuval_IFU_flux = np.array(karin_SDuval_IFU_flux)\n",
    "karin_IFU_flux = np.array(karin_IFU_flux)\n",
    "image_flux = np.array(image_flux)\n",
    "np.save('Data_files/misc_data/Karin_SDuval_IFU_expected_flux.npy', karin_SDuval_IFU_flux)\n",
    "np.save('Data_files/misc_data/Karin_IFU_expected_flux.npy', karin_IFU_flux)\n",
    "np.save('Data_files/misc_data/Image_fluxes.npy', image_flux)'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell recalculates karin and grant's spectrum's expected flux through filters, takes about 10 mins.\n",
    "#TJ these files should already be saved as described at the end of the cell\n",
    "Grant_IFU_flux = []\n",
    "karin_stitched_expected_flux = []\n",
    "for file in filter_files:\n",
    "    needed_fits = which_fits(file, Grant_conv_IFU_files) #TJ extract needed IFU files\n",
    "    current_filter_name = extract_filter_name(file).upper()\n",
    "    filter_data = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    karin_spectrum = load_and_sort_convolved_Karin_spectrum('Data_files/ARM2_HII2_conv_stitched_test.dat')\n",
    "    karin_stitched_expected = get_Fnu_transmission(karin_spectrum[\"intensity\"], karin_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    karin_stitched_expected_flux.append(karin_stitched_expected)\n",
    "    if len(needed_fits)==1:\n",
    "        IFU_file = needed_fits[0]\n",
    "        spectrum = get_IFU_spectrum(IFU_file, loc, radius, replace_negatives = 1e-1)\n",
    "\n",
    "    else:\n",
    "        spectrum = stitch_spectra(needed_fits, loc, radius, anchor_idx=0)\n",
    "    IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    Grant_IFU_flux.append(IFU_expected_flux)\n",
    "Grant_IFU_flux = np.array(Grant_IFU_flux)\n",
    "karin_stitched_expected_flux = np.array(karin_stitched_expected_flux)\n",
    "np.save('Data_files/misc_data/karin_stitched_and_convolved_expected_fluxes.npy', karin_stitched_expected_flux)\n",
    "np.save('Data_files/misc_data/Grant_IFU_expected_flux.npy', Grant_IFU_flux)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_flux = np.load('Data_files/misc_data/Image_fluxes.npy')\n",
    "\n",
    "karin_stitched_expected = np.load('Data_files/misc_data/karin_stitched_and_convolved_expected_fluxes.npy')\n",
    "rel_karin_stitched = karin_stitched_expected/image_flux\n",
    "\n",
    "karin_SDuval_flux = np.load('Data_files/misc_data/Karin_SDuval_IFU_expected_flux.npy')\n",
    "ksd_idx = [karin_SDuval_flux > 0][0]\n",
    "ksd_rel_flux = np.array(karin_SDuval_flux/image_flux)[ksd_idx]\n",
    "\n",
    "karin_IFU_flux = np.load('Data_files/misc_data/Karin_IFU_expected_flux.npy')\n",
    "karin_idx = [karin_IFU_flux > 0][0]\n",
    "rel_karin_flux = np.array(karin_IFU_flux/image_flux)[karin_idx]\n",
    "\n",
    "grant_flux = np.load('Data_files/misc_data/Grant_IFU_expected_flux.npy')\n",
    "grant_idx = [grant_flux > 0][0]\n",
    "rel_grant = np.array(grant_flux/image_flux)[grant_idx]\n",
    "\n",
    "Thomas_flux = np.load('Data_files/misc_data/Thomas_reduction_expected_fluxes.npy')\n",
    "Thomas_idx = [11, 12, 13, 14, 15]\n",
    "rel_Thomas = Thomas_flux/image_flux[Thomas_idx]\n",
    "\n",
    "x_axis = np.array([extract_filter_name(x) for x in filter_files])\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "\n",
    "plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "# Now plot with sorted data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_axis, rel_karin_stitched, label='', s=30, marker='o', color='purple')\n",
    "plt.scatter(x_axis[ksd_idx][1:], ksd_rel_flux[1:], label='Karin(NIRSpec)&Sara(MIRI) IFU', s=110, marker='o', color='blue')\n",
    "plt.scatter(x_axis[karin_idx][1:], rel_karin_flux[1:], label='karin_reduction IFU only', s=80, marker='o', color='red')\n",
    "plt.scatter(x_axis[grant_idx][1:], rel_grant[1:], label='grant_convolution IFU', s=70, marker='o', color='green')\n",
    "plt.scatter(x_axis[Thomas_idx], rel_Thomas, label='Thomas_reduction IFU', s=50, marker='o', color='black')\n",
    "plt.scatter(x_axis, rel_karin_stitched, label='Karin_stitched_and_convolved_spectrum', s=30, marker='o', color='purple')\n",
    "\n",
    "plt.axhline(y=1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.axhline(y = 1, color = 'gray', linestyle = '--', linewidth = 1, alpha = 0.5)\n",
    "plt.axvline(x=15.5, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "ymin, ymax = plt.ylim()\n",
    "text_y_pos = ymax * 0.9\n",
    "\n",
    "# Add NIRCam label to the left\n",
    "plt.text(15.25, text_y_pos, \"← NIRCam\", \n",
    "         ha='right', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "\n",
    "# Add MIRI label to the right\n",
    "plt.text(15.75, text_y_pos, \"MIRI →\", \n",
    "         ha='left', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "plt.xlabel('Filter Names')\n",
    "plt.ylabel('Synthetic image flux / actual image flux')\n",
    "plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to image-extracted values\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Data_files/misc_data/image_vs_spectra.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anchored to first file\n",
    "Karin = load_and_sort_convolved_Karin_spectrum('Data_files/ARM2_HII2_conv_stitched_test.dat')\n",
    "with open(\"Data_files/misc_data/Karin_SDuval_reduction_stitched.pkl\", \"rb\") as file:\n",
    "    full_spectrum = pickle.load(file)\n",
    "test_range = range(0,len(Karin))\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = \"stitching Grant's convolution\")\n",
    "plt.plot(full_spectrum['wavelength'][test_range]*1e6, full_spectrum['intensity'][test_range], color = 'red', label = 'my convolution of Karin&SDuval')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Comparing Grant's convolution to my convolution of Karin_SDuval IFUs\")\n",
    "plt.ylabel('Fnu (W/m^2/hz/sr)')\n",
    "plt.xlabel('wavlength (m)')\n",
    "plt.ylim([1e-30, 1e-27])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loc = [202.4340450, 47.1732517] \n",
    "radius = 0.75*u.arcsec\n",
    "data = []\n",
    "for i, file in enumerate(SDuval_IFU_files):\n",
    "    IFU_hdul = fits.open(file)\n",
    "    header = IFU_hdul[\"SCI\"].header\n",
    "    cube = SpectralCube.read(file, hdu='SCI')\n",
    "    wcs = WCS(header)\n",
    "\n",
    "    spectral_axis = cube.spectral_axis\n",
    "    data.append(get_IFU_spectrum(file, loc, radius))\n",
    "\n",
    "first_end = len(data[0]['wavelength'][data[0]['wavelength'] > data[1]['wavelength'][0]])\n",
    "second_start = len(data[1]['wavelength'][data[1]['wavelength'] < data[0]['wavelength'][-1]])\n",
    "second_end = len(data[1]['wavelength'][data[1]['wavelength'] > data[2]['wavelength'][0]])\n",
    "third_start = len(data[2]['wavelength'][data[2]['wavelength'] < data[1]['wavelength'][-1]])\n",
    "third_end = len(data[2]['wavelength'][data[2]['wavelength'] > data[3]['wavelength'][0]])\n",
    "fourth_start = len(data[3]['wavelength'][data[3]['wavelength'] < data[2]['wavelength'][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(data[0]['wavelength'][-2*first_end:], data[0]['intensity'][-2*first_end:], color = 'blue', label = 'data1')\n",
    "plt.plot(data[1]['wavelength'][:2*second_start], data[1]['intensity'][:2*second_start], color = 'orange', label = 'data2')\n",
    "plt.show()\n",
    "plt.plot(data[1]['wavelength'][-2*second_end:]*1e+6, data[1]['intensity'][-2*second_end:], color = 'blue', label = 'channel 2')\n",
    "plt.plot(data[2]['wavelength'][:2*third_start]*1e+6, data[2]['intensity'][:2*third_start], color = 'orange', label = 'channel 3')\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('MIRI Channels 2 and 3 overlapping region')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(data[2]['wavelength'][-2*third_end:]*1e+6, data[2]['intensity'][-2*third_end:], color = 'orange', label = 'channel 3')\n",
    "plt.plot(data[3]['wavelength'][:2*fourth_start]*1e+6, data[3]['intensity'][:2*fourth_start], color = 'green', label = 'channel 4')\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('MIRI Channels 3 and 4 overlapping region')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[3]['wavelength'], data[3]['intensity'], color = 'green', label = 'channel 4')\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('Channels 3 and 4 overlapping region')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spectrum = find_point_spectrum(files[0], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[-2*first_end:], spectrum[-2*first_end:], color = 'red', label = 'channel 1')\n",
    "\n",
    "spectrum = find_point_spectrum(files[1], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "\n",
    "plt.plot(wavelengths[:2*second_start], spectrum[:2*second_start], color = 'orange', label = 'channel 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "############################\n",
    "spectrum = find_point_spectrum(files[1], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[-2*second_end:], spectrum[-2*second_end:], color = 'orange', label = 'channel 2')\n",
    "\n",
    "spectrum = find_point_spectrum(files[2], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[:2*third_start], spectrum[:2*third_start], color = 'green', label = 'channel 3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#######################\n",
    "spectrum = find_point_spectrum(files[2], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[-2*third_end:], spectrum[-2*third_end:], color = 'green', label = 'channel 3')\n",
    "\n",
    "spectrum = find_point_spectrum(files[3], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[:2*fourth_start], spectrum[:2*fourth_start], color = 'blue', label = 'channel 4')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = []\n",
    "ends = []\n",
    "for i,file in enumerate(karin_SDuval_IFU_files):\n",
    "    cube = SpectralCube.read(file, hdu='SCI')\n",
    "    starts.append(cube.spectral_axis[0].value*1e-6)\n",
    "    ends.append(cube.spectral_axis[-1].value*1e-6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_fits = glob.glob('Data_files/IFU_files/*convolved*')\n",
    "for file in convolved_fits:\n",
    "    cube = SpectralCube.read(file)\n",
    "    cube_wl = cube.spectral_axis\n",
    "    filter_name = get_convolved_filter_name(file)\n",
    "    filter_range = get_filter_wl_range(filter_name)\n",
    "    print('filter spans ', filter_range)\n",
    "    print('cube spans ', cube_wl[0], cube_wl[-1])\n",
    "    if (filter_range[0].value > cube_wl[0].value*1e-6) & (filter_range[1].value < cube_wl[-1].value*1e-6):\n",
    "        print('Fully contained')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = SpectralCube.read(IFU_file, hdu='SCI')\n",
    "cube_wl = cube.spectral_axis.to(u.m)\n",
    "wl1, wl2 = get_filter_wl_range(extract_filter_name(file).upper())\n",
    "wl2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = webbpsf.MIRI()\n",
    "inst.filter = 'F1500W'\n",
    "psf = inst.calc_psf(monochromatic=1.5e-5)\n",
    "psf_data = psf[0].data\n",
    "hdu = fits.open(karin_IFU_files[-1])['SCI']\n",
    "header = hdu.header\n",
    "print('IFU pixel scale :', (header['CDELT2']*u.deg).to(u.arcsec))\n",
    "print('psf pixel scale :', psf[0].header['PIXELSCL'], 'arcsec')\n",
    "\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define center\n",
    "ny, nx = psf_data.shape\n",
    "y, x = np.indices(psf_data.shape)\n",
    "cx, cy = nx // 2, ny // 2\n",
    "r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "\n",
    "# Flatten and sort by radius\n",
    "r_flat = r.flatten()\n",
    "psf_flat = psf_data.flatten()\n",
    "sort_idx = np.argsort(r_flat)\n",
    "\n",
    "r_sorted = r_flat[sort_idx]\n",
    "psf_sorted = psf_flat[sort_idx]\n",
    "\n",
    "# Bin radially\n",
    "bin_size = 1  # pixel\n",
    "my_max_r = int(r.max())\n",
    "my_radial_median = [np.median(psf_data[(r >= i) & (r < i+bin_size)]) for i in range(my_max_r)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogy(range(my_max_r), my_radial_median)\n",
    "plt.xlabel(\"Radius [pixels]\")\n",
    "plt.ylabel(\"PSF intensity\")\n",
    "plt.title(\"Radial PSF profile\")\n",
    "plt.xlim(0,100)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.convolution import convolve, convolve_fft\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "from photutils.psf.matching import create_matching_kernel\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import webbpsf\n",
    "\n",
    "def convolve_JWST_cube_with_psf_plot(input_cubefile, target_lam, savename, target_inst, exclusion_threshold=0.9):\n",
    "    '''\n",
    "    Smooth a JWST cube to the resolution at a given wavelength and plot PSF comparison.\n",
    "    '''\n",
    "    NRS_handoff = 4.1 # micron\n",
    "\n",
    "    def get_fwhm_MIRI(lam):\n",
    "        return 0.033*(lam) + 0.106 # arcsec\n",
    "    \n",
    "    def get_x_fwhm_NRS(lamda):\n",
    "        if lamda < NRS_handoff:\n",
    "            return (0.01*lamda) + 0.14 # arcsec\n",
    "        elif lamda >= NRS_handoff:\n",
    "            return (0.02*lamda) + 0.15 # arcsec\n",
    "    def get_y_fwhm_NRS(lamda):\n",
    "        if lamda < NRS_handoff:\n",
    "            return (0.01*lamda) + 0.16 # arcsec\n",
    "        elif lamda >= NRS_handoff:\n",
    "            return (0.01*lamda) + 0.15 # arcsec\n",
    "    \n",
    "    def get_spectral_axis(cube):\n",
    "        wav_short = cube[1].header['CRVAL3']\n",
    "        delta_lam = cube[1].header['CDELT3']\n",
    "        lam_n = len(cube[1].data)\n",
    "        spectral_axis = np.asarray([wav_short + (delta_lam*i) for i in range(lam_n)])\n",
    "        return spectral_axis\n",
    "\n",
    "    ### ==== PREP INPUT CUBE ==== ###\n",
    "    input_cube = fits.open(input_cubefile)\n",
    "    input_spectral_axis = get_spectral_axis(input_cube)\n",
    "    input_slice = input_cube[1].data[0]\n",
    "    if input_cube[0].header['INSTRUME'] == 'NIRSPEC':\n",
    "        input_cube_type = 'NRS'\n",
    "    elif input_cube[0].header['INSTRUME'] == 'MIRI':\n",
    "        input_cube_type = 'MIRI'\n",
    "\n",
    "    # Pixel grid for kernels\n",
    "    y, x = np.mgrid[0:input_slice.shape[0], 0:input_slice.shape[1]]\n",
    "    midx, midy = int(np.floor(input_slice.shape[1]/2)), int(np.floor(input_slice.shape[0]/2))\n",
    "\n",
    "    ### ==== GET TARGET GAUSSIAN PSF ==== ###\n",
    "    if target_inst == 'NRS':\n",
    "        target_x_fwhm = get_x_fwhm_NRS(target_lam)\n",
    "        target_sig_arcsec_x = target_x_fwhm/np.sqrt(8*np.log(2))\n",
    "        target_sig_pix_x = target_sig_arcsec_x/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "    \n",
    "        target_y_fwhm = get_y_fwhm_NRS(target_lam)\n",
    "        target_sig_arcsec_y = target_y_fwhm/np.sqrt(8*np.log(2))\n",
    "        target_sig_pix_y = target_sig_arcsec_y/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "    elif target_inst == 'MIRI':\n",
    "        target_fwhm = get_fwhm_MIRI(target_lam)\n",
    "        target_sig_arcsec = target_fwhm/np.sqrt(8*np.log(2))\n",
    "        target_sig_pix_x = target_sig_arcsec/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "        target_sig_pix_y = target_sig_pix_x\n",
    "\n",
    "    target_gauss = Gaussian2D(1, midx, midy, target_sig_pix_x, target_sig_pix_y)\n",
    "    target_kernel = target_gauss(x, y)\n",
    "\n",
    "    ### ==== CALCULATE WEBBPSF PSF ==== ###\n",
    "    inst = webbpsf.NIRCam()\n",
    "    inst.filter = f'F200W'\n",
    "    psf_webbpsf = inst.calc_psf(monochromatic=target_lam*1e-6)\n",
    "    psf_data_webbpsf = psf_webbpsf[0].data\n",
    "    psf_data_webbpsf /= psf_data_webbpsf.sum()\n",
    "\n",
    "    ### ==== PLOT COMPARISON OF PSF ENIRCLED ENERGY ==== ###\n",
    "    def compute_EE(psf_data):\n",
    "        ny, nx = psf_data.shape\n",
    "        y, x = np.indices(psf_data.shape)\n",
    "        cx, cy = nx // 2, ny // 2\n",
    "        r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "        r_flat = r.flatten()\n",
    "        psf_flat = psf_data.flatten()\n",
    "        sort_idx = np.argsort(r_flat)\n",
    "        r_sorted = r_flat[sort_idx]\n",
    "        psf_sorted = psf_flat[sort_idx]\n",
    "\n",
    "        max_r = int(r_sorted.max())\n",
    "        EE = []\n",
    "        for i in range(max_r):\n",
    "            annulus_mask = (r_sorted >= 0) & (r_sorted < i+1)\n",
    "            ee_value = psf_sorted[annulus_mask].sum()\n",
    "            EE.append(ee_value)\n",
    "        EE = np.array(EE) / psf_sorted.sum()  # normalize\n",
    "        return EE, max_r\n",
    "\n",
    "    EE_webbpsf, max_r_webbpsf = compute_EE(psf_data_webbpsf)\n",
    "    EE_gauss, max_r_gauss = compute_EE(target_kernel)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(range(max_r_webbpsf), EE_webbpsf, label='webbpsf PSF')\n",
    "    plt.plot(range(max_r_gauss), EE_gauss, label='Gaussian PSF')\n",
    "    plt.xlabel(\"Radius [pixels]\")\n",
    "    plt.ylabel(\"Encircled Energy (normalized)\")\n",
    "    plt.title(f\"Encircled Energy Comparison @ {target_lam:.2f} μm\")\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.xlim(0,40)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ### ==== CONVOLUTION PROCESS ==== ###\n",
    "    convolved_planes = []\n",
    "    convolved_uncertainty_planes = []\n",
    "    for i in tqdm(range(len(input_spectral_axis))):\n",
    "        this_lam = input_spectral_axis[i]\n",
    "        this_slice = input_cube[1].data[i]\n",
    "        this_slice_unc = input_cube[2].data[i]\n",
    "\n",
    "        if this_lam <= target_lam:\n",
    "            if input_cube_type == 'NRS':\n",
    "                this_x_fwhm_NRS = get_x_fwhm_NRS(this_lam)\n",
    "                this_sig_arcsec_x = this_x_fwhm_NRS/np.sqrt(8*np.log(2))\n",
    "                this_sig_pix_x = this_sig_arcsec_x/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "                this_y_fwhm_NRS = get_y_fwhm_NRS(this_lam)\n",
    "                this_sig_arcsec_y = this_y_fwhm_NRS/np.sqrt(8*np.log(2))\n",
    "                this_sig_pix_y = this_sig_arcsec_y/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "            elif input_cube_type == 'MIRI':\n",
    "                this_x_fwhm_MIRI = get_fwhm_MIRI(this_lam)\n",
    "                this_sig_arcsec_x = this_x_fwhm_MIRI/np.sqrt(8*np.log(2))\n",
    "                this_sig_pix_x = this_sig_arcsec_x/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "                this_sig_pix_y = this_sig_pix_x\n",
    "\n",
    "            input_gauss = Gaussian2D(1, midx, midy, this_sig_pix_x, this_sig_pix_y)\n",
    "            input_kernel = input_gauss(x, y)\n",
    "            matching_kernel = create_matching_kernel(input_kernel, target_kernel)\n",
    "\n",
    "            fake_slice = np.where(this_slice!=this_slice, 0, 1)\n",
    "            fake_convolved_image = convolve_fft(fake_slice, matching_kernel, boundary='fill', fill_value=0, preserve_nan=True)\n",
    "            keep_mask = np.where(fake_convolved_image>=exclusion_threshold, 1, np.nan)\n",
    "\n",
    "            convolved_image = convolve_fft(this_slice, matching_kernel, boundary='fill', fill_value=0, preserve_nan=True)\n",
    "            convolved_image *= keep_mask\n",
    "            convolved_planes.append(convolved_image)\n",
    "\n",
    "            unc_matching_kernel = matching_kernel**2\n",
    "            unc_matching_kernel /= unc_matching_kernel.sum()\n",
    "            convolved_unc_image = convolve_fft(this_slice_unc, unc_matching_kernel, boundary='fill', fill_value=0, preserve_nan=True)\n",
    "            convolved_unc_image *= keep_mask\n",
    "            convolved_uncertainty_planes.append(convolved_unc_image)\n",
    "        else:\n",
    "            convolved_planes.append(this_slice)\n",
    "            convolved_uncertainty_planes.append(this_slice_unc)\n",
    "\n",
    "    convolved_planes = np.asarray(convolved_planes)\n",
    "    convolved_uncertainty_planes = np.asarray(convolved_uncertainty_planes)\n",
    "    input_cube[1].data = convolved_planes\n",
    "    input_cube[2].data = convolved_uncertainty_planes\n",
    "    input_cube.writeto(savename, overwrite=True)\n",
    "\n",
    "    return input_cube\n",
    "convolve_JWST_cube_with_psf_plot(\n",
    "    karin_IFU_files[1], \n",
    "    1.988, \n",
    "    'Data_files/IFU_files/testing_Grants_function.fits', \n",
    "    'NRS', \n",
    "    exclusion_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "hdu = fits.open(karin_IFU_files[1])[\"SCI\"]\n",
    "header = hdu.header\n",
    "pix_scale = (header[\"CDELT1\"]*u.deg).to(u.arcsec)\n",
    "inst = webbpsf.NIRCam()\n",
    "inst.filter = 'F200W'\n",
    "psf = inst.calc_psf(monochromatic=1.988e-6, fov_arcsec = 10)\n",
    "psf_data = psf[0].data\n",
    "# Re-normalize PSF\n",
    "print(psf_data.sum())\n",
    "psf_data /= psf_data.sum()\n",
    "\n",
    "# Calculate EE in radial bins\n",
    "ny, nx = psf_data.shape\n",
    "y, x = np.indices(psf_data.shape)\n",
    "cx, cy = nx // 2, ny // 2\n",
    "r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "\n",
    "r_arcsec = r * pix_scale\n",
    "\n",
    "max_r_arcsec = r_arcsec.max()\n",
    "bin_edges = np.linspace(0, max_r_arcsec, 100)\n",
    "EE = []\n",
    "\n",
    "for rmax in bin_edges:\n",
    "    mask = r_arcsec <= rmax\n",
    "    EE.append(psf_data[mask].sum())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(bin_edges, EE)\n",
    "plt.xlabel(\"Radius [arcsec]\")\n",
    "plt.ylabel(\"Encircled Energy\")\n",
    "plt.title(\"MIRI F1500W Encircled Energy\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(0,10)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = SpectralCube.read(karin_IFU_files[1], hdu = \"SCI\")\n",
    "cube.spectral_axis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filter_wl_range('F200W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.calc_psf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open(karin_IFU_files[0])['SCI']\n",
    "header = hdu.header\n",
    "wcs = WCS(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs.wcs.crval[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
