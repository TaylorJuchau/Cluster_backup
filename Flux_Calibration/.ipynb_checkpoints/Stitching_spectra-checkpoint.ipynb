{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "\n",
    "home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "parent_dir = Path(home_directory).resolve() \n",
    "os.chdir(parent_dir) #TJ change working directory to be the parent directory\n",
    "\n",
    "from Py_files.Basic_analysis import * #TJ import basic functions from custom package\n",
    "from Py_files.Image_vs_spectra import *\n",
    "from Py_files.Convolution_script import *\n",
    "from Py_files.Get_feature_fluxes import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#IFU_files = glob.glob('Data_files/IFU_files/*s3d.fits') #TJ this is not correctly sorted, run this and copy into line below\n",
    "IFU_files = [ 'Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits',\n",
    "            ]\n",
    "Grant_conv_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "\n",
    "\n",
    "loc = [202.4340450, 47.1732517] \n",
    "radius = 0.75*u.arcsec\n",
    "aperture_size = (np.pi*(radius**2).to('sr'))\n",
    "\n",
    "def combine_spectra(fits_files, loc, radius, anchor_idx=0, show_plot=False):\n",
    "    '''\n",
    "    Combine multiple spectral segments using a specified anchor spectrum for alignment\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_files : list of str\n",
    "        List of paths to FITS files to combine (must be in wavelength order)\n",
    "    anchor_idx : int, optional\n",
    "        Index of the file to use as anchor/reference (default: 0)\n",
    "    loc : list or SkyCoord\n",
    "        [RA, Dec] in degrees or SkyCoord object for extraction\n",
    "    radius : astropy Quantity\n",
    "        Aperture radius with units (e.g., 0.75*u.arcsec)\n",
    "    show_plot : bool, optional\n",
    "        Whether to show diagnostic plots (default: False)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Combined spectrum with 'wavelength' and 'intensity' keys\n",
    "    '''\n",
    "    \n",
    "    # Load anchor spectrum\n",
    "    anchor = get_IFU_spectrum(fits_files[anchor_idx], loc, radius, replace_negatives=1e-1)\n",
    "    combined = {'wavelength': anchor['wavelength'].copy(),\n",
    "                'intensity': anchor['intensity'].copy()}\n",
    "    \n",
    "    for i, file in enumerate(fits_files):\n",
    "        if i == anchor_idx:\n",
    "            continue  # Skip the anchor file\n",
    "            \n",
    "        # Load current spectrum\n",
    "        current = get_IFU_spectrum(file, loc, radius, replace_negatives=1e-1)\n",
    "        \n",
    "        # Find overlap with combined spectrum\n",
    "        mask_combined = (combined['wavelength'] >= current['wavelength'][0]) & \\\n",
    "                        (combined['wavelength'] <= current['wavelength'][-1])\n",
    "        mask_current = (current['wavelength'] >= combined['wavelength'][0]) & \\\n",
    "                       (current['wavelength'] <= combined['wavelength'][-1])\n",
    "        \n",
    "        # Skip if no overlap\n",
    "        if not np.any(mask_combined):\n",
    "            print(f\"No overlap between anchor and {file}\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate offset relative to anchor\n",
    "        current_interp = np.interp(\n",
    "            combined['wavelength'][mask_combined],\n",
    "            current['wavelength'][mask_current],\n",
    "            current['intensity'][mask_current]\n",
    "        )\n",
    "        offset = np.nanmedian(combined['intensity'][mask_combined] - current_interp)\n",
    "        \n",
    "        # Apply correction\n",
    "        corrected_current = current['intensity'] + offset\n",
    "        \n",
    "        # Combine spectra\n",
    "        non_overlap_mask = ~((current['wavelength'] >= combined['wavelength'][0]) & \n",
    "                            (current['wavelength'] <= combined['wavelength'][-1]))\n",
    "        \n",
    "        combined['wavelength'] = np.concatenate([\n",
    "            combined['wavelength'],\n",
    "            current['wavelength'][non_overlap_mask]\n",
    "        ])\n",
    "        combined['intensity'] = np.concatenate([\n",
    "            combined['intensity'],\n",
    "            corrected_current[non_overlap_mask]\n",
    "        ])\n",
    "        \n",
    "        # Sort by wavelength (in case files weren't perfectly ordered)\n",
    "        sort_idx = np.argsort(combined['wavelength'])\n",
    "        combined['wavelength'] = combined['wavelength'][sort_idx]\n",
    "        combined['intensity'] = combined['intensity'][sort_idx]\n",
    "        \n",
    "        if show_plot:\n",
    "            plt.figure(figsize=(12,6))\n",
    "            plt.plot(combined['wavelength'], combined['intensity'], 'k-', label='Combined')\n",
    "            plt.plot(current['wavelength'], current['intensity'], 'r-', alpha=0.5, label='Original')\n",
    "            plt.plot(current['wavelength'], corrected_current, 'b--', alpha=0.7, label='Aligned')\n",
    "            plt.yscale('log')\n",
    "            plt.title(f\"After adding {file}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "    return combined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell doesnt need to be run if the files exist already\n",
    "for i, file in enumerate(IFU_files):\n",
    "    convolve_using_reference(file, 'F2100W', f'convolved_to_2100_part{i+1}.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_convolution_files = np.array(glob.glob('Data_files/IFU_files/convolved_to_2100*'))\n",
    "part = [int(x.split('part')[1].split('.f')[0]) for x in common_convolution_files]\n",
    "sorted_indices = np.argsort(part)\n",
    "\n",
    "files = common_convolution_files[sorted_indices]\n",
    "full_spectrum = stitch_spectra(files, loc, radius)\n",
    "with open(\"Data_files/misc_data/Karin_SDuval_reduction_stitched.pkl\", \"wb\") as file:\n",
    "    pickle.dump(full_spectrum, file)\n",
    "\n",
    "Karin = load_and_sort_convolved_Karin_spectrum('Data_files/ARM2_HII2_conv_stitched_test.dat')\n",
    "plt.plot(full_spectrum['wavelength']*1e6, full_spectrum['intensity'], color = 'red', label = 'my stitch')\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = 'Karin stitch')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anchored to first file\n",
    "Karin = load_and_sort_convolved_Karin_spectrum('Data_files/ARM2_HII2_conv_stitched_test.dat')\n",
    "with open(\"Data_files/misc_data/Karin_SDuval_reduction_stitched.pkl\", \"rb\") as file:\n",
    "    full_spectrum = pickle.load(file)\n",
    "test_range = range(0,len(Karin))\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = \"stitching Grant's convolution\")\n",
    "plt.plot(full_spectrum['wavelength'][test_range]*1e6, full_spectrum['intensity'][test_range]*1.1, color = 'red', label = 'my convolution of Karin&SDuval')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('Comparing Karin stitched spectrum to my stitching of Karin&SDuval spectra')\n",
    "plt.ylabel('Fnu (W/m^2/hz/sr)')\n",
    "plt.xlabel('wavlength (m)')\n",
    "plt.ylim([1e-30, 1e-27])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anchored to second file\n",
    "files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits', \n",
    "         'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "         'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "'''\n",
    "full_spectrum = stitch_spectra(files, loc, radius, anchor_idx=0)'''\n",
    "with open(\"Data_files/misc_data/Karin_Grant_convolved.pkl\", \"wb\") as file:\n",
    "    pickle.dump(full_spectrum, file)\n",
    "with open(\"Data_files/misc_data/Karin_Grant_convolved.pkl\", \"rb\") as file:\n",
    "    full_spectrum = pickle.load(file)\n",
    "plt.plot(full_spectrum['wavelength']*1e6, full_spectrum['intensity'], color = 'red', label = 'my stitch')\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = 'Karin stitch')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([1e-30, 1e-27])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anchored to second file\n",
    "unconvolved_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits', \n",
    "         'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "         'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "         'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d.fits']\n",
    "convolved_files = []\n",
    "filter = 'F2100W'\n",
    "for i, file in enumerate(unconvolved_files):\n",
    "    convolved_files.append(convolve_using_reference(file, filter, reference_wl = 17.1e-6, output_file=f'jw_IFU_convolved_to17p1um_part_{i}'))\n",
    "\n",
    "full_spectrum = stitch_spectra(convolved_files, loc, radius, anchor_idx=0)\n",
    "with open(\"Data_files/misc_data/karin_SDuval_convolved_to17p1um.pkl\", \"wb\") as file:\n",
    "    pickle.dump(full_spectrum, file)\n",
    "plt.plot(full_spectrum['wavelength']*1e6, full_spectrum['intensity']/aperture_size, color = 'red', label = 'my stitch')\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = 'Karin stitch')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([1e-20, 1e-17])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(full_spectrum['wavelength']*1e6, full_spectrum['intensity'], color = 'red', label = 'my convolution')\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = 'Grant_convolution')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-30, 1e-27)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_sort_convolved_Karin_spectrum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_wl, transitions = pull_vacuum_data_from_NIST()\n",
    "feature_wl = np.array(feature_wl)\n",
    "feature_wl *= 1e-6  # Modify in-place immediately after\n",
    "features = fit_voigt_to_all(full_spectrum['wavelength'], full_spectrum['intensity'], np.array([0]*len(full_spectrum['wavelength'])), feature_wl, transitions, guess_Z = 0.001534)\n",
    "Karin_features = fit_voigt_to_all(Karin['wavelength'], Karin['intensity'], np.array([0]*len(Karin['wavelength'])), feature_wl, transitions, guess_Z = 0.001534)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(features):\n",
    "    my_rat = feature[1]/features[15][1]\n",
    "    Karin_rat = Karin_features[i][1]/Karin_features[15][1]\n",
    "    print(my_rat, 'compared to ', Karin_rat ,'difference of ', (my_rat-Karin_rat)/Karin_rat, \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_continuum_around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul = fits.open(IFU_files[0])[\"SCI\"]\n",
    "hdul.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_and_get_expected_flux_array(IFU_files, filters, loc, radius):\n",
    "    '''find expected fluxes for each filter using the spectra from the relevant IFU files\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    IFU_files : type = list - list of strings representing paths to IFU files\n",
    "    filters : type = list - list of all the filters you want to get fluxes for\n",
    "    loc : type = list - ra, dec in degrees or SkyCoord object\n",
    "    radius : type = astropy.units.quantity.Quantity - angular radius of the aperture (with units), for example 0.75*u.arcsecond\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    numpy array with entries for each filter in filter. Entries represent the expected flux through that filter.\n",
    "    ''' \n",
    "    dtype = [\n",
    "        ('filter', 'U20'),      #TJ Unicode string (20 chars max)\n",
    "        ('flux', float),        #TJ Float for flux values\n",
    "        ('image_flux', float)   #TJ Float for image flux values\n",
    "    ]\n",
    "    \n",
    "    #TJ Initialize an empty structured array, this will be returned at the end of the function\n",
    "    data = np.array([], dtype=dtype)\n",
    "    image_files, filter_files = generate_list_of_files()\n",
    "    for filter in filters:\n",
    "        filter_file = [flt for flt in filter_files if extract_filter_name(flt).upper() == filter][0]\n",
    "        filter_data = []\n",
    "        with open(filter_file, 'r') as f:\n",
    "            header = f.readline().strip().split()\n",
    "            for line in f:\n",
    "                data_line = line.strip().split()\n",
    "                filter_data.append(data_line)\n",
    "        \n",
    "        header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "        filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "        filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "        \n",
    "        needed_fits = which_fits(filter_file, IFU_files)\n",
    "        image_file = [img for img in image_files if extract_filter_name(img).upper() == filter][0]\n",
    "        photo_flux = (get_image_flux(image_file, loc, radius))\n",
    "        if len(needed_fits)==1:\n",
    "            IFU_file = needed_fits[0]\n",
    "            instrument = 'NIRCam' if get_filter_number(filter) < 450 else \"MIRI\"\n",
    "            new_fits = convolve_filter(IFU_file, filter, output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{filter}.fits')\n",
    "            spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "        else:\n",
    "            new_fits = []\n",
    "            for IFU_file in needed_fits:\n",
    "                new_fits.append(convolve_filter(IFU_file, filter, output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{filter}.fits'))\n",
    "            spectrum = stitch_spectra(new_fits, loc, radius)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        new_row = np.array([(filter, IFU_expected_flux, photo_flux)], dtype=dtype)\n",
    "        data = np.append(data, new_row)\n",
    "    return data\n",
    "data = convolve_and_get_expected_flux_array(IFU_files, [\"F140M\", \"F150W\", \"F164N\"], loc, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['filter'], data['flux']/data['image_flux'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
