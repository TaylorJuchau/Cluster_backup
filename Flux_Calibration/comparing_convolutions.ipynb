{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from spectral_cube import SpectralCube\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.constants import c\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "from astropy.visualization import AsinhStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import SqrtStretch \n",
    "\n",
    "home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "parent_dir = Path(home_directory).resolve() #TJ current notebook's parent directory\n",
    "os.chdir(parent_dir) #TJ change working directory to be the parent directory\n",
    "\n",
    "from Py_files.Basic_analysis import * #TJ import basic functions from custom package\n",
    "from Py_files.Image_vs_spectra import *\n",
    "from Py_files.Convolution_script import *\n",
    "\n",
    "#IFU_files = glob.glob('Data_files/IFU_files/*s3d.fits') #TJ this is not correctly sorted, run this and copy into line below\n",
    "karin_SDuval_IFU_files = ['Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch4-shortmediumlong_s3d.fits'\n",
    "            ]\n",
    "\n",
    "karin_IFU_files = [ 'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch4-shortmediumlong_s3d.fits',\n",
    "            ]\n",
    "Thomas_IFU_file = 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'\n",
    "\n",
    "SDuval_IFU_files = ['Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch4-shortmediumlong_s3d.fits']\n",
    "\n",
    "Grant_conv_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "pivot_files = []\n",
    "for i in range(1,8):\n",
    "    pivot_files.append(f'Data_files/IFU_files/convolved_to_2100_part{i}.fits')\n",
    "jw_files = glob.glob('Data_files/IFU_files/my_convolutions/*/jw*')\n",
    "sw_files = glob.glob('Data_files/IFU_files/my_convolutions/*/SW*')\n",
    "my_convolutions = np.concatenate([jw_files, sw_files])\n",
    "image_files, filter_files = generate_list_of_files()\n",
    "filter_names = ['F115W', 'F140M', 'F150W', 'F164N', 'F182M', 'F187N', 'F200W', 'F210M', 'F212N', 'F250M', 'F300M', 'F335M', 'F360M', 'F405N', \n",
    "           'F430M', 'F444W', 'F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W'] \n",
    "loc = [202.4340450, 47.1732517]\n",
    "test_loc = [202.43357, 47.17296]\n",
    "\n",
    "radius = 0.75*u.arcsec\n",
    "with open('Data_files/misc_data/flux_v_radius/maximum_radii.dic', 'rb') as f:\n",
    "    radius_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdu = fits.open(karin_IFU_files[1])['SCI']\n",
    "loc_deg = np.array(loc)*u.deg\n",
    "coord = SkyCoord(ra=loc_deg[0], dec=loc_deg[1], frame='icrs')\n",
    "\n",
    "# Convert to HMS / DMS\n",
    "ra_hms = coord.ra.to_string(unit=u.hour, sep=':', precision=2)\n",
    "dec_dms = coord.dec.to_string(unit=u.degree, sep=':', precision=2, alwayssign=True)\n",
    "print(ra_hms, dec_dms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_integrated_aperture_overlay(IFU_file, image_file, loc, radius, zoom_scale=5):\n",
    "    \"\"\"Display wavelength-integrated IFU data alongside 2D image.\"\"\"\n",
    "    from astropy.nddata import block_reduce\n",
    "    \n",
    "    def load_data(file):\n",
    "        with fits.open(file) as hdul:\n",
    "            for ext in [1, 'SCI', 0]:\n",
    "                try:\n",
    "                    data = hdul[ext].data\n",
    "                    header = hdul[ext].header\n",
    "                    if data is not None:\n",
    "                        # Get 2D celestial WCS\n",
    "                        wcs = WCS(header, naxis=2)\n",
    "                        if data.ndim == 3:\n",
    "                            # Sum over wavelength axis (axis=0)\n",
    "                            integrated_data = np.nansum(data, axis=0)\n",
    "                            return integrated_data, header, wcs\n",
    "                        return data, header, wcs\n",
    "                except (KeyError, IndexError):\n",
    "                    continue\n",
    "        raise ValueError(f\"No valid data found in {file}\")\n",
    "\n",
    "    # Load and integrate IFU data\n",
    "    ifu_integrated, ifu_header, ifu_wcs = load_data(IFU_file)\n",
    "    image_data, image_header, image_wcs = load_data(image_file)\n",
    "    # Convert location to pixels\n",
    "    loc_sky = SkyCoord(ra=loc[0]*u.deg, dec=loc[1]*u.deg, frame='icrs')\n",
    "    x_ifu, y_ifu = ifu_wcs.all_world2pix(loc_sky.ra, loc_sky.dec, 0)\n",
    "    x_img, y_img = image_wcs.all_world2pix(loc_sky.ra, loc_sky.dec, 0)\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    # Plot integrated IFU data\n",
    "    ax1 = fig.add_subplot(121, projection=ifu_wcs)\n",
    "    im1 = ax1.imshow(ifu_integrated, origin='lower', cmap='viridis',\n",
    "                    norm=ImageNormalize(ifu_integrated, stretch=AsinhStretch(0.1)))\n",
    "    fig.colorbar(im1, ax=ax1, label='Integrated Flux')\n",
    "    ax1.set_title('IFU Data (λ-integrated)')\n",
    "\n",
    "    # Plot Image\n",
    "    ax2 = fig.add_subplot(122, projection=image_wcs)\n",
    "    im2 = ax2.imshow(image_data, origin='lower', cmap='viridis',\n",
    "                    norm=ImageNormalize(image_data/8, stretch=SqrtStretch()))\n",
    "    fig.colorbar(im2, ax=ax2, label='Flux')\n",
    "    ax2.set_title('Image Data')\n",
    "\n",
    "    # Add apertures and set zoom\n",
    "    for ax, (x, y), wcs in zip([ax1, ax2], [(x_ifu, y_ifu), (x_img, y_img)], [ifu_wcs, image_wcs]):\n",
    "        pixel_scale = np.abs(wcs.wcs.cdelt[0]) * 3600  # arcsec/pixel\n",
    "        radius_pix = radius.to(u.arcsec).value / pixel_scale\n",
    "        ax.add_patch(Circle((x, y), radius_pix, ec='red', fc='none', lw=2, ls='--'))\n",
    "        \n",
    "        # Set zoom (5x aperture radius by default)\n",
    "        zoom_width = zoom_scale * radius_pix\n",
    "        ax.set_xlim(x - zoom_width, x + zoom_width)\n",
    "        ax.set_ylim(y - zoom_width, y + zoom_width)\n",
    "    \n",
    "    plt.suptitle(f\"Aperture Radius: {radius}\", y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "image_file = [img for img in image_files if extract_filter_name(img).upper() == \"F560W\"][0]\n",
    "IFU_file = 'Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits'\n",
    "#[202.4340450, 47.1732517]\n",
    "plot_integrated_aperture_overlay(IFU_file, image_file, loc, 1.1*u.arcsec)\n",
    "plot_integrated_aperture_overlay(IFU_file, image_file, test_loc, 1.5*u.arcsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_files_unfiltered = glob.glob('Data_files/misc_data/misc_plots/*')\n",
    "figure_files = [f for f in figure_files_unfiltered if f[-5:] != 't.png']\n",
    "\n",
    "for file in figure_files:\n",
    "    img = plt.imread(file)\n",
    "    \n",
    "    # Display it\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Optional: turn off axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convolved_filter_name(file):\n",
    "    '''Extracts \"F115W\" from 'Data_files/IFU_files/f100lp_s3dIFU_convolved_tof115w.fits'\n",
    "    -------------\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    file : type = str - string of a convolved IFU\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    filter_name : type = str - string with capital letters representing the filter name\n",
    "    '''   \n",
    "    return file.split(\"convolved_to\")[1].split(\".f\")[0].upper()\n",
    "needed_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell compares Karin_reduction cubes to thomas reduction\n",
    "image_flux = get_image_flux(image_files[15], loc, radius)\n",
    "filter_name = extract_filter_name(filter_files[15]).upper()\n",
    "filter_data = []\n",
    "with open(filter_files[15], 'r') as f:\n",
    "    header = f.readline().strip().split()\n",
    "    for line in f:\n",
    "        data_line = line.strip().split()\n",
    "        filter_data.append(data_line)\n",
    "        \n",
    "header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "instrument = 'NIRCam'\n",
    "#TJ commented out so the entire script can be re-run\n",
    "#new_fits = convolve_filter(IFU_files[2], filter_name, output_file = f'Karin_reduction_convolved_to_F444W.fits')\n",
    "new_fits = 'Data_files/IFU_files/Karin_reduction_convolved_to_F444W.fits'\n",
    "spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "print('Using karin_reduction: ', IFU_expected_flux/image_flux)\n",
    "\n",
    "############################################\n",
    "\n",
    "image_flux = get_image_flux(image_files[15], loc, radius)\n",
    "filter_name = extract_filter_name(filter_files[15]).upper()\n",
    "filter_data = []\n",
    "with open(filter_files[15], 'r') as f:\n",
    "    header = f.readline().strip().split()\n",
    "    for line in f:\n",
    "        data_line = line.strip().split()\n",
    "        filter_data.append(data_line)\n",
    "        \n",
    "header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "instrument = 'NIRCam'\n",
    "#TJ commented out so the entire script can be re-run\n",
    "#new_fits = convolve_filter('Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits', filter_name, output_file = f'Thomas_reduction_convolved_to_F444W.fits')\n",
    "new_fits = 'Data_files/IFU_files/Thomas_reduction_convolved_to_F444W.fits'\n",
    "spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 1e-1)\n",
    "IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "print('Using Thomas_reduction IFU for convolution: ', IFU_expected_flux/image_flux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis cell checks the radius dependance of a single filter. For quick verifications\n",
    "current_filter_name = 'F560W'\n",
    "image_file = [img for img in image_files if extract_filter_name(img).upper() == current_filter_name][0]\n",
    "needed_fits = which_fits(filter_files[-8], karin_SDuval_IFU_files) #TJ extract needed IFU files\n",
    "filter_data = []\n",
    "with open(filter_files[-8], 'r') as f:\n",
    "    header = f.readline().strip().split()\n",
    "    for line in f:\n",
    "        data_line = line.strip().split()\n",
    "        filter_data.append(data_line)\n",
    "\n",
    "header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "max_R_candidates = []\n",
    "for IFU_file in needed_fits:\n",
    "    max_R_candidates.append(find_max_radius(IFU_file, image_file, test_loc)[0])\n",
    "max_radius = min(max_R_candidates)\n",
    "radii = np.linspace(0.1, max_radius.value, 10)\n",
    "IFU_fluxes = []\n",
    "for r in radii:\n",
    "    radius = r*u.arcsec\n",
    "\n",
    "    g_spectrum = stitch_spectra(needed_fits, test_loc, radius, replace_negatives = 0)\n",
    "    g_photo_flux = get_image_flux(image_file, test_loc, radius)\n",
    "    g_IFU_expected_flux = get_Fnu_transmission(g_spectrum[\"intensity\"], g_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    IFU_fluxes.append(g_IFU_expected_flux/g_photo_flux)\n",
    "    #plot_integrated_aperture_overlay(needed_fits[0], image_file, loc, radius)\n",
    "\n",
    "plt.scatter(radii, IFU_fluxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell doesnt need to be re-ran unless you want to recreate the convolved files, it should save the arrays at the end as well\n",
    "#TJ THIS TAKES SEVERAL HOURS\n",
    "'''\n",
    "image_flux = []\n",
    "karin_SDuval_IFU_flux = []\n",
    "karin_IFU_flux = []\n",
    "grant_flux = []\n",
    "aperture_area_sr = np.pi * (radius.to(u.rad))**2\n",
    "for file in filter_files:\n",
    "    \n",
    "    needed_fits = which_fits(file, karin_IFU_files) #TJ extract needed IFU files\n",
    "    needed_karins = which_fits(file, karin_SDuval_IFU_files)\n",
    "    needed_grants = which_fits(file, Grant_conv_IFU_files)\n",
    "    print(f'for filter {extract_filter_name(file).upper()} we need: {needed_fits}')\n",
    "    current_filter_name = extract_filter_name(file).upper()\n",
    "    image_file = [img for img in image_files if extract_filter_name(img).upper() == current_filter_name][0]\n",
    "    print(f'image file selected as {image_file}')\n",
    "    photo_flux = (get_image_flux(image_file, loc, radius, replace_negatives=0))\n",
    "    image_flux.append(photo_flux)\n",
    "\n",
    "    \n",
    "    filter_data = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    \n",
    "    if len(needed_fits)==1:\n",
    "        IFU_file = needed_fits[0]\n",
    "        instrument = 'NIRCam' if get_filter_number(current_filter_name) < 450 else \"MIRI\"\n",
    "        new_fits = convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits')\n",
    "        spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives = 0)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_SDuval_IFU_flux.append(IFU_expected_flux)\n",
    "    else:\n",
    "        new_fits = []\n",
    "        for IFU_file in needed_fits:\n",
    "            \n",
    "            new_fits.append(convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits'))\n",
    "        \n",
    "        spectrum = stitch_spectra(new_fits, loc, radius, replace_negatives=0)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_SDuval_IFU_flux.append(IFU_expected_flux)\n",
    "\n",
    "    if len(needed_karins)==1:\n",
    "        IFU_file = needed_karins[0]\n",
    "        instrument = 'NIRCam' if get_filter_number(current_filter_name) < 450 else \"MIRI\"\n",
    "        new_fits = convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits')\n",
    "        spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives=0)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_IFU_flux.append(IFU_expected_flux)\n",
    "    else:\n",
    "        new_fits = []\n",
    "        for IFU_file in needed_karins:\n",
    "            \n",
    "            new_fits.append(convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits'))\n",
    "        \n",
    "        spectrum = stitch_spectra(new_fits, loc, radius, replace_negatives=0)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        karin_IFU_flux.append(IFU_expected_flux)\n",
    "        \n",
    "    if len(needed_grants)==1:\n",
    "        IFU_file = needed_grants[0]\n",
    "        instrument = 'NIRCam' if get_filter_number(current_filter_name) < 450 else \"MIRI\"\n",
    "        new_fits = convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits')\n",
    "        spectrum = get_IFU_spectrum(new_fits, loc, radius, replace_negatives=0)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        grant_flux.append(IFU_expected_flux)\n",
    "    else:\n",
    "        new_fits = []\n",
    "        for IFU_file in needed_karins:\n",
    "            \n",
    "            new_fits.append(convolve_filter(IFU_file, extract_filter_name(file).upper(), output_file = f'{IFU_file.split(\"/\")[-1].split(\".fits\")[0]}_convolved_to{extract_filter_name(file).upper()}.fits'))\n",
    "        \n",
    "        spectrum = stitch_spectra(new_fits, loc, radius, replace_negatives=0)\n",
    "        IFU_expected_flux = get_Fnu_transmission(spectrum[\"intensity\"], spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "        grant_flux.append(IFU_expected_flux)\n",
    "\n",
    "\n",
    "karin_SDuval_IFU_flux = np.array(karin_SDuval_IFU_flux)\n",
    "karin_IFU_flux = np.array(karin_IFU_flux)\n",
    "grant_flux = np.array(grant_flux)\n",
    "image_flux = np.array(image_flux)\n",
    "np.save('Data_files/misc_data/Karin_SDuval_IFU_expected_flux.npy', karin_SDuval_IFU_flux)\n",
    "np.save('Data_files/misc_data/Karin_IFU_expected_flux.npy', karin_IFU_flux)\n",
    "np.save('Data_files/misc_data/Image_fluxes.npy', image_flux)\n",
    "np.save('Data_files/misc_data/Grant_IFU_expected_flux.npy', grant_flux)\n",
    "'''\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(spectrum['wavelength'][spectrum['intensity']<0])\n",
    "#print(np.sum(spectrum['intensity']))\n",
    "#spectrum['wavelength']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TJ this cell recalculates an IFU spectrum's expected flux through filters, takes about 10 mins per set of IFU files.\n",
    "#TJ these files should already be saved as described at the end of the cell\n",
    "Grant_IFU_flux = []\n",
    "#my_flux = []\n",
    "#pivot_flux = []\n",
    "radius = 0.75*u.arcsec\n",
    "for file in filter_files:\n",
    "    #needed_files = which_fits(file, karin_SDuval_IFU_files) #TJ extract needed IFU files\n",
    "    needed_grant = which_fits(file, Grant_conv_IFU_files) #TJ extract needed IFU files\n",
    "    filter_name = extract_filter_name(file).upper()\n",
    "    #needed_mine = [x for x in my_convolutions if x.split('/')[-1].split('.fit')[0].split('ved_to')[-1]==current_filter_name]\n",
    "    image_file = [img for img in image_files if extract_filter_name(img).upper() == filter_name][0]\n",
    "    photo_flux = (get_image_flux(image_file, test_loc, radius))\n",
    "    filter_data = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "            \n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    \n",
    "    g_spectrum = stitch_spectra(needed_grant, test_loc, radius, anchor_idx=0, replace_negatives = 0)\n",
    "    #my_spectrum = stitch_spectra(needed_mine, test_loc, radius, anchor_idx=0, replace_negatives = 0)\n",
    "    #new_fits = []\n",
    "    #for i, IFU in enumerate(needed_files):\n",
    "    #    new_fits.append(convolve_using_reference(IFU, 1.71e-5, output_file = f'test_convolution_overwrite_ok{i}.fits'))\n",
    "    #pivot_spectrum = stitch_spectra(new_fits, test_loc, radius, anchor_idx=0, replace_negatives = 0)\n",
    "    grant_expected_flux = get_Fnu_transmission(g_spectrum[\"intensity\"], g_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    #my_expected_flux = get_Fnu_transmission(my_spectrum[\"intensity\"], my_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    #pivot_expected_flux = get_Fnu_transmission(pivot_spectrum[\"intensity\"], pivot_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    Grant_IFU_flux.append(grant_expected_flux/photo_flux)\n",
    "    #my_flux.append(my_expected_flux/photo_flux)\n",
    "    #pivot_flux.append(pivot_expected_flux/photo_flux)\n",
    "Grant_IFU_flux = np.array(Grant_IFU_flux)\n",
    "pivot_IFU_flux = np.array(pivot_flux)\n",
    "#my_flux = np.array(my_flux)\n",
    "#pivot_flux = np.array(pivot_flux)\n",
    "#np.save('Data_files/misc_data/new_loc_my_files.npy', my_flux)\n",
    "np.save('Data_files/misc_data/new_loc_grant_files.npy', Grant_IFU_flux)\n",
    "#np.save('Data_files/misc_data/new_loc_pivot_files.npy', pivot_flux)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This just plots the data created above (if it's already made)\n",
    "\n",
    "my_flux = np.load('Data_files/misc_data/new_loc_my_files.npy')\n",
    "Grant_IFU_flux = np.load('Data_files/misc_data/new_loc_grant_files.npy')\n",
    "pivot_flux = np.load('Data_files/misc_data/new_loc_pivot_files.npy')\n",
    "x_axis = np.array([extract_filter_name(x) for x in filter_files])\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "\n",
    "plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "# Now plot with sorted data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_axis, my_flux, label='convolved to native PSF', s=30, marker='o', color='red')\n",
    "#plt.scatter(x_axis, Grant_IFU_flux, label='convolved to 17.1um', s=30, marker='o', color='blue')\n",
    "plt.scatter(x_axis, pivot_flux, label='convolved to 17.1um', s=30, marker='o', color='green')\n",
    "\n",
    "plt.axhline(y=1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.axhline(y = 1, color = 'gray', linestyle = '--', linewidth = 1, alpha = 0.5)\n",
    "plt.axvline(x=15.5, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.ylim(0.5,1.4)\n",
    "ymin, ymax = plt.ylim()\n",
    "text_y_pos = ymax * 0.94\n",
    "\n",
    "# Add NIRCam label to the left\n",
    "plt.text(15.25, text_y_pos, \"← NIRCam\", \n",
    "         ha='right', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "\n",
    "# Add MIRI label to the right\n",
    "plt.text(15.75, text_y_pos, \"MIRI →\", \n",
    "         ha='left', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "plt.xlabel('Filter Names')\n",
    "plt.ylabel('Synthetic image flux / actual image flux')\n",
    "plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to image-extracted values (Centered on brighter source)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Data_files/misc_data/image_vs_spectra.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell plots the various convolutions spec/photo flux ratios for each filter (must have the data already made)\n",
    "image_flux = np.load('Data_files/misc_data/Image_fluxes.npy')\n",
    "\n",
    "karin_stitched_expected = np.load('Data_files/misc_data/karin_stitched_and_convolved_expected_fluxes.npy')\n",
    "rel_karin_stitched = karin_stitched_expected/image_flux\n",
    "\n",
    "karin_SDuval_flux = np.load('Data_files/misc_data/Karin_SDuval_IFU_expected_flux.npy')\n",
    "ksd_idx = [karin_SDuval_flux > 0][0]\n",
    "ksd_rel_flux = np.array(karin_SDuval_flux/image_flux)[ksd_idx]\n",
    "\n",
    "karin_IFU_flux = np.load('Data_files/misc_data/Karin_IFU_expected_flux.npy')\n",
    "karin_idx = [karin_IFU_flux > 0][0]\n",
    "rel_karin_flux = np.array(karin_IFU_flux/image_flux)[karin_idx]\n",
    "\n",
    "grant_flux = np.load('Data_files/misc_data/Grant_IFU_expected_flux.npy')\n",
    "grant_idx = [grant_flux > 0][0]\n",
    "rel_grant = np.array(grant_flux/image_flux)[grant_idx]\n",
    "\n",
    "Thomas_flux = np.load('Data_files/misc_data/Thomas_reduction_expected_fluxes.npy')\n",
    "Thomas_idx = [11, 12, 13, 14, 15]\n",
    "rel_Thomas = Thomas_flux/image_flux[Thomas_idx]\n",
    "\n",
    "x_axis = np.array([extract_filter_name(x) for x in filter_files])\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "\n",
    "plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "# Now plot with sorted data\n",
    "plt.figure(figsize=(10, 6))\n",
    "#plt.scatter(x_axis, rel_karin_stitched, label='', s=30, marker='o', color='purple')\n",
    "plt.scatter(x_axis[ksd_idx][1:], ksd_rel_flux[1:], label='Karin(NIRSpec)&Sara(MIRI) IFU', s=110, marker='o', color='blue')\n",
    "plt.scatter(x_axis[karin_idx][1:], rel_karin_flux[1:], label='karin_reduction IFU only', s=80, marker='o', color='red')\n",
    "plt.scatter(x_axis[grant_idx][1:], rel_grant[1:], label='grant_convolution IFU', s=70, marker='o', color='green')\n",
    "#plt.scatter(x_axis[Thomas_idx], rel_Thomas, label='Thomas_reduction IFU', s=50, marker='o', color='black')\n",
    "#plt.scatter(x_axis, rel_karin_stitched, label='Karin_stitched_and_convolved_spectrum', s=30, marker='o', color='purple')\n",
    "\n",
    "plt.axhline(y=1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.axhline(y = 1, color = 'gray', linestyle = '--', linewidth = 1, alpha = 0.5)\n",
    "plt.axvline(x=15.5, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "ymin, ymax = plt.ylim()\n",
    "text_y_pos = ymax * 0.9\n",
    "\n",
    "# Add NIRCam label to the left\n",
    "plt.text(15.25, text_y_pos, \"← NIRCam\", \n",
    "         ha='right', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "\n",
    "# Add MIRI label to the right\n",
    "plt.text(15.75, text_y_pos, \"MIRI →\", \n",
    "         ha='left', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "plt.xlabel('Filter Names')\n",
    "plt.ylabel('Synthetic image flux / actual image flux')\n",
    "plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to image-extracted values\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Data_files/misc_data/image_vs_spectra.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anchored to first file\n",
    "Karin = load_and_sort_convolved_Karin_spectrum('Data_files/ARM2_HII2_conv_stitched_test.dat')\n",
    "with open(\"Data_files/misc_data/Karin_SDuval_reduction_stitched.pkl\", \"rb\") as file:\n",
    "    full_spectrum = pickle.load(file)\n",
    "test_range = range(0,len(Karin))\n",
    "plt.plot(Karin['wavelength']*1e6, Karin['intensity'], color = 'black', label = \"stitching Grant's convolution\")\n",
    "plt.plot(full_spectrum['wavelength'][test_range]*1e6, full_spectrum['intensity'][test_range], color = 'red', label = 'my convolution of Karin&SDuval')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Comparing Grant's convolution to my convolution of Karin_SDuval IFUs\")\n",
    "plt.ylabel('Fnu (W/m^2/hz/sr)')\n",
    "plt.xlabel('wavlength (m)')\n",
    "plt.ylim([1e-30, 1e-27])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_coverage(filter_name, IFU_file):\n",
    "    '''Checks if the IFU has full filter converage or not'''\n",
    "    filter_coverage = get_filter_wl_range(filter_name)\n",
    "    cube = SpectralCube.read(IFU_file, hdu = 'SCI')\n",
    "    cube_range = [cube.spectral_axis[0], cube.spectral_axis[-1]]\n",
    "    if filter_coverage[0] < cube_range[0]:\n",
    "        return 'missing shorter'\n",
    "    if filter_coverage[1] > cube_range[1]:\n",
    "        return'missing longer'\n",
    "    else:\n",
    "        return 'good'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell calculates the relative fluxes using the largest aperture that you can without spilling into unimaged regions\n",
    "\n",
    "#This takes about 45-60 minutes\n",
    "Grant_IFU_flux = []\n",
    "my_flux = []\n",
    "pivot_flux = []\n",
    "for file in filter_files:\n",
    "    \n",
    "    current_filter_name = extract_filter_name(file).upper()\n",
    "    image_file = [img for img in image_files if extract_filter_name(img).upper() == current_filter_name][0]\n",
    "    \n",
    "    radius = radius_dict[current_filter_name]\n",
    "    \n",
    "    needed_fits = which_fits(file, Grant_conv_IFU_files) #TJ extract needed IFU files\n",
    "    needed_mine = [junk for junk in my_convolutions if junk.split('.f')[0].split('convolved_to')[-1] == current_filter_name]\n",
    "    needed_pivot = which_fits(file, pivot_files)\n",
    "    filter_data = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "    anchor = 0\n",
    "#    if current_filter_name == \"F560W\":\n",
    "#        anchor = 1\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = [try_float(filter_T[i,0])*1e-10 for i in range(len(filter_T))]\n",
    "    filter_trans = [try_float(filter_T[i,1]) for i in range(len(filter_T))]\n",
    "    g_spectrum = stitch_spectra(needed_fits, loc, radius, anchor_idx=anchor, replace_negatives = 0)\n",
    "    g_photo_flux = get_image_flux(image_file, loc, radius)\n",
    "    g_IFU_expected_flux = get_Fnu_transmission(g_spectrum[\"intensity\"], g_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    Grant_IFU_flux.append(g_IFU_expected_flux/g_photo_flux)\n",
    "\n",
    "    \n",
    "    my_spectrum = stitch_spectra(needed_mine, loc, radius, anchor_idx=anchor, replace_negatives = 0)\n",
    "    my_photo_flux = get_image_flux(image_file, loc, radius)\n",
    "    my_IFU_expected_flux = get_Fnu_transmission(my_spectrum[\"intensity\"], my_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    my_flux.append(my_IFU_expected_flux/my_photo_flux)\n",
    "\n",
    "    p_spectrum = stitch_spectra(needed_pivot, loc, radius, anchor_idx=anchor, replace_negatives=0)\n",
    "    p_photo_flux = get_image_flux(image_file, loc, radius)\n",
    "    p_IFU_expected_flux = get_Fnu_transmission(p_spectrum[\"intensity\"], p_spectrum[\"wavelength\"], filter_trans, filter_wl)\n",
    "    pivot_flux.append(p_IFU_expected_flux/p_photo_flux)\n",
    "Grant_IFU_flux = np.array(Grant_IFU_flux)\n",
    "my_flux = np.array(my_flux)\n",
    "pivot_flux = np.array(pivot_flux)\n",
    "np.save('Data_files/misc_data/my_expected_fluxes_max_radius.npy', my_flux)\n",
    "np.save('Data_files/misc_data/Grant_IFU_expected_flux_max_radius.npy', Grant_IFU_flux)\n",
    "np.save('Data_files/misc_data/pivot_IFU_expected_flux_max_radius.npy', pivot_flux)\n",
    "\n",
    "pivot_flux = np.load('Data_files/misc_data/pivot_IFU_expected_flux_max_radius.npy')\n",
    "my_flux = np.load('Data_files/misc_data/my_expected_fluxes_max_radius.npy')\n",
    "Grant_IFU_flux = np.load('Data_files/misc_data/Grant_IFU_expected_flux_max_radius.npy')\n",
    "\n",
    "\n",
    "image_flux_p75 = np.load('Data_files/misc_data/Image_fluxes.npy')\n",
    "grant_flux_p75 = np.load('Data_files/misc_data/Grant_IFU_expected_flux.npy')\n",
    "grant_idx = [grant_flux_p75 > 0][0]\n",
    "rel_grant_p75 = np.array(grant_flux_p75/image_flux_p75)[grant_idx]\n",
    "x_axis = np.array([extract_filter_name(x) for x in filter_files])\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')  #TJ just a random style for the plot\n",
    "\n",
    "plt.rcParams.update({'font.size': 12, 'axes.titlesize': 14, 'axes.labelsize': 12}) #TJ \n",
    "# Now plot with sorted data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_axis, my_flux, label='my_convolutions (max_radius)', s=30, marker='o', color='red')\n",
    "plt.scatter(x_axis, Grant_IFU_flux, label='grant (max radius)', s=30, marker='o', color='blue')\n",
    "plt.scatter(x_axis, pivot_flux, label='Convolved to 21um (max radius)', s=30, marker='o', color='green')\n",
    "#plt.scatter(x_axis[grant_idx], rel_grant_p75, label='grant_original', s=30, marker='o', color='black', alpha = 0.3)\n",
    "\n",
    "plt.axhline(y=1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tick_params(axis='y', which='both', labelsize=10)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.axhline(y = 1, color = 'gray', linestyle = '--', linewidth = 1, alpha = 0.5)\n",
    "plt.axvline(x=15.5, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.ylim(0.75,1.4)\n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "text_y_pos = ymax * 0.9\n",
    "\n",
    "# Add NIRCam label to the left\n",
    "plt.text(15.25, text_y_pos, \"← NIRCam\", \n",
    "         ha='right', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "\n",
    "# Add MIRI label to the right\n",
    "plt.text(15.75, text_y_pos, \"MIRI →\", \n",
    "         ha='left', va='center', \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2),\n",
    "         fontsize=10)\n",
    "plt.xlabel('Filter Names')\n",
    "plt.ylabel('Synthetic image flux / actual image flux')\n",
    "plt.title(\"FLux transmitted through filter compared to spectrum-derived expectations \\nNormalized to image-extracted values\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Data_files/misc_data/image_vs_spectra.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell generated the dictionary of largest radii available in the raw files, it does not need to be run again unless for new loc.\n",
    "#Dictionary saved at bottom\n",
    "'''\n",
    "filter_max_radius = {}\n",
    "\n",
    "for file in filter_files:\n",
    "    current_filter_name = extract_filter_name(file).upper()\n",
    "    \n",
    "    # Find matching image file\n",
    "    image_candidates = [img for img in image_files if extract_filter_name(img).upper() == current_filter_name]\n",
    "    if not image_candidates:\n",
    "        print(f\"No matching image for filter {current_filter_name}\")\n",
    "        continue\n",
    "    image_file = image_candidates[0]\n",
    "    \n",
    "    # Get corresponding IFU files\n",
    "    needed_fits = which_fits(file, karin_SDuval_IFU_files)\n",
    "    \n",
    "    # Find maximum radius for each IFU and take the minimum (most conservative)\n",
    "    radii = []\n",
    "    for IFU in needed_fits:\n",
    "        max_r = find_max_radius(IFU, image_file, loc)[0]\n",
    "        radii.append(max_r)\n",
    "    \n",
    "    # Store in dictionary (only if we found valid radii)\n",
    "    if radii:\n",
    "        filter_max_radius[current_filter_name] = min(radii)\n",
    "with open('Data_files/misc_data/flux_v_radius/maximum_radii.dic', 'wb') as f:\n",
    "    pickle.dump(filter_max_radius, f)\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "flux_ratios_dict = flux_ratios\n",
    "#flux_ratios_array = np.array(flux_ratios)\n",
    "fluxes = flux_ratios_dict['my_pivot']['flux']\n",
    "sizes = flux_ratios_dict['my_pivot']['size']\n",
    "idxs = flux_ratios_dict['my_pivot']['idx']\n",
    "\n",
    "# Convert sizes to float if Quantity\n",
    "sizes_float = np.array([s.value if hasattr(s, 'value') else s for s in sizes])\n",
    "norm = mcolors.Normalize(vmin=np.min(sizes_float), vmax=np.max(sizes_float))\n",
    "cmap = cm.get_cmap('rainbow')\n",
    "\n",
    "# Map sizes to colors\n",
    "colors = cmap(norm(sizes_float))\n",
    "# Convert x data to your intended x_axis\n",
    "x = np.array([x_axis[i] for i in idxs])\n",
    "special_idx = np.isclose(sizes_float, 54.82, atol=0.5)  # Adjust atol as needed\n",
    "\n",
    "# Set their color to black\n",
    "colors[special_idx] = [0, 0, 0, 1] \n",
    "# Plot\n",
    "mask = 9\n",
    "plt.scatter(x[mask:], fluxes[mask:], s=sizes_float[mask:], c=colors[mask:], alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(1e-2, 1e1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.axvline(x=13.5, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.ylim(0.7, 1.5)\n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "text_y_pos = 1.45\n",
    "params = {'facecolor':'white', 'alpha':0.8, 'edgecolor':'none', 'pad':2}\n",
    "# Add NIRCam label to the left\n",
    "plt.text(13.25, text_y_pos, \"← NIRCam\", \n",
    "         ha='right', va='center', \n",
    "         bbox=params,\n",
    "         fontsize=10)\n",
    "\n",
    "# Add MIRI label to the right\n",
    "plt.text(13.75, text_y_pos, \"MIRI →\", \n",
    "         ha='left', va='center', \n",
    "         bbox=params,\n",
    "         fontsize=10)\n",
    "plt.axhline(y=1, alpha = 0.7, linestyle = '--')\n",
    "plt.title('spec/photo for different aperture radii \\n[0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5] arcsec')\n",
    "plt.xlabel('filter name')\n",
    "plt.ylabel('spec / photo flux')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aperture_flux(file, loc, radius, show_plot= False, zoom = None):\n",
    "    '''display image of fits file, with aperture with radius at location, can also specify zoom\n",
    "    -------------\n",
    "    Parameters\n",
    "    -------------\n",
    "    file : type = str - string to fits file you want to display, can be a list of locations (len(loc) must equal len(radius))\n",
    "    loc : type = either [ra, dec] in degrees, or a SkyCoord object - location of center of the aperture\n",
    "    radius : type = angular unit - radius of aperture with units attached\n",
    "    show_plot (optional, defaults to false) : type = Boolean - show png of image?\n",
    "    zoom : type = angular unit, or list of units - width and height of the fov in the image if single value, if list [width, height]\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    flux : type = float - in units of the image file, total flux through aperture.\n",
    "    '''   \n",
    "\n",
    "    hdul = fits.open(file)\n",
    "    data = hdul[0].data\n",
    "    header = hdul[0].header\n",
    "    pix_area = header[\"PIXAR_SR\"]\n",
    "    # Create WCS object\n",
    "    wcs = WCS(header)\n",
    "\n",
    "    # Plot with imshow_norm\n",
    "    if show_plot:\n",
    "        try:\n",
    "            plt.figure(figsize = (8,8*zoom[1]/zoom[0]))\n",
    "        except:\n",
    "            plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(projection=wcs)\n",
    "        norm = simple_norm(data, stretch='asinh', percent=96.9)\n",
    "        im = ax.imshow(data, norm=norm, cmap='gray', origin='lower')\n",
    "        \n",
    "        # Add RA/Dec gridlines and labels\n",
    "        ax.coords.grid(True, color='white', ls='dotted')\n",
    "        ax.coords[0].set_axislabel('RA')\n",
    "        ax.coords[1].set_axislabel('Dec')\n",
    "    if (type(loc[0]) == float) or (type(loc[0])==np.float64):\n",
    "        x,y = wcs.all_world2pix(loc[0], loc[1], 0)\n",
    "        aperture = CircularAperture((x, y), r=radius.to_value(u.deg) / header['CDELT2'])\n",
    "        phot_result = aperture_photometry(data, aperture)\n",
    "        flux = phot_result['aperture_sum'][0]\n",
    "        if show_plot:\n",
    "            aperture.plot(color='red', lw=2, alpha=0.7, label=f'{flux} MJy')\n",
    "    else:\n",
    "        flux = []\n",
    "        for location in loc:\n",
    "            x,y = wcs.all_world2pix(location[0], location[1], 0)\n",
    "            aperture = CircularAperture((x, y), r=radius.to_value(u.deg) / header['CDELT2'])\n",
    "            phot_result = aperture_photometry(data, aperture)\n",
    "            this_flux = phot_result['aperture_sum'][0]*pix_area\n",
    "            flux.append(this_flux)\n",
    "            if show_plot:\n",
    "                aperture.plot(color='red', lw=2, alpha=0.7, label=f'{radius}\" Aperture')\n",
    "    if show_plot and (zoom is not None):\n",
    "        # Calculate half-width in pixels\n",
    "        pix_scale = abs(header['CDELT2']) * u.deg  # pixel scale in deg/pix\n",
    "        try:\n",
    "            npix_half_x = (zoom[0].to(u.deg) / pix_scale).value / 2\n",
    "            npix_half_y = (zoom[1].to(u.deg) / pix_scale).value / 2\n",
    "            ax.set_xlim(x - npix_half_x, x + npix_half_x)\n",
    "            ax.set_ylim(y - npix_half_y, y + npix_half_y)\n",
    "        except:\n",
    "            npix_half = (zoom.to(u.deg) / pix_scale).value / 2\n",
    "            ax.set_xlim(x - npix_half, x + npix_half)\n",
    "            ax.set_ylim(y - npix_half, y + npix_half)\n",
    "    if show_plot:\n",
    "        ax.legend()\n",
    "\n",
    "        # Colorbar\n",
    "        plt.colorbar(im, ax=ax, orientation='vertical', label='Flux')\n",
    "        \n",
    "        plt.title(f\"{file.split('.fi')[0].split('/')[-1].split('/')[-1]}\")\n",
    "        plt.show()\n",
    "    return flux\n",
    "get_aperture_flux(image_files[-1], loc, radius, show_plot= True, zoom = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filter_files[10]\n",
    "IFU_needed_files = which_fits(file, karin_SDuval_IFU_files)\n",
    "filter_name = extract_filter_name(file).upper()\n",
    "max_radius = radius_dict[filter_name]\n",
    "new_fits = []\n",
    "for i, IFU in enumerate(IFU_needed_files):      \n",
    "    new_fits.append(convolve_using_reference(IFU, filter_name, output_file = f'test_convolution_overwrite_ok{i}.fits'))\n",
    "\n",
    "\n",
    "image_candidates = [img for img in image_files if extract_filter_name(img).upper() == filter_name]\n",
    "if not image_candidates:\n",
    "    print(f\"No matching image for filter {filter_name}\")\n",
    "image_file = image_candidates[0]\n",
    "\n",
    "def radius_to_size(r, radii):\n",
    "    min_radius = np.min(radii)\n",
    "    max_radius = np.max(radii)\n",
    "    # Linearly map radius to marker size between 30 and 110\n",
    "    return 30 + (r - min_radius) / (max_radius - min_radius) * (110 - 30)\n",
    "\n",
    "filter_files_maybe = [filt for filt in filter_files if extract_filter_name(filt).upper() == filter_name]\n",
    "if not image_candidates:\n",
    "    print(f\"No matching image for filter {filter_name}\")\n",
    "filter_file = filter_files_maybe[0]\n",
    "\n",
    "\n",
    "filter_data = []\n",
    "with open(filter_file, 'r') as f:\n",
    "    header = f.readline().strip().split()\n",
    "    for line in f:\n",
    "        data_line = line.strip().split()\n",
    "        filter_data.append(data_line)\n",
    "if len(filter_data) < 2:\n",
    "    print(f\"Filter file {filter_file} seems empty or malformed.\")\n",
    "\n",
    "header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "filter_wl = np.array([try_float(row[0]) * 1e-10 for row in filter_T])\n",
    "filter_trans = np.array([try_float(row[1]) for row in filter_T])\n",
    "relative_fluxes = []\n",
    "raw_fluxes = []\n",
    "radii = np.linspace(0.1, max_radius.value, 10)\n",
    "print(f'Using 10 radii between 0.1 and {max_radius}')\n",
    "for radius in radii:\n",
    "    radius = radius*u.arcsec\n",
    "    marker_size = radius_to_size(radius.value, radii)\n",
    "\n",
    "    photo_flux = get_image_flux(image_file, test_loc, radius)\n",
    "    print('stitching convolved IFUs')\n",
    "    spectrum = stitch_spectra(new_fits, test_loc, radius)\n",
    "    \n",
    "    print('stitching raw IFUs', IFU_needed_files[0].split('/')[-1], IFU_needed_files[1].split('/')[-1])\n",
    "    raw_spectrum = stitch_spectra(IFU_needed_files, test_loc, radius)\n",
    "    print(raw_spectrum['wavelength'][0], raw_spectrum['wavelength'][-1])\n",
    "    \n",
    "    flux = get_Fnu_transmission(spectrum['intensity'], spectrum['wavelength'], filter_trans, filter_wl)/photo_flux\n",
    "    raw_flux = get_Fnu_transmission(raw_spectrum['intensity'], raw_spectrum['wavelength'], filter_trans, filter_wl)/photo_flux\n",
    "    \n",
    "    relative_fluxes.append(flux)\n",
    "    raw_fluxes.append(raw_flux)\n",
    "\n",
    "flux_v_radius = np.array([relative_fluxes, radii])\n",
    "raw_flux_v_radius = np.array([raw_fluxes, radii])\n",
    "np.save(f'Data_files/misc_data/flux_v_radius/{filter_name}_radius_dependance', flux_v_radius)\n",
    "if max(relative_fluxes) > 2:\n",
    "    plt.ylim(0, 2)\n",
    "    plt.ylabel(f'spec/photo flux \\n(cut to < 2)')\n",
    "else:\n",
    "    plt.ylabel('spec/photo flux')\n",
    "plt.scatter(radii, relative_fluxes, marker = 'o', label ='convolved')\n",
    "plt.scatter(radii, raw_fluxes, marker = '*', label ='unconvolved')\n",
    "plt.legend()\n",
    "plt.title(f\"Radius dependance for filter {filter_name}\\nmax_radius allowed : {max_radius}\")\n",
    "plt.xlabel('radius in arcseconds')\n",
    "plt.savefig(f'Data_files/misc_data/misc_plots/Radius_dependence_of_{filter_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all possible radii first for size scaling\n",
    "radius_factors = [0.1, 0.25, 0.5, 1, 1.25, 1.5, 2, 3]\n",
    "all_radii = np.array(radius_factors) * radius\n",
    "min_radius = np.min(all_radii)\n",
    "max_radius = np.max(all_radii)\n",
    "\n",
    "def radius_to_size(r):\n",
    "    # Linearly map radius to marker size between 30 and 110\n",
    "    return 30 + (r - min_radius) / (max_radius - min_radius) * (110 - 30)\n",
    "\n",
    "# Initialize storage including size\n",
    "flux_ratios = {'karin': {'flux': [], 'idx': [], 'size': [], 'color': 'red'},\n",
    "               'sara': {'flux': [], 'idx': [], 'size': [], 'color': 'blue'},\n",
    "               'misc': {'flux': [], 'idx': [], 'size': [], 'color': 'green'}}\n",
    "\n",
    "for j, filter_file in enumerate(filter_files):\n",
    "    filter_name = extract_filter_name(filter_file).upper()\n",
    "\n",
    "    # Match image file\n",
    "    image_candidates = [img for img in image_files if extract_filter_name(img).upper() == filter_name]\n",
    "    if not image_candidates:\n",
    "        print(f\"No matching image for filter {filter_name}\")\n",
    "        continue\n",
    "    image_file = image_candidates[0]\n",
    "\n",
    "    # Read filter data\n",
    "    filter_data = []\n",
    "    with open(filter_file, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        for line in f:\n",
    "            data_line = line.strip().split()\n",
    "            filter_data.append(data_line)\n",
    "    if len(filter_data) < 2:\n",
    "        print(f\"Filter file {filter_file} seems empty or malformed.\")\n",
    "        continue\n",
    "\n",
    "    header, filter_T = filter_data[:2], np.array(filter_data[2:])\n",
    "    filter_wl = np.array([try_float(row[0]) * 1e-10 for row in filter_T])\n",
    "    filter_trans = np.array([try_float(row[1]) for row in filter_T])\n",
    "\n",
    "    # Find compatible IFU files\n",
    "    IFU_files = glob.glob(f\"Data_files/IFU_files/my_convolutions/{filter_name}/*\")\n",
    "    print(f\"{filter_name} IFU files:\", IFU_files)\n",
    "\n",
    "    for IFU_file in IFU_files:\n",
    "        # Determine group\n",
    "        filename = os.path.basename(IFU_file)\n",
    "        if filename.startswith('SW'):\n",
    "            group = 'sara'\n",
    "        elif filename.startswith(('Arm', 'jw')):\n",
    "            group = 'karin'\n",
    "        else:\n",
    "            group = 'misc'\n",
    "\n",
    "\n",
    "        # For each radius factor, calculate flux and store\n",
    "        for factor in radius_factors:\n",
    "            test_radius = radius * factor\n",
    "            marker_size = radius_to_size(test_radius)\n",
    "    \n",
    "            # Load or stitch spectrum once\n",
    "            if full_coverage(filter_name, IFU_file) == 'good':\n",
    "                spectrum = get_IFU_spectrum(IFU_file, loc, test_radius, replace_negatives=0.001)\n",
    "            else:\n",
    "                file_class = IFU_file.split('/')[-1][:2]\n",
    "                if filter_name == \"F560W\":\n",
    "                    files_to_stitch = ['Data_files/IFU_files/my_convolutions/F560W/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_convolved_toF560W.fits', IFU_file]\n",
    "                else:\n",
    "                    files_to_stitch = glob.glob(f\"Data_files/IFU_files/my_convolutions/{filter_name}/{file_class}*\")\n",
    "                try:\n",
    "                    spectrum = stitch_spectra(files_to_stitch, loc, test_radius)\n",
    "                    print(f'Stitched files for {filter_name}: {files_to_stitch}')\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to stitch files for {filter_name}: {e}\")\n",
    "                    continue\n",
    "            # Calculate photometric flux from image for this radius\n",
    "            photo_flux = get_image_flux(image_file, loc, test_radius)\n",
    "\n",
    "            # Calculate transmission flux for this radius\n",
    "            flux = get_Fnu_transmission(spectrum['intensity'], spectrum['wavelength'], filter_trans, filter_wl)\n",
    "\n",
    "            flux_ratios[group]['flux'].append(flux / photo_flux)\n",
    "            flux_ratios[group]['idx'].append(j)\n",
    "            flux_ratios[group]['size'].append(marker_size)\n",
    "for group in flux_ratios:\n",
    "    plt.scatter(x_axis[flux_ratios[group]['idx']],\n",
    "                flux_ratios[group]['flux'],\n",
    "                s=flux_ratios[group]['size'],\n",
    "                color=flux_ratios[group]['color'],\n",
    "                label=group)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loc = [202.4340450, 47.1732517] \n",
    "radius = 0.75*u.arcsec\n",
    "data = []\n",
    "for i, file in enumerate(SDuval_IFU_files):\n",
    "    IFU_hdul = fits.open(file)\n",
    "    header = IFU_hdul[\"SCI\"].header\n",
    "    cube = SpectralCube.read(file, hdu='SCI')\n",
    "    wcs = WCS(header)\n",
    "\n",
    "    spectral_axis = cube.spectral_axis\n",
    "    data.append(get_IFU_spectrum(file, loc, radius))\n",
    "\n",
    "first_end = len(data[0]['wavelength'][data[0]['wavelength'] > data[1]['wavelength'][0]])\n",
    "second_start = len(data[1]['wavelength'][data[1]['wavelength'] < data[0]['wavelength'][-1]])\n",
    "second_end = len(data[1]['wavelength'][data[1]['wavelength'] > data[2]['wavelength'][0]])\n",
    "third_start = len(data[2]['wavelength'][data[2]['wavelength'] < data[1]['wavelength'][-1]])\n",
    "third_end = len(data[2]['wavelength'][data[2]['wavelength'] > data[3]['wavelength'][0]])\n",
    "fourth_start = len(data[3]['wavelength'][data[3]['wavelength'] < data[2]['wavelength'][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(data[0]['wavelength'][-2*first_end:], data[0]['intensity'][-2*first_end:], color = 'blue', label = 'data1')\n",
    "plt.plot(data[1]['wavelength'][:2*second_start], data[1]['intensity'][:2*second_start], color = 'orange', label = 'data2')\n",
    "plt.show()\n",
    "plt.plot(data[1]['wavelength'][-2*second_end:]*1e+6, data[1]['intensity'][-2*second_end:], color = 'blue', label = 'channel 2')\n",
    "plt.plot(data[2]['wavelength'][:2*third_start]*1e+6, data[2]['intensity'][:2*third_start], color = 'orange', label = 'channel 3')\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('MIRI Channels 2 and 3 overlapping region')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(data[2]['wavelength'][-2*third_end:]*1e+6, data[2]['intensity'][-2*third_end:], color = 'orange', label = 'channel 3')\n",
    "plt.plot(data[3]['wavelength'][:2*fourth_start]*1e+6, data[3]['intensity'][:2*fourth_start], color = 'green', label = 'channel 4')\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('MIRI Channels 3 and 4 overlapping region')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[3]['wavelength'], data[3]['intensity'], color = 'green', label = 'channel 4')\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('intensity')\n",
    "plt.title('Channels 3 and 4 overlapping region')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spectrum = find_point_spectrum(files[0], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[-2*first_end:], spectrum[-2*first_end:], color = 'red', label = 'channel 1')\n",
    "\n",
    "spectrum = find_point_spectrum(files[1], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "\n",
    "plt.plot(wavelengths[:2*second_start], spectrum[:2*second_start], color = 'orange', label = 'channel 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "############################\n",
    "spectrum = find_point_spectrum(files[1], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[-2*second_end:], spectrum[-2*second_end:], color = 'orange', label = 'channel 2')\n",
    "\n",
    "spectrum = find_point_spectrum(files[2], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[:2*third_start], spectrum[:2*third_start], color = 'green', label = 'channel 3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#######################\n",
    "spectrum = find_point_spectrum(files[2], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[-2*third_end:], spectrum[-2*third_end:], color = 'green', label = 'channel 3')\n",
    "\n",
    "spectrum = find_point_spectrum(files[3], loc)\n",
    "wavelengths = spectrum.spectral_axis\n",
    "plt.plot(wavelengths[:2*fourth_start], spectrum[:2*fourth_start], color = 'blue', label = 'channel 4')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = []\n",
    "ends = []\n",
    "for i,file in enumerate(karin_SDuval_IFU_files):\n",
    "    cube = SpectralCube.read(file, hdu='SCI')\n",
    "    starts.append(cube.spectral_axis[0].value*1e-6)\n",
    "    ends.append(cube.spectral_axis[-1].value*1e-6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_fits = glob.glob('Data_files/IFU_files/*convolved*')\n",
    "for file in convolved_fits:\n",
    "    cube = SpectralCube.read(file)\n",
    "    cube_wl = cube.spectral_axis\n",
    "    filter_name = get_convolved_filter_name(file)\n",
    "    filter_range = get_filter_wl_range(filter_name)\n",
    "    print('filter spans ', filter_range)\n",
    "    print('cube spans ', cube_wl[0], cube_wl[-1])\n",
    "    if (filter_range[0].value > cube_wl[0].value*1e-6) & (filter_range[1].value < cube_wl[-1].value*1e-6):\n",
    "        print('Fully contained')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = SpectralCube.read(IFU_file, hdu='SCI')\n",
    "cube_wl = cube.spectral_axis.to(u.m)\n",
    "wl1, wl2 = get_filter_wl_range(extract_filter_name(file).upper())\n",
    "wl2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = webbpsf.MIRI()\n",
    "inst.filter = 'F1500W'\n",
    "psf = inst.calc_psf(monochromatic=1.5e-5)\n",
    "psf_data = psf[0].data\n",
    "hdu = fits.open(karin_IFU_files[-1])['SCI']\n",
    "header = hdu.header\n",
    "print('IFU pixel scale :', (header['CDELT2']*u.deg).to(u.arcsec))\n",
    "print('psf pixel scale :', psf[0].header['PIXELSCL'], 'arcsec')\n",
    "\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define center\n",
    "ny, nx = psf_data.shape\n",
    "y, x = np.indices(psf_data.shape)\n",
    "cx, cy = nx // 2, ny // 2\n",
    "r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "\n",
    "# Flatten and sort by radius\n",
    "r_flat = r.flatten()\n",
    "psf_flat = psf_data.flatten()\n",
    "sort_idx = np.argsort(r_flat)\n",
    "\n",
    "r_sorted = r_flat[sort_idx]\n",
    "psf_sorted = psf_flat[sort_idx]\n",
    "\n",
    "# Bin radially\n",
    "bin_size = 1  # pixel\n",
    "my_max_r = int(r.max())\n",
    "my_radial_median = [np.median(psf_data[(r >= i) & (r < i+bin_size)]) for i in range(my_max_r)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogy(range(my_max_r), my_radial_median)\n",
    "plt.xlabel(\"Radius [pixels]\")\n",
    "plt.ylabel(\"PSF intensity\")\n",
    "plt.title(\"Radial PSF profile\")\n",
    "plt.xlim(0,100)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.convolution import convolve, convolve_fft\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "from photutils.psf.matching import create_matching_kernel\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import webbpsf\n",
    "\n",
    "def convolve_JWST_cube_with_psf_plot(input_cubefile, target_lam, savename, target_inst, exclusion_threshold=0.9):\n",
    "    '''\n",
    "    Smooth a JWST cube to the resolution at a given wavelength and plot PSF comparison.\n",
    "    '''\n",
    "    NRS_handoff = 4.1 # micron\n",
    "\n",
    "    def get_fwhm_MIRI(lam):\n",
    "        return 0.033*(lam) + 0.106 # arcsec\n",
    "    \n",
    "    def get_x_fwhm_NRS(lamda):\n",
    "        if lamda < NRS_handoff:\n",
    "            return (0.01*lamda) + 0.14 # arcsec\n",
    "        elif lamda >= NRS_handoff:\n",
    "            return (0.02*lamda) + 0.15 # arcsec\n",
    "    def get_y_fwhm_NRS(lamda):\n",
    "        if lamda < NRS_handoff:\n",
    "            return (0.01*lamda) + 0.16 # arcsec\n",
    "        elif lamda >= NRS_handoff:\n",
    "            return (0.01*lamda) + 0.15 # arcsec\n",
    "    \n",
    "    def get_spectral_axis(cube):\n",
    "        wav_short = cube[1].header['CRVAL3']\n",
    "        delta_lam = cube[1].header['CDELT3']\n",
    "        lam_n = len(cube[1].data)\n",
    "        spectral_axis = np.asarray([wav_short + (delta_lam*i) for i in range(lam_n)])\n",
    "        return spectral_axis\n",
    "\n",
    "    ### ==== PREP INPUT CUBE ==== ###\n",
    "    input_cube = fits.open(input_cubefile)\n",
    "    input_spectral_axis = get_spectral_axis(input_cube)\n",
    "    input_slice = input_cube[1].data[0]\n",
    "    if input_cube[0].header['INSTRUME'] == 'NIRSPEC':\n",
    "        input_cube_type = 'NRS'\n",
    "    elif input_cube[0].header['INSTRUME'] == 'MIRI':\n",
    "        input_cube_type = 'MIRI'\n",
    "\n",
    "    # Pixel grid for kernels\n",
    "    y, x = np.mgrid[0:input_slice.shape[0], 0:input_slice.shape[1]]\n",
    "    midx, midy = int(np.floor(input_slice.shape[1]/2)), int(np.floor(input_slice.shape[0]/2))\n",
    "\n",
    "    ### ==== GET TARGET GAUSSIAN PSF ==== ###\n",
    "    if target_inst == 'NRS':\n",
    "        target_x_fwhm = get_x_fwhm_NRS(target_lam)\n",
    "        target_sig_arcsec_x = target_x_fwhm/np.sqrt(8*np.log(2))\n",
    "        target_sig_pix_x = target_sig_arcsec_x/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "    \n",
    "        target_y_fwhm = get_y_fwhm_NRS(target_lam)\n",
    "        target_sig_arcsec_y = target_y_fwhm/np.sqrt(8*np.log(2))\n",
    "        target_sig_pix_y = target_sig_arcsec_y/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "    elif target_inst == 'MIRI':\n",
    "        target_fwhm = get_fwhm_MIRI(target_lam)\n",
    "        target_sig_arcsec = target_fwhm/np.sqrt(8*np.log(2))\n",
    "        target_sig_pix_x = target_sig_arcsec/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "        target_sig_pix_y = target_sig_pix_x\n",
    "\n",
    "    target_gauss = Gaussian2D(1, midx, midy, target_sig_pix_x, target_sig_pix_y)\n",
    "    target_kernel = target_gauss(x, y)\n",
    "\n",
    "    ### ==== CALCULATE WEBBPSF PSF ==== ###\n",
    "    inst = webbpsf.NIRCam()\n",
    "    inst.filter = f'F200W'\n",
    "    psf_webbpsf = inst.calc_psf(monochromatic=target_lam*1e-6)\n",
    "    psf_data_webbpsf = psf_webbpsf[0].data\n",
    "    psf_data_webbpsf /= psf_data_webbpsf.sum()\n",
    "\n",
    "    ### ==== PLOT COMPARISON OF PSF ENIRCLED ENERGY ==== ###\n",
    "    def compute_EE(psf_data):\n",
    "        ny, nx = psf_data.shape\n",
    "        y, x = np.indices(psf_data.shape)\n",
    "        cx, cy = nx // 2, ny // 2\n",
    "        r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "        r_flat = r.flatten()\n",
    "        psf_flat = psf_data.flatten()\n",
    "        sort_idx = np.argsort(r_flat)\n",
    "        r_sorted = r_flat[sort_idx]\n",
    "        psf_sorted = psf_flat[sort_idx]\n",
    "\n",
    "        max_r = int(r_sorted.max())\n",
    "        EE = []\n",
    "        for i in range(max_r):\n",
    "            annulus_mask = (r_sorted >= 0) & (r_sorted < i+1)\n",
    "            ee_value = psf_sorted[annulus_mask].sum()\n",
    "            EE.append(ee_value)\n",
    "        EE = np.array(EE) / psf_sorted.sum()  # normalize\n",
    "        return EE, max_r\n",
    "\n",
    "    EE_webbpsf, max_r_webbpsf = compute_EE(psf_data_webbpsf)\n",
    "    EE_gauss, max_r_gauss = compute_EE(target_kernel)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(range(max_r_webbpsf), EE_webbpsf, label='webbpsf PSF')\n",
    "    plt.plot(range(max_r_gauss), EE_gauss, label='Gaussian PSF')\n",
    "    plt.xlabel(\"Radius [pixels]\")\n",
    "    plt.ylabel(\"Encircled Energy (normalized)\")\n",
    "    plt.title(f\"Encircled Energy Comparison @ {target_lam:.2f} μm\")\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.xlim(0,40)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ### ==== CONVOLUTION PROCESS ==== ###\n",
    "    convolved_planes = []\n",
    "    convolved_uncertainty_planes = []\n",
    "    for i in tqdm(range(len(input_spectral_axis))):\n",
    "        this_lam = input_spectral_axis[i]\n",
    "        this_slice = input_cube[1].data[i]\n",
    "        this_slice_unc = input_cube[2].data[i]\n",
    "\n",
    "        if this_lam <= target_lam:\n",
    "            if input_cube_type == 'NRS':\n",
    "                this_x_fwhm_NRS = get_x_fwhm_NRS(this_lam)\n",
    "                this_sig_arcsec_x = this_x_fwhm_NRS/np.sqrt(8*np.log(2))\n",
    "                this_sig_pix_x = this_sig_arcsec_x/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "                this_y_fwhm_NRS = get_y_fwhm_NRS(this_lam)\n",
    "                this_sig_arcsec_y = this_y_fwhm_NRS/np.sqrt(8*np.log(2))\n",
    "                this_sig_pix_y = this_sig_arcsec_y/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "            elif input_cube_type == 'MIRI':\n",
    "                this_x_fwhm_MIRI = get_fwhm_MIRI(this_lam)\n",
    "                this_sig_arcsec_x = this_x_fwhm_MIRI/np.sqrt(8*np.log(2))\n",
    "                this_sig_pix_x = this_sig_arcsec_x/np.sqrt(input_cube[1].header['PIXAR_A2'])\n",
    "                this_sig_pix_y = this_sig_pix_x\n",
    "\n",
    "            input_gauss = Gaussian2D(1, midx, midy, this_sig_pix_x, this_sig_pix_y)\n",
    "            input_kernel = input_gauss(x, y)\n",
    "            matching_kernel = create_matching_kernel(input_kernel, target_kernel)\n",
    "\n",
    "            fake_slice = np.where(this_slice!=this_slice, 0, 1)\n",
    "            fake_convolved_image = convolve_fft(fake_slice, matching_kernel, boundary='fill', fill_value=0, preserve_nan=True)\n",
    "            keep_mask = np.where(fake_convolved_image>=exclusion_threshold, 1, np.nan)\n",
    "\n",
    "            convolved_image = convolve_fft(this_slice, matching_kernel, boundary='fill', fill_value=0, preserve_nan=True)\n",
    "            convolved_image *= keep_mask\n",
    "            convolved_planes.append(convolved_image)\n",
    "\n",
    "            unc_matching_kernel = matching_kernel**2\n",
    "            unc_matching_kernel /= unc_matching_kernel.sum()\n",
    "            convolved_unc_image = convolve_fft(this_slice_unc, unc_matching_kernel, boundary='fill', fill_value=0, preserve_nan=True)\n",
    "            convolved_unc_image *= keep_mask\n",
    "            convolved_uncertainty_planes.append(convolved_unc_image)\n",
    "        else:\n",
    "            convolved_planes.append(this_slice)\n",
    "            convolved_uncertainty_planes.append(this_slice_unc)\n",
    "\n",
    "    convolved_planes = np.asarray(convolved_planes)\n",
    "    convolved_uncertainty_planes = np.asarray(convolved_uncertainty_planes)\n",
    "    input_cube[1].data = convolved_planes\n",
    "    input_cube[2].data = convolved_uncertainty_planes\n",
    "    input_cube.writeto(savename, overwrite=True)\n",
    "\n",
    "    return input_cube\n",
    "convolve_JWST_cube_with_psf_plot(\n",
    "    karin_IFU_files[1], \n",
    "    1.988, \n",
    "    'Data_files/IFU_files/testing_Grants_function.fits', \n",
    "    'NRS', \n",
    "    exclusion_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "hdu = fits.open(karin_IFU_files[1])[\"SCI\"]\n",
    "header = hdu.header\n",
    "pix_scale = (header[\"CDELT1\"]*u.deg).to(u.arcsec)\n",
    "inst = webbpsf.NIRCam()\n",
    "inst.filter = 'F200W'\n",
    "psf = inst.calc_psf(monochromatic=1.988e-6, fov_arcsec = 10)\n",
    "psf_data = psf[0].data\n",
    "# Re-normalize PSF\n",
    "print(psf_data.sum())\n",
    "psf_data /= psf_data.sum()\n",
    "\n",
    "# Calculate EE in radial bins\n",
    "ny, nx = psf_data.shape\n",
    "y, x = np.indices(psf_data.shape)\n",
    "cx, cy = nx // 2, ny // 2\n",
    "r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "\n",
    "r_arcsec = r * pix_scale\n",
    "\n",
    "max_r_arcsec = r_arcsec.max()\n",
    "bin_edges = np.linspace(0, max_r_arcsec, 100)\n",
    "EE = []\n",
    "\n",
    "for rmax in bin_edges:\n",
    "    mask = r_arcsec <= rmax\n",
    "    EE.append(psf_data[mask].sum())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(bin_edges, EE)\n",
    "plt.xlabel(\"Radius [arcsec]\")\n",
    "plt.ylabel(\"Encircled Energy\")\n",
    "plt.title(\"MIRI F1500W Encircled Energy\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(0,10)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = SpectralCube.read(karin_IFU_files[1], hdu = \"SCI\")\n",
    "cube.spectral_axis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filter_wl_range('F200W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.calc_psf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open(karin_IFU_files[0])['SCI']\n",
    "header = hdu.header\n",
    "wcs = WCS(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs.wcs.crval[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open(karin_IFU_files[0])[0]\n",
    "hdu.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
