{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/d/ret1/Taylor/jupyter_notebooks/Research') #TJ change working directory to be the parent directory\n",
    "from Py_files.Functions import *\n",
    "_, filter_files = generate_list_of_files(filter_directory, image_directory)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "karin_SDuval_IFU_files = ['Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/SW_IFU_ch4-shortmediumlong_s3d.fits'\n",
    "            ]\n",
    "\n",
    "karin_IFU_files = [ 'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g140m-f100lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g235m-f170lp_s3d.fits',\n",
    "             'Data_files/IFU_files/raw_IFUs/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "             'Data_files/IFU_files/Arm2_Level3_ch4-shortmediumlong_s3d.fits',\n",
    "            ]\n",
    "Thomas_IFU_file = 'Data_files/IFU_files/M51_SW_f290lp_g395m-f290lp_s3d.fits'\n",
    "\n",
    "SDuval_IFU_files = ['Data_files/IFU_files/raw_IFUs/SW_IFU_ch1-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch2-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch3-shortmediumlong_s3d.fits',\n",
    "                  'Data_files/IFU_files/raw_IFUs/SW_IFU_ch4-shortmediumlong_s3d.fits']\n",
    "\n",
    "Grant_conv_IFU_files = ['Data_files/IFU_files/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/jw03435-o012_t014_nirspec_g395m-f290lp_s3d_conv17p1.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch1-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch2-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch3-shortmediumlong_s3d_conv17p1um.fits',\n",
    "                        'Data_files/IFU_files/SW_IFU_ch4-shortmediumlong_s3d_conv17p1um.fits']\n",
    "\n",
    "full_raw_ifu_files_loc0 = ['Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g140m-f100lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g235m-f170lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/jw03435-o004_t005_nirspec_g395m-f290lp_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_0/Arm1_Level3_ch4-shortmediumlong_s3d_trimmed.fits']\n",
    "full_raw_ifu_files_loc1 = ['Data_files/IFU_files/raw_IFUs/location_1/jw03435-o012_t014_nirspec_g140m-f100lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/jw03435-o012_t014_nirspec_g235m-f170lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/jw03435-o012_t014_nirspec_g395m-f290lp_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_1/Arm2_Level3_ch4-shortmediumlong_s3d_trimmed.fits']\n",
    "#TJ location 2 also within loc1 files\n",
    "full_raw_ifu_files_loc3 = ['Data_files/IFU_files/raw_IFUs/location_3/jw03435-o006_t010_nirspec_g140m-f100lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/jw03435-o006_t010_nirspec_g235m-f170lp_s3d_trimmed.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/jw03435-o006_t010_nirspec_g395m-f290lp_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch1-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch2-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch3-shortmediumlong_s3d.fits',\n",
    "              'Data_files/IFU_files/raw_IFUs/location_3/Arm3_Level3_ch4-shortmediumlong_s3d_trimmed.fits']\n",
    "\n",
    "\n",
    "\n",
    "def get_EW_using_filters(feature_filter, continuum_filters, location, radius):\n",
    "    #TJ load files\n",
    "    feature_file = [x for x in image_files if extract_filter_name(x) == feature_filter][0]\n",
    "    cont_files = [x for x in image_files if extract_filter_name(x) in continuum_filters]\n",
    "\n",
    "    #TJ get all 3 image fluxes\n",
    "    Fnu_feature = get_image_flux(feature_file, location, radius, replace_negatives=False)\n",
    "    Fnu_cont = [get_image_flux(f, location, radius, replace_negatives=False) for f in cont_files]\n",
    "\n",
    "    #TJ look up pivot wavelengths\n",
    "    pivot_feat = jwst_pivots[feature_filter]\n",
    "    pivot_cont = [jwst_pivots[extract_filter_name(f)] for f in cont_files]\n",
    "    \n",
    "    #TJ convert continuum levels into F_lambda using pivot wavelengths, still need to multiply by dlamda\n",
    "    f位_cont = [(Fnu * c / pivot**2).to(u.W / u.m**2 / u.m)\n",
    "               for Fnu, pivot in zip(Fnu_cont, pivot_cont)]\n",
    "    \n",
    "    #TJ get mean wavelengths\n",
    "    cont_wls = [jwst_means[f] for f in continuum_filters]\n",
    "    line_wl = jwst_means[feature_filter]\n",
    "\n",
    "    #TJ interpolate continuum values to the feature wavelength\n",
    "    feature_continuum = np.interp(\n",
    "        line_wl.value,\n",
    "        [w.value for w in cont_wls],\n",
    "        [f.value for f in f位_cont]\n",
    "    ) * u.W / u.m**2 / u.m\n",
    "    \n",
    "    #TJ print continuum if needed\n",
    "    #print(\"F_lamda of photo continuum : \", feature_continuum)\n",
    "    #TJ get filter transmission curve info\n",
    "    wl, T = get_filter_data(feature_filter)\n",
    "\n",
    "    #TJ multiply feature F_lambda by dlambda to complete unit conversion\n",
    "    norm = np.trapz(T, wl) / np.max(T)\n",
    "    cont_in_filter = feature_continuum * norm\n",
    "    \n",
    "    #TJ convert feature filter's F_nu into F_lamda\n",
    "    f位_feature = ((Fnu_feature * c / pivot_feat**2).to(u.W / u.m**2 / u.m))*norm \n",
    "\n",
    "    #TJ feature area is only the area above the continuum\n",
    "    feature_only = f位_feature - cont_in_filter\n",
    "\n",
    "    #TJEquivalent width is this area divided by the continuum level\n",
    "    EW = (feature_only / feature_continuum).to(u.m)\n",
    "\n",
    "    return EW\n",
    "\n",
    "def get_raw_EW_using_integration(ifu_file, location, radius, feature_wavelength, feature_width = 8, show_plot = True):\n",
    "    plot_range = 50 \n",
    "    spectrum = get_IFU_spectrum(ifu_file, location, radius, replace_negatives = False) \n",
    "    feature_idx = np.argmin(np.abs(spectrum['wavelength'] - feature_wavelength.to(u.m))) \n",
    "    continuum_value, continuum_std = get_continuum_around(spectrum['wavelength'], spectrum['F_lambda'], feature_idx, window_size=25, iqr_mult=1.5) \n",
    "    #print(\"F_lamda IFU continuum : \", continuum_value)\n",
    "\n",
    "    feature_start = feature_idx - int(feature_width/2) \n",
    "    feature_stop = feature_idx + int(feature_width/2) \n",
    "    area = np.trapz(spectrum['F_lambda'][feature_start:feature_stop] - continuum_value, spectrum['wavelength'][feature_start:feature_stop]) \n",
    "    if show_plot: \n",
    "        plt.plot(spectrum['wavelength'][feature_idx-int(plot_range/2):feature_idx+int(plot_range/2)],spectrum['F_lambda'][feature_idx-int(plot_range/2):feature_idx+int(plot_range/2)]-continuum_value) \n",
    "        plt.plot(spectrum['wavelength'][feature_idx-int(plot_range/2): feature_idx+int(plot_range/2)], [0]*len(spectrum['wavelength'][feature_idx-int(plot_range/2): feature_idx+int(plot_range/2)]), color = 'green', label = 'continuum') \n",
    "        plt.axvline(x=spectrum['wavelength'][feature_start].value, color = 'red', linestyle = '--') \n",
    "        plt.axvline(x=spectrum['wavelength'][feature_stop].value, color = 'red', linestyle = '--') \n",
    "        plt.show() \n",
    "    return area/continuum_value\n",
    "\n",
    "def get_adjusted_EW_using_integration(spectrum, feature_wavelength, feature_width = 8, show_plot = True):\n",
    "    plot_range = 50 \n",
    "    feature_idx = np.argmin(np.abs(spectrum[0]['frequency'] - (c/(feature_wavelength.to(u.m))))) \n",
    "    continuum_value, continuum_std = get_continuum_around(spectrum[0]['frequency'], spectrum[0]['F_nu'], feature_idx, window_size=25, iqr_mult=1.5) \n",
    "    #print(\"F_lamda adjusted IFU continuum : \", continuum_value)\n",
    "\n",
    "    feature_start = feature_idx - int(feature_width/2) \n",
    "    feature_stop = feature_idx + int(feature_width/2) \n",
    "    area = np.trapz(spectrum[0]['F_nu'][feature_start:feature_stop] - continuum_value, spectrum[0]['frequency'][feature_start:feature_stop]) \n",
    "    if show_plot: \n",
    "        plt.plot(spectrum[0]['frequency'][feature_idx-int(plot_range/2):feature_idx+int(plot_range/2)],spectrum[0]['F_nu'][feature_idx-int(plot_range/2):feature_idx+int(plot_range/2)]-continuum_value) \n",
    "        plt.plot(spectrum[0]['frequency'][feature_idx-int(plot_range/2): feature_idx+int(plot_range/2)], [0]*len(spectrum[0]['frequency'][feature_idx-int(plot_range/2): feature_idx+int(plot_range/2)]), color = 'green', label = 'continuum') \n",
    "        plt.axvline(x=spectrum[0]['frequency'][feature_start].value, color = 'red', linestyle = '--') \n",
    "        plt.axvline(x=spectrum[0]['frequency'][feature_stop].value, color = 'red', linestyle = '--') \n",
    "        plt.show() \n",
    "    EW_in_hz = (area/continuum_value)\n",
    "    mean_nu = (c/pa_alpha_wl).to(u.Hz)\n",
    "    EW = -(c/(mean_nu**2))*EW_in_hz\n",
    "    return EW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_alpha_wl = 1.879e-6*u.m\n",
    "perc_errors = []\n",
    "corrected_perc_errors = []\n",
    "radius = 1*u.arcsec\n",
    "for loc, file in zip([0,1,2,3], [full_raw_ifu_files_loc0, full_raw_ifu_files_loc1, full_raw_ifu_files_loc1, full_raw_ifu_files_loc3]):\n",
    "    filt = get_EW_using_filters('F187N', ['F150W', 'F300M'], locations[loc], radius) \n",
    "    raw = get_EW_using_integration(file[1], locations[loc], radius, pa_alpha_wl)\n",
    "\n",
    "    new_spectrum = adjust_spectrum(file[1], \"F187N\", image_files, locations[loc], radius, adjustment_operation = 'multiply')\n",
    "    adjusted = get_adjusted_EW_using_integration(new_spectrum, pa_alpha_wl, feature_width = 8, show_plot = True)\n",
    "    percent_E = 100*((filt-raw)/raw)\n",
    "    corrected_percent_E = 100*((filt-adjusted)/adjusted)\n",
    "    print(f'percent error : {percent_E:.2f}%')\n",
    "    print(f'adjusted percent error : {corrected_percent_E:.2f}%')\n",
    "    perc_errors.append(percent_E)\n",
    "    corrected_perc_errors.append(corrected_percent_E)\n",
    "plt.scatter(range(len(perc_errors)), perc_errors, color = 'red')\n",
    "plt.scatter(range(len(corrected_perc_errors)), corrected_perc_errors, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_alpha_wl = 1.879e-6*u.m\n",
    "perc_errors = []\n",
    "corrected_perc_errors = []\n",
    "radius = 1*u.arcsec\n",
    "for loc, file in zip([0,1,2,3], [full_raw_ifu_files_loc0, full_raw_ifu_files_loc1, full_raw_ifu_files_loc1, full_raw_ifu_files_loc3]):\n",
    "    filt = get_EW_using_filters('F187N', ['F150W', 'F300M'], locations[loc], radius) \n",
    "    raw = get_EW_using_integration(file[1], locations[loc], radius, pa_alpha_wl)\n",
    "\n",
    "    new_spectrum = adjust_spectrum(file[1], \"F187N\", image_files, locations[loc], radius, adjustment_operation = 'add')\n",
    "    adjusted = get_adjusted_EW_using_integration(new_spectrum, pa_alpha_wl, feature_width = 8, show_plot = True)\n",
    "    percent_E = 100*((filt-raw)/raw)\n",
    "    corrected_percent_E = 100*((filt-adjusted)/adjusted)\n",
    "    print(f'percent error : {percent_E:.2f}%')\n",
    "    print(f'adjusted percent error : {corrected_percent_E:.2f}%')\n",
    "    perc_errors.append(percent_E)\n",
    "    corrected_perc_errors.append(corrected_percent_E)\n",
    "plt.scatter(range(len(perc_errors)), perc_errors, color = 'red')\n",
    "plt.scatter(range(len(corrected_perc_errors)), corrected_perc_errors, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Data_files/Kiana_files/*')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "t = Table.read(files[0], format=\"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
