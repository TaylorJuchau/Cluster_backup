{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "#sys.path.append('/d/ret1/Taylor/jupyter_notebooks/Research/slug2')  # Path to slug2 directory\n",
    "sys.path.append('/project/phangs/tjuchau/Cluster_backup/slug2')\n",
    "\n",
    "import os\n",
    "#home_directory = \"/d/ret1/Taylor/jupyter_notebooks/Research\" \n",
    "home_directory = \"/project/phangs/tjuchau/Cluster_backup\" \n",
    "os.chdir(home_directory) #TJ change working directory to be the parent directory\n",
    "from Py_files.Functions import *\n",
    "\n",
    "import glob\n",
    "import re\n",
    "#slug_path = \"/d/ret1/Taylor/jupyter_notebooks/Research/slug2/bin/slug\"\n",
    "slug_path = \"/project/phangs/tjuchau/Cluster_backup/slug2/bin/slug\"\n",
    "#os.chdir(\"/d/ret1/Taylor/jupyter_notebooks/Research/slug2\")\n",
    "os.chdir(\"/project/phangs/tjuchau/Cluster_backup/slug2\")\n",
    "import slugpy\n",
    "#wd = '/d/ret1/Taylor/jupyter_notebooks/Research'\n",
    "wd = '/project/phangs/tjuchau'\n",
    "slug_output_dir = '/project/phangs/tjuchau/Data_files/misc_data/slug_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_float(x):\n",
    "    '''\n",
    "    Try to convert an item or an array of items to float.\n",
    "    If conversion fails, returns original value(s).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : scalar or array-like\n",
    "        Item(s) to convert.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float, array of floats, or original input if conversion fails.\n",
    "    '''\n",
    "    # If x is array-like, attempt vectorized conversion\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        try:\n",
    "            return np.array(x, dtype=float)\n",
    "        except ValueError:\n",
    "            return x\n",
    "    else:\n",
    "        # Scalar input\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            return x\n",
    "            \n",
    "def do_alex_model(model_name, mass, N=1000):\n",
    "    '''Replication of Alex's model'''\n",
    "    input_file = f\"{model_name}.slugin\"\n",
    "    \n",
    "    with open(input_file, 'w') as f:\n",
    "        f.write(f'model_name {model_name}\\n')\n",
    "        f.write(f'out_dir {slug_output_dir}\\n') #TJ this is where the output files will be written to\n",
    "        f.write(f'verbosity 1\\n') #TJ level of printed outputs while running (0=only warnings/errors) (1=some outputs) (2=lots of outputs)\n",
    "        ##################################################################\n",
    "        # Parameters controlling simulation execution and physical model #\n",
    "        ##################################################################\n",
    "        f.write(f'sim_type cluster\\n') #TJ must be either galaxy or cluster (defaults to galaxy)\n",
    "        f.write(f'n_trials {N}\\n') #TJ total number of model clusters to run\n",
    "        #f.write(f'checkpoint_interval = 100\\n') #TJ create checkpoint after this many trials (default to no checkpointing)\n",
    "        f.write(f'time_step 1.0e6\\n') #TJ simulation runs for 1million years before computing new values\n",
    "        #f.write(f'start_time 1.0e6\\n') #TJ default start time is the same as timestep\n",
    "        f.write(f'end_time 1.0e7\\n') #TJ how long does each simulation run for in years\n",
    "        #f.write(f'sfr 0.001\\n') #TJ star formation rate, ignored for sim types = cluster\n",
    "        #f.write(f'sfh sfh.txt\\n') #TJ star formation history, ignored for sim types = cluster\n",
    "        f.write(f'cluster_mass {mass}\\n') #TJ cluster mass in solar masses, ignored for sim type = galaxy\n",
    "        #f.write(f'redshift 0\\n') #TJ defaults to 0\n",
    "        ##################################################################\n",
    "        # Parameters controlling simulation outputs #\n",
    "        ##################################################################\n",
    "        f.write(f'out_cluster 1\\n') #TJ output cluster properties? default = 1\n",
    "        f.write(f'out_cluster_phot 1\\n') #TJ output cluster photometry? (must specify filters also)\n",
    "        f.write(f'out_cluster_spec 0\\n') #TJ output cluster spectroscopy? *adds significant computation time*\n",
    "        f.write(f'out_cluster_yield 1\\n') #TJ output cluster nucleosynthesis yields?\n",
    "        #f.write(f'out_integrated 1\\n') #TJ output integrated properties of galaxy? ignored for sim types = cluster\n",
    "        #f.write(f'out_integrated_phot 1\\n') #TJ output integrated photometry of galaxy? ignored for sim types = cluster\n",
    "        #f.write(f'out_integrated_spec 1\\n') #TJ output integrated spectroscopy of galaxy? ignored for sim types = cluster\n",
    "        #f.write(f'out_integrated_yield 1\\n') #TJ output integrated chemical yields of galaxy? ignored for sim types = cluster\n",
    "        f.write(f'output_mode ascii\\n') #TJ can be either binary, ascii, or fits\n",
    "        #####################################################################\n",
    "        # Parameters controlling the physical models used for stars         #\n",
    "        #####################################################################\n",
    "        #f.write(f'imf lib/imf/chabrier.imf\\n') #TJ what imf to use? defaults to chabrier 2001\n",
    "        #f.write(f'cmf lib/cmf/slug_default.cmf\\n') #TJ cluster mass function for galaxies, ignored for sim types = cluster\n",
    "        f.write(f'clf lib/clf/nodisrupt.clf\\n') #TJ cluster lifetime Default: lib/clf/slug_default.clf (dN/dt ~ t^-1.9)\n",
    "        f.write(f'tracks mist_2016_vvcrit_40\\n') #TJ choose the stellar track. Defaults to geneva_2013_vvcrit_00\n",
    "        f.write(f'atmospheres lib/atmospheres\\n') #TJ directory of the stellar atmospheres\n",
    "        f.write(f'specsyn_mode sb99\\n') #TJ Spectral synthesis mode, describing which models to use for stellar atmospheres allowed values below\n",
    "        # -- planck (treat stars as blackbodies)\n",
    "        # -- kurucz (use Kurucz atmospheres, as compiled by Lejeune+ 1997)\n",
    "        # -- kurucz+hillier (use Hillier models for WR stars, kurucz for all others)\n",
    "        # -- kurucz+pauldrach (use Pauldrach models for OB stars, kurucz for others)\n",
    "        # -- sb99 (emulate starburst99 -- Pauldrach for OB stars, Hillier for WR stars, kurucz for others) This is the default value\n",
    "        f.write(f'clust_frac 1.0\\n') #TJ fraction of stars born in clusters (always 1.0 for sim types = cluster)\n",
    "        f.write(f'min_stoch_mass 0.08\\n') #TJ minimum stochastically sampled mass. Everything below is considered to be continuously sampled\n",
    "        #f.write(f'metallicity       1.0\\n') #TJ metalicity function. If tracks is specified, this should be omitted\n",
    "        #####################################################################\n",
    "        # Parameters controlling extinction                                 #\n",
    "        #####################################################################\n",
    "        f.write(f'A_V lib/avdist/slug_default.av\\n') #TJ set extinction function\n",
    "        f.write(f'extinction_curve lib/extinct/MW_EXT_SLUG.dat\\n') #TJ shape of extinction curve\n",
    "        f.write(f'nebular_extinction_factor lib/avdist/neb_factor_default.av\\n') #TJ use a different extinction law for nebulae\n",
    "        #####################################################################\n",
    "        # Parameters controlling nebular emission                           #\n",
    "        #####################################################################\n",
    "        f.write(f'compute_nebular 1\\n') #TJ compute nebular emission specifically?\n",
    "        #f.write(f'atomic_data lib/atomic\\n') #TJ atomic information, defaults to lib/atomic\n",
    "        #f.write(f'nebular_no_metals 0\\n') #TJ 1 would be to turn off nebular metal emission (includes He), 0 means leave metals on\n",
    "        #f.write(f'nebular_den 1.0e2\\n') #TJ hydrogen density (default is 100)\n",
    "        #f.write(f'nebular_temp -1.0\\n') #TJ nebular temperature, default is -1, if negative, temp will be calculated from cloudy\n",
    "        f.write(f'nebular_logU -2.5\\n') #TJ logU representing ionization parameter\n",
    "        f.write(f'nebular_phi 0.73\\n') #TJ fraction of ionizing photons that are absorbed by Hydrogen atoms\n",
    "        #############################################\n",
    "        # Parameters describing photometric filters #\n",
    "        #############################################\n",
    "        f.write(f'phot_bands JWST_F150W, JWST_F187N, JWST_F300M\\n') #TJ list of filters for photometric results\n",
    "        f.write(f'filters lib/filters\\n') #TJ directory for filter information to be read from\n",
    "        #f.write(f'phot_mode Lnu\\n') #TJ what units should the photometry results print in?\n",
    "        ############################################\n",
    "        # Parameters controlling yield calculation #\n",
    "        ############################################\n",
    "        f.write(f'yield_dir lib/yields\\n') #TJ directory for yield files\n",
    "        \n",
    "        # are available:\n",
    "        # \n",
    "        \n",
    "        # \n",
    "        f.write(f'yield_mode sukhbold16+karakas16+doherty14\\n') #TJ Model to use for yield calculation. Currently the following models accepted:\n",
    "        # -- sukhbold16 = Solar metallicity type II SN yields from Sukhbold et al. (2016, ApJ, 821, 38); no other yields\n",
    "        # -- # karakas16+doherty14 = metallicity-dependent AGB star yields from Karakas & Lugaro (2016, ApJ, 825, 26), and super- \n",
    "        #                                                                                 AGB star yields from Doherty+ (2014, MNRAS, 437, 195)\n",
    "        # -- sukhbold16+karakas16+doherty14 = sukhbold16 used for SNII, karakas16+doherty14 for AGB\n",
    "        f.write(f'\\n')\n",
    "\n",
    "    return input_file\n",
    "\n",
    "\n",
    "def read_all_files(model_name):\n",
    "    '''\n",
    "    Reads all SLUG output .txt files for a given model_name into a dictionary of numpy arrays.\n",
    "    Keys are column names, values are data arrays.\n",
    "    '''\n",
    "    output = {}\n",
    "    files = glob.glob(f'{slug_output_dir}/{model_name}_cluster*.txt')\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Get column names\n",
    "        col_names = lines[0].strip().split()\n",
    "        n_cols_names = len(col_names)\n",
    "        \n",
    "        # Parse data lines\n",
    "        data_entries = []\n",
    "        for line in lines[2:]:\n",
    "            stripped = line.strip()\n",
    "            if line.startswith('---------'):\n",
    "                continue\n",
    "            entries = stripped.split()\n",
    "            \n",
    "            # Pad missing entries with 'nan'\n",
    "            if len(entries) < n_cols_names:\n",
    "                entries += ['nan'] * (n_cols_names - len(entries))\n",
    "            data_entries.append(entries)\n",
    "        \n",
    "        # Skip empty files gracefully\n",
    "        if not data_entries:\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy array of strings first\n",
    "        data_array = np.array(data_entries, dtype='U20')\n",
    "        \n",
    "        # Convert each column individually to float if possible, else keep as string\n",
    "        for i, name in enumerate(col_names):\n",
    "            col = data_array[:, i]\n",
    "            try:\n",
    "                col_converted = col.astype(float)\n",
    "            except ValueError:\n",
    "                col_converted = col  # keep as string if conversion fails\n",
    "            \n",
    "            if name in output:\n",
    "                print(f\"Warning: Duplicate column name '{name}' found. Overwriting previous value.\")\n",
    "            output[name] = col_converted\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def compute_paalpha_ew(data):  \n",
    "    \"\"\"  \n",
    "    Compute Paα flux and equivalent width from SLUG output.  \n",
    "\n",
    "    Args:  \n",
    "        data (dict): Dictionary with filter fluxes (e.g., 'JWST_F150W').  \n",
    "\n",
    "    Returns:  \n",
    "        dict: Paα flux (Jy), continuum (Jy), and EW (Å).  \n",
    "    \"\"\"  \n",
    "    # Extract fluxes (adjust keys if needed)  \n",
    "    f150 = data['JWST_F150W']  # Continuum filter 1  \n",
    "    f200 = data['JWST_F200W']  # Continuum filter 2  \n",
    "    f187n = data['JWST_F187N'] # Paα filter  \n",
    "    f187c = data['JWST_F187N_n'] #continuum around Paa\n",
    "    # Estimate continuum at Paα (1.875 µm) by linear interpolation  \n",
    "    # Wavelengths (µm) for each filter (central λ from JWST)  \n",
    "    lambda150 = 1.50  \n",
    "    lambda187 = 1.875  \n",
    "    lambda200 = 2.00  \n",
    "\n",
    "    # Linear fit to continuum (F150W and F200W)  \n",
    "    slope = (f200 - f150) / (lambda200 - lambda150)  \n",
    "    continuum = f150 + slope * (lambda187 - lambda150)  \n",
    "    \n",
    "    # Subtract continuum to isolate Paα flux  \n",
    "    paalpha_flux = f187n - continuum  \n",
    "    paalpha_flux_c = f187n - f187c\n",
    "    # Compute equivalent width (EW) in Ångströms  \n",
    "    # EW = Δλ (F_line / F_continuum), where Δλ = F187N filter width (~0.02 µm = 200 Å)  \n",
    "    f187n_width = 0.02 * 1e4  # Convert µm to Å (1 µm = 1e4 Å)  \n",
    "    ew = f187n_width * (paalpha_flux / continuum)  \n",
    "    ew_c = f187n_width * (paalpha_flux_c / f187c)  \n",
    "\n",
    "    return {'paalpha_flux': paalpha_flux, 'continuum': continuum, 'EW': ew,\n",
    "            'paalpha_flux_c': paalpha_flux, 'continuum_c': continuum, 'EW_c': ew_c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [200, 2000,5000,10000,20000,50000]:\n",
    "    model_name = f'testing_young_cluster_mass_{m}'\n",
    "    slug_input_file = do_alex_model(model_name, m, N=1000)\n",
    "    os.system(f\"conda run -n TaylorJ {slug_path} {slug_input_file}\")\n",
    "    temp = read_all_files(model_name)\n",
    "    rows = [dict(zip(temp.keys(), values)) for values in zip(*temp.values())]\n",
    "    ews = []\n",
    "    ews_c = []\n",
    "    for row in rows:\n",
    "        ews.append(compute_paalpha_ew(row)['EW'])\n",
    "        ews_c.append(compute_paalpha_ew(row)['EW_c'])\n",
    "    data = np.array([temp['Time'], ews, ews_c])\n",
    "    np.save(f'{slug_output_dir}/young_{m}_mass_EW.npy', data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masses = [200, 2000, 5000, 10000, 20000, 50000]\n",
    "\n",
    "# Determine grid size (e.g. 2 rows x 3 columns for 6 plots)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(masses) / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, m in enumerate(masses):\n",
    "    data = np.load(f'/d/ret1/Taylor/jupyter_notebooks/Research/SLUG_stuff/datasets/young_{m}_mass_EW.npy')\n",
    "    \n",
    "    ax = axes[i]\n",
    "    chunk_data = []\n",
    "    c_chunk_data = []\n",
    "    for chunk in range(1000):\n",
    "        start = 10*chunk\n",
    "        ax.plot(data[0][start:start+10], data[1][start:start+10], linewidth = 0.1, color = 'black')\n",
    "        chunk_data.append(data[1][start:start+10])\n",
    "        c_chunk_data.append(data[2][start:start+10])\n",
    "        \n",
    "    chunk_data = np.array(chunk_data)  # shape: (100, 10)\n",
    "    c_chunk_data = np.array(chunk_data)  # shape: (100, 10)\n",
    "    \n",
    "    # Calculate median across chunks for each timestep\n",
    "    median_y = np.nanmedian(chunk_data, axis=0)\n",
    "    median_y_c = np.nanmedian(c_chunk_data, axis=0)\n",
    "    \n",
    "    # Overplot median track\n",
    "    ax.plot(data[0][start:start+10], median_y, color='red', linewidth=3, label='Median')\n",
    "    ax.plot(data[0][start:start+10], median_y_c, color='blue', linewidth=1, label='Median_c')\n",
    "    \n",
    "    ax.set_title(f'Mass = {m}')\n",
    "    ax.set_xlabel('Age (years)')\n",
    "    ax.set_ylabel('EW in Angstroms')\n",
    "    ax.legend(fontsize=6)\n",
    "# Hide any unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in temp:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['JWST_F187N_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
